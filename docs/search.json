[
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#objective",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#objective",
    "title": "Matchup satellite data to track locations",
    "section": "Objective",
    "text": "Objective\nThis tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like those produced by an animal telemetry tag, and ship track, or a glider track.",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Matchup satellite data to track locations",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nImporting track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#datasets-used",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#datasets-used",
    "title": "Matchup satellite data to track locations",
    "section": "Datasets used",
    "text": "Datasets used\nChlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nLoggerhead turtle telemetry track data\nThe turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. This dataset has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The track data are stored in the data folder in this project folder.",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "title": "Matchup satellite data to track locations",
    "section": "Install required packages and load libraries",
    "text": "Install required packages and load libraries\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\nThe downloaded binary packages are in\n    /var/folders/w4/4s0hrwdd2gd8k4kp6s1z8zn40000gn/T//Rtmp0nKV5b/downloaded_packages",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "title": "Matchup satellite data to track locations",
    "section": "Import the track data into a data frame",
    "text": "Import the track data into a data frame\n\n# Import csv file into a data frame\nturtle_df &lt;- read.csv(\"../data/25317_05_subsampled.dat\")\n# Show 3 rows from the data frame\nhead(turtle_df,3)\n\n  mean_lon mean_lat year month day\n1 176.6194 32.67873 2005     5   4\n2 175.8609 35.05773 2005     6  23\n3 180.5926 40.40576 2005     8  12",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to track locations",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\n# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map turtle tracks\nggplot(turtle_df, aes(mean_lon,mean_lat)) +\n  geom_path(group=1)+\n  geom_point(aes(x=mean_lon,y=mean_lat), pch=1, size=2 )+\n  geom_point(aes(x=mean_lon[1],y=mean_lat[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=mean_lon[length(mean_lon)],y=mean_lat[length(mean_lat)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=1/2)\n\n\n\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nBy manually constructing a URL with the data data request\n\n\nExtracting XYT data using the rerddapXtracto package\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#examine-metadata",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#examine-metadata",
    "title": "Matchup satellite data to track locations",
    "section": "Examine metadata",
    "text": "Examine metadata\nrerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n\n# Display the metadata\ndataInfo\n\n&lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n Dataset Type: griddap \n Dimensions (range):  \n     time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n     latitude: (-89.97916666666666, 89.97916666666667) \n     longitude: (0.020833333333314386, 359.97916666666663) \n Variables:  \n     chlor_a: \n         Units: mg m-3 \n     chlor_a_log10_bias: \n     chlor_a_log10_rmsd: \n     MERIS_nobs_sum: \n     MODISA_nobs_sum: \n     OLCI_A_nobs_sum: \n     OLCI_B_nobs_sum: \n     SeaWiFS_nobs_sum: \n     total_nobs_sum: \n     VIIRS_nobs_sum: \n\n# Display data attributes\nnames(dataInfo)\n\n[1] \"variables\" \"alldata\"   \"base_url\" \n\n# Examine attribute: variables\ndataInfo$variables\n\n        variable_name data_type actual_range\n1             chlor_a     float             \n2  chlor_a_log10_bias     float             \n3  chlor_a_log10_rmsd     float             \n4      MERIS_nobs_sum     float             \n5     MODISA_nobs_sum     float             \n6     OLCI_A_nobs_sum     float             \n7     OLCI_B_nobs_sum     float             \n8    SeaWiFS_nobs_sum     float             \n9      total_nobs_sum     float             \n10     VIIRS_nobs_sum     float             \n\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n\n [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n[10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n[13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"    \n\n\n\nExtract data using the rxtracto function\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\nturtle_df$date &lt;- as.Date(paste(turtle_df$year, turtle_df$month, turtle_df$day, sep=\"-\"))\n\n# Get variables x, y, t coordinates from turtle track data\nxcoords &lt;- turtle_df$mean_lon\nycoords &lt;- turtle_df$mean_lat\ntcoords &lt;- turtle_df$date\n\n# Extract satellite data using x, y, t coordinates from turtle track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "title": "Matchup satellite data to track locations",
    "section": "Check the output of the rxtracto function",
    "text": "Check the output of the rxtracto function\n\n# Check all variables extracted using rxtracto\nchl_track\n\n$`mean chlor_a`\n [1] 0.26779765 0.12073122 0.30777924 0.31780368 0.28884829 0.36146353\n [7] 0.22923882 0.11644071 0.09268904 0.05536651 0.18447913 0.22765385\n[13] 0.23869553 0.24669819 0.35838123 0.09624625 0.12024124 0.11400095\n[19] 0.10017463 0.09397742 0.08515869 0.06913812 0.14883095 0.51560753\n[25] 0.65806269\n\n$`stdev chlor_a`\n [1] 0.032191816 0.007231171 0.036716832 0.041052758 0.027952051 0.053364804\n [7] 0.024394244 0.007282479 0.003880810 0.001490017 0.040774493 0.025363286\n[13] 0.014782180 0.013523678 0.036640145 0.004842596 0.004098601 0.003910613\n[19] 0.003537558 0.005928580 0.007001476 0.004942355 0.011980482 0.099209610\n[25] 0.149563991\n\n$n\n [1] 36 36 36 27 36 30 36 36 30 30 30 30 36 30 36 30 36 36 36 30 36 30 36 36 36\n\n$`satellite date`\n [1] \"2005-05-01T00:00:00Z\" \"2005-07-01T00:00:00Z\" \"2005-08-01T00:00:00Z\"\n [4] \"2005-10-01T00:00:00Z\" \"2005-12-01T00:00:00Z\" \"2006-01-01T00:00:00Z\"\n [7] \"2006-03-01T00:00:00Z\" \"2006-05-01T00:00:00Z\" \"2006-06-01T00:00:00Z\"\n[10] \"2006-08-01T00:00:00Z\" \"2006-09-01T00:00:00Z\" \"2006-11-01T00:00:00Z\"\n[13] \"2007-01-01T00:00:00Z\" \"2007-02-01T00:00:00Z\" \"2007-04-01T00:00:00Z\"\n[16] \"2007-06-01T00:00:00Z\" \"2007-07-01T00:00:00Z\" \"2007-09-01T00:00:00Z\"\n[19] \"2007-11-01T00:00:00Z\" \"2007-12-01T00:00:00Z\" \"2008-02-01T00:00:00Z\"\n[22] \"2008-04-01T00:00:00Z\" \"2008-05-01T00:00:00Z\" \"2008-07-01T00:00:00Z\"\n[25] \"2008-08-01T00:00:00Z\"\n\n$`requested lon min`\n [1] 176.5194 175.7609 180.4926 183.4102 186.8997 193.2152 198.9158 196.2679\n [9] 194.2116 192.7545 193.9788 191.9444 191.6600 194.9631 199.2066 205.5050\n[17] 210.1805 215.6225 222.9073 225.5386 232.3064 239.4530 245.7716 248.4710\n[25] 245.6579\n\n$`requested lon max`\n [1] 176.7194 175.9609 180.6926 183.6102 187.0997 193.4152 199.1158 196.4679\n [9] 194.4116 192.9545 194.1788 192.1444 191.8600 195.1631 199.4066 205.7050\n[17] 210.3805 215.8225 223.1073 225.7386 232.5064 239.6530 245.9716 248.6710\n[25] 245.8579\n\n$`requested lat min`\n [1] 32.57873 34.95773 40.30576 41.58480 37.26623 32.03793 32.01126 34.81224\n [9] 34.59661 36.99175 41.66933 38.12796 34.63858 31.63964 34.24324 35.02771\n[17] 38.36083 39.23749 35.76793 30.08540 28.22859 25.88108 24.73662 23.62417\n[25] 26.68177\n\n$`requested lat max`\n [1] 32.77873 35.15773 40.50576 41.78480 37.46623 32.23793 32.21126 35.01224\n [9] 34.79661 37.19175 41.86933 38.32796 34.83858 31.83964 34.44324 35.22771\n[17] 38.56083 39.43749 35.96793 30.28540 28.42859 26.08108 24.93662 23.82417\n[25] 26.88177\n\n$`requested z min`\n [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n\n$`requested z max`\n [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n\n$`requested date`\n [1] \"2005-05-04\" \"2005-06-23\" \"2005-08-12\" \"2005-10-01\" \"2005-11-20\"\n [6] \"2006-01-09\" \"2006-02-28\" \"2006-04-19\" \"2006-06-08\" \"2006-07-28\"\n[11] \"2006-09-16\" \"2006-11-05\" \"2006-12-25\" \"2007-02-13\" \"2007-04-04\"\n[16] \"2007-05-24\" \"2007-07-13\" \"2007-09-01\" \"2007-10-21\" \"2007-12-10\"\n[21] \"2008-01-29\" \"2008-03-19\" \"2008-05-08\" \"2008-06-27\" \"2008-08-16\"\n\n$`median chlor_a`\n [1] 0.26985641 0.11935977 0.31413330 0.31312889 0.28226255 0.35456662\n [7] 0.22596541 0.11711950 0.09256660 0.05540323 0.18355133 0.22467585\n[13] 0.24202415 0.24848759 0.34953472 0.09518800 0.11983451 0.11379882\n[19] 0.10012896 0.09296544 0.08735247 0.06766215 0.14883141 0.49834299\n[25] 0.67895702\n\n$`mad chlor_a`\n [1] 0.030100095 0.008344179 0.039171724 0.027213317 0.023952735 0.049566912\n [7] 0.022928175 0.009027836 0.003463391 0.001267676 0.035848973 0.026539111\n[13] 0.016244819 0.011793729 0.035606685 0.003954114 0.002984454 0.002953619\n[19] 0.002999692 0.003767908 0.003242842 0.003565519 0.015092995 0.109981245\n[25] 0.133971250\n\nattr(,\"row.names\")\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\"\nattr(,\"class\")\n[1] \"list\"          \"rxtractoTrack\"\nattr(,\"base_url\")\n[1] \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\nattr(,\"datasetid\")\n[1] \"esa-cci-chla-monthly-v6-0\"\n\n\nrxtracto computes statistics using all the pixels found in the search radius around each track point.",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "title": "Matchup satellite data to track locations",
    "section": "Plotting the results using plotTrack",
    "text": "Plotting the results using plotTrack\nWe will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#animating-the-track",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#animating-the-track",
    "title": "Matchup satellite data to track locations",
    "section": "Animating the track",
    "text": "Animating the track\nOne of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done.\n\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track, make180(xcoords), ycoords, tcoords, plotColor = 'viridis',\n                    animate = TRUE, cumulative = TRUE)\n\nNULL",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "title": "Matchup satellite data to track locations",
    "section": "Plotting the results using ggplot",
    "text": "Plotting the results using ggplot\n\nCreate a data frame with the turtle track and the output of rxtracto\nIf we to do an customization of the plot, its better to plot the dat ausing ggplot. We will first create a data frame that contains longitudes and latitudes from the turtle and associated satellite chlor-a values.\n\n# Create a data frame of coords from turtle and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`))\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \"Lat\", \"Matchup_Lon_Lower\", \"Matchup_Lon_Upper\", \"Matchup_Lat_Lower\", \"Matchup_Lat_Upper\",  \"Chlor_a\")\nwrite.csv(new_df, \"matchup_df.csv\")\n\n\n\nPlot using ggplot\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\nExtracting XYT data by constructing the URL data requests manually\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_1d_2018_0.csv?chlor_a\"\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data is severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps.\n\n# Set erddap address\nerddap &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\"\n\n# Get longitude and latitude from turtle track data\nlon &lt;- turtle_df$mean_lon\nlat &lt;- turtle_df$mean_lat\n\n# Get time from turtle track data and convert into ERDDAP date format\ndates &lt;- mdy.date(turtle_df$month,turtle_df$day,turtle_df$year)\ndates2 &lt;- format(as.Date(dates), \"%Y-%m-%d\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each turtle track data\nfor (i in 1:dim(turtle_df)[1]) {\n\n   # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap, \"[(\", dates2[i], \"):1:(\", dates2[i], \")][(\", lat[i], \"):1:(\", lat[i], \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n}\n\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining turtle track data and the chlo-a data\nchl_track2 &lt;- data.frame(turtle_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'turtle-track-chl.m.csv', row.names = FALSE)\n\n\n\nMake a map of the data extracted using the second method\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(mean_lon,mean_lat,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\nPlot histogram of chlorophyll\nHow do the chlorophyll values of the turtle track compare to values in the surrounding environment? Meaning does the turtle seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the turtle track over the span of time the turtle was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\n\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or turtle chlorophyll \n\nchl_turtle &lt;- chl_track$`mean chlor_a`\n\nNow we we plot histograms of all the chlorphyll values in the area, and those of the turtle track. Since we subset the turtletrack, and only have 25 points for this subsampopled dataset the turtle histogram isn’t as useful as it would be with a larger dataset.\n\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_turtle), aes(x=chl_turtle,y=after_stat(density),color='green', fill='Turtle'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\n\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\* This dataset is a different ERDDAP, so remember to change the base URL. \\* Set the new dataset ID and variable name.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\* This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\* Set the new dataset ID and variable name. \\* Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/2-subset-and-plot.html#summary",
    "href": "tutorials/r/2-subset-and-plot.html#summary",
    "title": "Subset and Plot",
    "section": "Summary",
    "text": "Summary\nNeed to make a R version of the Python code.",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html",
    "href": "tutorials/r/05-r-geospatial.html",
    "title": "Geospatial in R - lab 1",
    "section": "",
    "text": "require(sf)\nrequire(mapview)\nrequire(readr)\nrequire(readxl)\nhere::i_am(\"tutorials/r/05-r-geospatial.qmd\")\ndir_data &lt;- here::here(\"tutorials\", \"data\")\nIn this lab, you will learn basic skills of working with points. We will store our points in data frames. All our points data frames will have these columns:\nBut the columns names are often shortened to lon, lat or lng, latd or anything else.\nIn addition they will have other info in other columns."
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#create-a-data-frame-of-points",
    "href": "tutorials/r/05-r-geospatial.html#create-a-data-frame-of-points",
    "title": "Geospatial in R - lab 1",
    "section": "Create a data frame of points",
    "text": "Create a data frame of points\n\nlibrary(mapview)\n  \n# Create example data of points\nlon &lt;- c(85.21, 80.23, 77.28)\nlat = c(25.59, 12.99, 28.56)\nnames = c(\"Patna\", \"Chennai\", \"New Delhi\")\n  \n# Create a data frame with the point data\ndf &lt;- data.frame(lon, lat, names)"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#convert-to-a-spatial-points-data-frame",
    "href": "tutorials/r/05-r-geospatial.html#convert-to-a-spatial-points-data-frame",
    "title": "Geospatial in R - lab 1",
    "section": "Convert to a spatial points data frame",
    "text": "Convert to a spatial points data frame\n\n\n\n\n\n\nCore skill\n\n\n\nConvert data frame with latitude and longitude columns to a geospatial object with a geometry column and coordinate system. We are setting the coordinate system to WGS 84 with crs = 4326.\n\nsf::st_as_sf() function\n\n\n\nThis is a special data frame where the location data is converted to a single point object.\n\ncities3 &lt;- sf::st_as_sf(\n    df, # the data frame\n    coords = c(\"lon\", \"lat\"), # what are the x and y dimension names\n    crs = 4326)\n\nLook at the class of the object\n\nclass(cities3)\n\n[1] \"sf\"         \"data.frame\""
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#plot-the-points",
    "href": "tutorials/r/05-r-geospatial.html#plot-the-points",
    "title": "Geospatial in R - lab 1",
    "section": "Plot the points",
    "text": "Plot the points\n\nplot(cities3)\n\n\n\n\nIt plotted but it is not very useful. Let’s use the helper package mapview. That’s more useful.\n\nmapview::mapview(cities3, label = cities3$names)"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#read-in-points-from-files",
    "href": "tutorials/r/05-r-geospatial.html#read-in-points-from-files",
    "title": "Geospatial in R - lab 1",
    "section": "Read in points from files",
    "text": "Read in points from files\n\n\n\n\n\n\nCore skill\n\n\n\nRead in tabular data with latitude, longitude into a data frame.\n\nreadr::read_csv() or readxl::read_excel()"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#from-a-csv-file",
    "href": "tutorials/r/05-r-geospatial.html#from-a-csv-file",
    "title": "Geospatial in R - lab 1",
    "section": "from a csv file",
    "text": "from a csv file\nHere I use a URL to a csv file. However I could use fil &lt;- file.path(\"data\", \"india_tide_guages.csv\") since I have the data file in a directory data in the same folder as my Quarto file (or RMarkdown or R script).\n\nfil &lt;- here::here(\"tutorials\", \"data\", \"india_tide_guages.csv\")\ndf2 &lt;- readr::read_csv(fil, show_col_types = FALSE)\n\nConvert to spatial data frame. Notice, I had to change the latitude and longitude to match the columns names in the dataframe.\n\nsdf &lt;- sf::st_as_sf(\n    df2, \n    coords = c(\"Longitude\", \"Latitude\"), # what are the x and y dimension names\n    crs = 4326)\n\nMap. You can click on the points to get more info.\n\nmapview::mapview(sdf)\n\n\n\n\n\nIf you want state labels, you need to only have the geometry and label columns in the dataframe.\n\nsdf2 &lt;- sdf %&gt;% select(geometry, State)\nmapview::mapview(sdf2, label = sdf2$State)\n\n\nfrom Excel file\n\nfil &lt;- here::here(\"tutorials\", \"data\", \"india_tide_guages.xlsx\")\ndf3 &lt;- readxl::read_excel(fil, sheet = \"Kerala\")\n\nConvert to spatial points.\n\nsdf = sf::st_as_sf(\n    df3, \n    coords = c(\"Longitude\", \"Latitude\"), \n    crs = 4326)\n\n\nmapview::mapview(sdf)"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#using-ggplot2",
    "href": "tutorials/r/05-r-geospatial.html#using-ggplot2",
    "title": "Geospatial in R - lab 1",
    "section": "Using ggplot2",
    "text": "Using ggplot2\nHere is a gallery of some basic plots you can make. There are many ways to make maps with ggplot2. I will use a single approach that is fairly flexible.\n\n\n\n\n\n\nCore skill\n\n\n\nCreate a base world and India map from rnaturalearth. Plot with ggplot2.\n\nne_countries()\nggplot() + geom_sf()\ncoord_sf()\n\n\n\n\nIndia alone\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nindia_sf &lt;- ne_countries(country = \"India\", scale = \"medium\", returnclass = \"sf\")\nbasemap &lt;- ggplot() + \n  geom_sf(data = india_sf, color = \"black\", size = 2, fill=\"green\") +\n  coord_sf(xlim = c(58, 98), ylim = c(6, 30))\nbasemap\n\n\n\n\n\nfil &lt;- here::here(\"tutorials\", \"data\", \"india.jpeg\")\nggsave(filename = fil, plot = basemap, device = \"jpeg\")\n\nSaving 7 x 5 in image\n\n\n\n\n\n\n\n\nCore skill\n\n\n\nAdd points to a plot.\n\ngeom_sf(data=points_df)\n\n\n\nAdd points\n\nbasemap + \n  geom_sf(data = cities3, aes(color = names), size = 3) +\n  theme_void()\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n\n\nThe world\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nbasemap &lt;- ggplot() + \n  geom_sf(data = world_sf, color = \"black\", size = 0.2, fill=\"lightblue\")\nbasemap\n\n\n\n\nAdd points\n\nbasemap + \n  geom_sf(data = cities3, aes(color = names), size = 1)\n\n\n\n\nZoom in\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nbasemap &lt;- ggplot() + \n  geom_sf(data = world_sf, color = \"black\", size = 0.2, fill=\"lightblue\") +\n  coord_sf(xlim = c(58, 98), ylim = c(0, 30))\nbasemap\n\n\n\n\nAdd points\n\nbasemap + \n  geom_sf(data = cities3, aes(color = names), size = 2) +\n  coord_sf(xlim = c(58, 98), ylim = c(0, 30))\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one."
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#change-the-projection",
    "href": "tutorials/r/05-r-geospatial.html#change-the-projection",
    "title": "Geospatial in R - lab 1",
    "section": "Change the projection",
    "text": "Change the projection\n\n\n\n\n\n\nCore skill\n\n\n\nApply a coordinate reference system to a sf object.\n\nst_transform(sf_object, crs=crs)\n\nCommon CRS’s\n\ncrs = 4326 WGS 84\nRobinson crs = \"+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\nGlobe crs = \"+proj=laea +lon_0=77 +lat_0=20 +ellps=WGS84 +no_defs\"\n\n\n\nMake a world in Robinson coord system.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\ncrs &lt;- \"+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\" \nworld_crs &lt;- st_transform(world_sf, crs=crs)\nbasemap &lt;- ggplot() +\n  geom_sf(data = world_crs, color = \"black\", size = 0.2, fill=\"lightblue\") +\n  theme_minimal()\nbasemap\n\n\n\n\nAdd points.\n\ncities3_robin &lt;- st_transform(cities3, crs=crs)\nbasemap + \n  geom_sf(data = cities3_robin, aes(color = names), size = 2)\n\n\n\n\nMake a globe.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\ncrs &lt;- \"+proj=laea +lon_0=77 +lat_0=20 +ellps=WGS84 +no_defs\"\nworld_crs &lt;- sf::st_transform(world_sf, crs)\nbasemap &lt;- ggplot() +\n  geom_sf(data = world_crs, color = \"black\", size = 0.2, fill=\"lightblue\") +\n  theme_minimal()\nbasemap\n\n\n\n\nAdd points.\n\ncities3_crs &lt;- st_transform(cities3, crs=crs)\nbasemap + \n  geom_sf(data = cities3_crs, aes(color = names), size = 2)\n\n\n\n\nAdd a circle around the globe.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\ncrs &lt;- \"+proj=laea +lon_0=77 +lat_0=20 +ellps=WGS84 +no_defs\"\nworld_crs &lt;- sf::st_transform(world_sf, crs)\n\nsphere &lt;- st_graticule(ndiscr = 10000, margin = 10e-6) %&gt;%\n  st_transform(crs = crs) %&gt;%\n  st_convex_hull() %&gt;%\n  summarise(geometry = st_union(geometry))\n\nbasemap &lt;- ggplot()  +\n  geom_sf(data = sphere, fill = \"#D8F4FF\", alpha = 0.7) +\n  geom_sf(data = world_crs, fill=\"grey\") +\n  theme_bw()\nbasemap\n\n\n\n\nAdd points and remove legend.\n\n# Add crs\ncities3_crs &lt;- st_transform(cities3, crs=crs)\nbasemap + \n  geom_sf(data = cities3_crs, aes(color = names), size = 1) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#getting-help-from-chatgpt",
    "href": "tutorials/r/05-r-geospatial.html#getting-help-from-chatgpt",
    "title": "Geospatial in R - lab 1",
    "section": "Getting help from ChatGPT",
    "text": "Getting help from ChatGPT\nUnfortunately, ChatGPT often gets confused with mapping and gives you code that doesn’t fully work. This can be hard for beginners (and experts) to debug.\nTry telling it\n\nUse only the sf, rnaturalearth, and ggplot2 packages\nWork in steps, “Make a sf points object and name it sf_points”, “Using sf_points”, add these points to a map of the world.”"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#your-turn",
    "href": "tutorials/r/05-r-geospatial.html#your-turn",
    "title": "Geospatial in R - lab 1",
    "section": "Your Turn!",
    "text": "Your Turn!\nMake some maps using mapview of your own data, data in the “r-tutorials/data” directory or data you can find on-line.\nTry the layer feature to change the base map."
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan or frequency measurements, or spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of locations with boundaries include Marine Protected Areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces.",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary.",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server\nVisualizing data on a map\nMasking satellite data using a shape file",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#import-packages",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#import-packages",
    "title": "Extract data within a boundary",
    "section": "Import packages",
    "text": "Import packages\nNote: Make sure you have at least version 0.10.0 of regionmask * To install with conda use “conda install -c conda-forge regionmask=0.10.0 cartopy”\n\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport geopandas\nimport regionmask\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "title": "Extract data within a boundary",
    "section": "Load the Longhurst Provinces shape files into a geopandas dataframe",
    "text": "Load the Longhurst Provinces shape files into a geopandas dataframe\n\n#shape_path = '../resources/longhurst_v4_2010/Longhurst_world_v4_2010.shp'\nshape_path = os.path.join('..',\n                          'resources',\n                          'longhurst_v4_2010',\n                          'Longhurst_world_v4_2010.shp'\n                          )\nshapefiles = geopandas.read_file(shape_path)\nshapefiles.head(8)\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n0\nBPLR\nPolar - Boreal Polar Province (POLR)\nMULTIPOLYGON (((-161.18426 63.50000, -161.5000...\n\n\n1\nARCT\nPolar - Atlantic Arctic Province\nMULTIPOLYGON (((-21.51305 64.64409, -21.55945 ...\n\n\n2\nSARC\nPolar - Atlantic Subarctic Province\nMULTIPOLYGON (((11.26472 63.96082, 11.09548 63...\n\n\n3\nNADR\nWesterlies - N. Atlantic Drift Province (WWDR)\nPOLYGON ((-11.50000 57.50000, -11.50000 56.500...\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500...\n\n\n5\nNASW\nWesterlies - N. Atlantic Subtropical Gyral Pro...\nPOLYGON ((-39.50000 25.50000, -40.50000 25.500...\n\n\n6\nNATR\nTrades - N. Atlantic Tropical Gyral Province (...\nMULTIPOLYGON (((-72.34673 18.53597, -72.36877 ...\n\n\n7\nWTRA\nTrades - Western Tropical Atlantic Province\nPOLYGON ((-19.50000 -6.50000, -20.50000 -6.500...",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "title": "Extract data within a boundary",
    "section": "Isolate the Gulf Stream Province",
    "text": "Isolate the Gulf Stream Province\nThe Gulf Stream Province can be isolated using its ProvCode (GFST)\n\nProvCode = \"GFST\"\n\n# Locate the row with the ProvCode code\ngulf_stream = shapefiles.loc[shapefiles[\"ProvCode\"] == ProvCode]\ngulf_stream\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500...",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "title": "Extract data within a boundary",
    "section": "Find the coordinates of the bounding box",
    "text": "Find the coordinates of the bounding box\n\nThe bounding box is the smallest rectangle that will completely enclose the province.\nWe will use the bounding box coordinates to subset the satellite data\n\n\ngs_bnds = gulf_stream.bounds\ngs_bnds\n\n\n\n\n\n\n\n\nminx\nminy\nmaxx\nmaxy\n\n\n\n\n4\n-73.5\n33.5\n-43.5\n43.5",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "title": "Extract data within a boundary",
    "section": "Open the satellite dataset into a xarray dataset object",
    "text": "Open the satellite dataset into a xarray dataset object\n\nerddap_url = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'NOAA_DHW_monthly'\n                       ])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                          (time: 464, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time                             (time) datetime64[ns] 1985-01-16 ... 202...\n  * latitude                         (latitude) float32 89.97 89.93 ... -89.97\n  * longitude                        (longitude) float32 -180.0 -179.9 ... 180.0\nData variables:\n    sea_surface_temperature          (time, latitude, longitude) float32 ...\n    mask                             (time, latitude, longitude) float32 ...\n    sea_surface_temperature_anomaly  (time, latitude, longitude) float32 ...\nAttributes: (12/66)\n    _NCProperties:                    version=2,netcdf=4.8.1,hdf5=1.12.2\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2023-08-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              1985-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -179.975xarray.DatasetDimensions:time: 464latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-16 ... 2023-08-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-16T00:00:00.000000000', '1985-02-16T00:00:00.000000000',\n       '1985-03-16T00:00:00.000000000', ..., '2023-06-16T00:00:00.000000000',\n       '2023-07-16T00:00:00.000000000', '2023-08-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3289.97 89.93 89.88 ... -89.92 -89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([ 89.975   ,  89.92501 ,  89.87501 , ..., -89.875   , -89.924995,\n       -89.975   ], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-179.975  , -179.925  , -179.875  , ...,  179.875  ,  179.92499,\n        179.975  ], dtype=float32)Data variables: (3)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[12026880000 values with dtype=float32]mask(time, latitude, longitude)float32...colorBarMaximum :5.0colorBarMinimum :0.0comment :A 2D array, in the same size as the data array in the X and Y directions, the classifies land, ice pixels, and water (data) pixelscoverage_content_type :thematicClassificationflag_meanings :valid-water land missing iceflag_values :[0 1 2 4]ioos_category :Qualitylong_name :Pixel characteristics flag arrayunits :pixel_classification[12026880000 values with dtype=float32]sea_surface_temperature_anomaly(time, latitude, longitude)float32...colorBarMaximum :3.0colorBarMinimum :-3.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :sea surface temperature anomalystandard_name :surface_temperature_anomalyunits :degree_Cvalid_max :15.0valid_min :-15.0[12026880000 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-16 00:00:00', '1985-02-16 00:00:00',\n               '1985-03-16 00:00:00', '1985-04-16 00:00:00',\n               '1985-05-15 23:00:00', '1985-06-15 23:00:00',\n               '1985-07-15 23:00:00', '1985-08-15 23:00:00',\n               '1985-09-15 23:00:00', '1985-10-15 23:00:00',\n               ...\n               '2022-11-16 00:00:00', '2022-12-16 00:00:00',\n               '2023-01-16 00:00:00', '2023-02-16 00:00:00',\n               '2023-03-16 00:00:00', '2023-04-16 00:00:00',\n               '2023-05-16 00:00:00', '2023-06-16 00:00:00',\n               '2023-07-16 00:00:00', '2023-08-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', length=464, freq=None))latitudePandasIndexPandasIndex(Index([  89.9749984741211,  89.92501068115234,  89.87500762939453,\n        89.82500457763672,   89.7750015258789,   89.7249984741211,\n        89.67501068115234,  89.62500762939453,  89.57500457763672,\n         89.5250015258789,\n       ...\n        -89.5250015258789, -89.57499694824219,            -89.625,\n       -89.67499542236328,  -89.7249984741211,  -89.7750015258789,\n       -89.82499694824219,            -89.875, -89.92499542236328,\n        -89.9749984741211],\n      dtype='float32', name='latitude', length=3600))longitudePandasIndexPandasIndex(Index([-179.97500610351562,  -179.9250030517578,            -179.875,\n       -179.82501220703125, -179.77500915527344, -179.72500610351562,\n        -179.6750030517578,            -179.625, -179.57501220703125,\n       -179.52500915527344,\n       ...\n        179.52499389648438,  179.57501220703125,             179.625,\n        179.67498779296875,  179.72500610351562,  179.77499389648438,\n        179.82501220703125,             179.875,  179.92498779296875,\n        179.97500610351562],\n      dtype='float32', name='longitude', length=7200))Attributes: (66)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.12.2acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :179.975geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_units :degrees_northgeospatial_lon_max :179.975geospatial_lon_min :-179.975geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T18:39:14Z (local files)\n2023-09-06T18:39:14Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.dasid :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :-89.975spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2023-08-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1985-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-179.975",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Subset the satellite data",
    "text": "Subset the satellite data\n\nUse the bounding box coordinates for the latitude and longitude slices\nSelect the entire year of 2020\n\n\n# This dataset has latitude in descending order. \n# Therefore use maxy first and miny last to slice latitude\nds_subset = ds['sea_surface_temperature'].sel(time=slice(\"2020-01-16\", \"2020-12-16\"),\n                                              latitude=slice(gs_bnds.maxy.item(), \n                                                             gs_bnds.miny.item()),\n                                              longitude=slice(gs_bnds.minx.item(), \n                                                              gs_bnds.maxx.item())\n                                            )\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'sea_surface_temperature' (time: 12, latitude: 200,\n                                             longitude: 600)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2020-01-16 2020-02-16 ... 2020-12-16\n  * latitude   (latitude) float32 43.47 43.43 43.38 43.33 ... 33.62 33.58 33.53\n  * longitude  (longitude) float32 -73.47 -73.42 -73.38 ... -43.62 -43.57 -43.53\nAttributes:\n    colorBarMaximum:        32.0\n    colorBarMinimum:        0.0\n    coverage_content_type:  physicalMeasurement\n    ioos_category:          Temperature\n    long_name:              analysed sea surface temperature\n    standard_name:          sea_surface_temperature\n    units:                  degree_C\n    valid_max:              50.0\n    valid_min:              -2.0xarray.DataArray'sea_surface_temperature'time: 12latitude: 200longitude: 600...[1440000 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2020-01-16 ... 2020-12-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2020-01-16T00:00:00.000000000', '2020-02-16T00:00:00.000000000',\n       '2020-03-15T23:00:00.000000000', '2020-04-15T23:00:00.000000000',\n       '2020-05-15T23:00:00.000000000', '2020-06-15T23:00:00.000000000',\n       '2020-07-15T23:00:00.000000000', '2020-08-15T23:00:00.000000000',\n       '2020-09-15T23:00:00.000000000', '2020-10-15T23:00:00.000000000',\n       '2020-11-16T00:00:00.000000000', '2020-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3243.47 43.43 43.38 ... 33.58 33.53_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([43.475   , 43.42501 , 43.375008, 43.325005, 43.275   , 43.225   ,\n       43.17501 , 43.125008, 43.075005, 43.025   , 42.975   , 42.92501 ,\n       42.875008, 42.825005, 42.775   , 42.725   , 42.67501 , 42.625008,\n       42.575005, 42.525   , 42.475   , 42.42501 , 42.375008, 42.325005,\n       42.275   , 42.225   , 42.17501 , 42.125008, 42.075005, 42.025   ,\n       41.975   , 41.92501 , 41.875008, 41.825005, 41.775   , 41.725   ,\n       41.67501 , 41.625008, 41.575005, 41.525   , 41.475   , 41.42501 ,\n       41.375008, 41.325005, 41.275   , 41.225   , 41.17501 , 41.125008,\n       41.075005, 41.025   , 40.975   , 40.92501 , 40.875008, 40.825005,\n       40.775   , 40.725   , 40.67501 , 40.625008, 40.575005, 40.525   ,\n       40.475   , 40.42501 , 40.375008, 40.325005, 40.275   , 40.225   ,\n       40.17501 , 40.125008, 40.075005, 40.025   , 39.975   , 39.92501 ,\n       39.875008, 39.825005, 39.775   , 39.725   , 39.67501 , 39.625008,\n       39.575005, 39.525   , 39.475   , 39.42501 , 39.375008, 39.325005,\n       39.275   , 39.225   , 39.17501 , 39.125008, 39.075005, 39.025   ,\n       38.975   , 38.92501 , 38.875008, 38.825005, 38.775   , 38.725   ,\n       38.67501 , 38.625008, 38.575005, 38.525   , 38.475   , 38.42501 ,\n       38.375008, 38.325005, 38.275   , 38.225   , 38.17501 , 38.125008,\n       38.075005, 38.025   , 37.975006, 37.925003, 37.875   , 37.825005,\n       37.775   , 37.725006, 37.675003, 37.625   , 37.575005, 37.525   ,\n       37.475006, 37.425003, 37.375   , 37.325005, 37.275   , 37.225006,\n       37.175003, 37.125   , 37.075005, 37.025   , 36.975006, 36.925003,\n       36.875   , 36.825005, 36.775   , 36.725006, 36.675003, 36.625   ,\n       36.575005, 36.525   , 36.475006, 36.425003, 36.375   , 36.325005,\n       36.275   , 36.225006, 36.175003, 36.125   , 36.075005, 36.025   ,\n       35.975006, 35.925003, 35.875   , 35.825005, 35.775   , 35.725006,\n       35.675003, 35.625   , 35.575005, 35.525   , 35.475006, 35.425003,\n       35.375   , 35.325005, 35.275   , 35.225006, 35.175003, 35.125   ,\n       35.075005, 35.025   , 34.975006, 34.925003, 34.875   , 34.825005,\n       34.775   , 34.725006, 34.675003, 34.625   , 34.575005, 34.525   ,\n       34.475006, 34.425003, 34.375   , 34.325005, 34.275   , 34.225006,\n       34.175003, 34.125   , 34.075005, 34.025   , 33.975006, 33.925003,\n       33.875   , 33.825005, 33.775   , 33.725006, 33.675003, 33.625   ,\n       33.575005, 33.525   ], dtype=float32)longitude(longitude)float32-73.47 -73.42 ... -43.57 -43.53_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-73.475   , -73.424995, -73.375   , ..., -43.624992, -43.57499 ,\n       -43.525   ], dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2020-01-16 00:00:00', '2020-02-16 00:00:00',\n               '2020-03-15 23:00:00', '2020-04-15 23:00:00',\n               '2020-05-15 23:00:00', '2020-06-15 23:00:00',\n               '2020-07-15 23:00:00', '2020-08-15 23:00:00',\n               '2020-09-15 23:00:00', '2020-10-15 23:00:00',\n               '2020-11-16 00:00:00', '2020-12-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([43.474998474121094, 43.425010681152344,  43.37500762939453,\n        43.32500457763672, 43.275001525878906, 43.224998474121094,\n       43.175010681152344,  43.12500762939453,  43.07500457763672,\n       43.025001525878906,\n       ...\n       33.975006103515625,  33.92500305175781,             33.875,\n        33.82500457763672, 33.775001525878906, 33.725006103515625,\n        33.67500305175781,             33.625,  33.57500457763672,\n       33.525001525878906],\n      dtype='float32', name='latitude', length=200))longitudePandasIndexPandasIndex(Index([  -73.4749984741211,  -73.42499542236328,             -73.375,\n        -73.32499694824219,  -73.27499389648438,   -73.2249984741211,\n        -73.17499542236328,             -73.125,  -73.07499694824219,\n        -73.02499389648438,\n       ...\n       -43.974998474121094,  -43.92499542236328,  -43.87499237060547,\n       -43.824989318847656, -43.775001525878906, -43.724998474121094,\n        -43.67499542236328,  -43.62499237060547, -43.574989318847656,\n       -43.525001525878906],\n      dtype='float32', name='longitude', length=600))Attributes: (9)colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the unmasked data on a map",
    "text": "Visualize the unmasked data on a map\nThe map shows the full extent of the bounding box\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nds_subset[0].plot.pcolormesh(ax=ax1, transform=ccrs.PlateCarree(), cmap='jet')\n\nplt.title('Satellite Data Before Masking')\n\nText(0.5, 1.0, 'Satellite Data Before Masking')",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "title": "Extract data within a boundary",
    "section": "Create the region from the shape file",
    "text": "Create the region from the shape file\nThe plot shows the shape of the region and its placement along the US East Coast.\n\nregion = regionmask.from_geopandas(gulf_stream)\nregion.plot()",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Mask the satellite data",
    "text": "Mask the satellite data\n\n# Create the mask\nmask = region.mask(ds_subset.longitude, ds_subset.latitude)\n\n# Apply mask the the satellite data\nmasked_ds = ds_subset.where(mask == region.numbers[0])",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the masked data on a map",
    "text": "Visualize the masked data on a map\nThese data have been trimmed to contain only values within the Gulf Stream Province\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nmasked_ds[0].plot.pcolormesh(ax=ax1,\n                             transform=ccrs.PlateCarree(),\n                             cmap='jet')\n\nplt.title('Satellite Data After Masking for Longhurst GFST')\n\n\nText(0.5, 1.0, 'Satellite Data After Masking for Longhurst GFST')",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "title": "Extract data within a boundary",
    "section": "Plot the mean seasonal temperature for the province",
    "text": "Plot the mean seasonal temperature for the province\n\ngulf_stream_mean = masked_ds.mean(dim=['latitude', 'longitude'])\n\n\ngulf_stream_mean\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(gulf_stream_mean.time,\n              gulf_stream_mean, \n              'o', markersize=8, \n              label='gulf stream', c='black', \n              linestyle='-', linewidth=2) \n\nplt.title('Gulf Stream Province Monthly Mean Temperature 2020')\nplt.ylabel('SST(degrees C)') \nplt.legend()",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#references",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#references",
    "title": "Extract data within a boundary",
    "section": "References",
    "text": "References\nThe several CoastWatch Node websites have data catalog containing documentation and links to all the datasets available:\n* https://oceanwatch.pifsc.noaa.gov/doc.html\n* https://coastwatch.pfeg.noaa.gov/data.html\n* https://polarwatch.noaa.gov/catalog/\nSources for marine shape files * https://www.marineregions.org/downloads.php",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#summary",
    "href": "tutorials/python/1-earthaccess.html#summary",
    "title": "Data discovery with earthaccess",
    "section": "Summary",
    "text": "Summary\nIn this example we will use the earthaccess library to search for data collections from NASA Earthdata. earthaccess is a Python library that simplifies data discovery and access to NASA Earth science data by providing an abstraction layer for NASA’s Common Metadata Repository (CMR) API Search API. The library makes searching for data more approachable by using a simpler notation instead of low level HTTP queries. earthaccess takes the trouble out of Earthdata Login authentication, makes search easier, and provides a stream-line way to download or stream search results into an xarray object.\nFor more on earthaccess visit the earthaccess GitHub page and/or the earthaccess documentation site. Be aware that earthaccess is under active development.",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#prerequisites",
    "href": "tutorials/python/1-earthaccess.html#prerequisites",
    "title": "Data discovery with earthaccess",
    "section": "Prerequisites",
    "text": "Prerequisites\nAn Earthdata Login account is required to access data from NASA Earthdata. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#learning-objectives",
    "href": "tutorials/python/1-earthaccess.html#learning-objectives",
    "title": "Data discovery with earthaccess",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nHow to authenticate with earthaccess\nHow to use earthaccess to search for data using spatial and temporal filters\nHow to explore and work with search results",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#get-started",
    "href": "tutorials/python/1-earthaccess.html#get-started",
    "title": "Data discovery with earthaccess",
    "section": "Get Started",
    "text": "Get Started\n\nImport Required Packages\n\nimport earthaccess \nfrom pprint import pprint\nimport xarray as xr\nimport geopandas as gpd\n\n\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\nWe are already authenticated with NASA EDL\n\n\n\n\nSearch for data\nThere are multiple keywords we can use to discovery data from collections. The table below contains the short_name, concept_id, and doi for some collections we are interested in for other exercises. Each of these can be used to search for data or information related to the collection we are interested in.\n\n\n\nShortname\nCollection Concept ID\nDOI\n\n\n\n\nGPM_3IMERGDF\nC2723754864-GES_DISC\n10.5067/GPM/IMERGDF/DAY/07\n\n\nMOD10C1\nC1646609808-NSIDC_ECS\n10.5067/MODIS/MOD10C1.061\n\n\nSPL4SMGP\nC2531308461-NSIDC_ECS\n10.5067/EVKPQZ4AFC4D\n\n\nSPL4SMAU\nC2537927247-NSIDC_ECS\n10.5067/LWJ6TF5SZRG3\n\n\n\nBut wait…You may be asking “how can we find the shortname, concept_id, and doi for collections not in the table above?”. Let’s take a quick detour.\nhttps://search.earthdata.nasa.gov/search?q=GPM_3IMERGDF\n\nSearch by collection\n\n#collection_id = 'C2723754864-GES_DISC'\ncollection_id = 'C1598621096-GES_DISC'\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    count = 10    # Restricting to 10 records returned\n)\n\nGranules found: 7792\n\n\nIn this example we used the concept_id parameter to search from our desired collection. However, there are multiple ways to specify the collection(s) we are interested in. Alternative parameters include:\n\ndoi - request collection by digital object identifier (e.g., doi = ‘10.5067/GPM/IMERGDF/DAY/07’)\n\nshort_name - request collection by CMR shortname (e.g., short_name = ‘GPM_3IMERGDF’)\n\nNOTE: Each Earthdata collect has a unique concept_id and doi. This is not the case with short_name. A shortname can be associated with multiple versions of a collection. If multiple versions of a collection are publicaly available, using the short_name parameter with return all versions available. It is advised to use the version parameter in conjunction with the short_name parameter with searching.\nWe can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the temporal parameter to request a date range and the bounding_box parameter to request granules that intersect with a bounding box.\nFor our bounding box, we are going to read in a GeoJSON file containing a single feature and extract the coordinate pairs for the southeast corner and the northwest corner (or lowerleft and upperright corners) of the bounding box around the feature.\n\ninGeojson = gpd.read_file('../../NOAAHackDay-Dec-2023/data/sf_to_sierranvmt.geojson')\n\n\nxmin, ymin, xmax, ymax = inGeojson.total_bounds\n\nWe will assign our start date and end date to a variable named date_range and we’ll assign the southeast and the northwest corner coordinates to a variable named bbox to be passed to our earthaccess search request.\n\n#date_range = (\"2022-11-19\", \"2023-04-06\")\ndate_range = (\"2019-11-19\", \"2019-12-06\")\nbbox = (xmin, ymin, xmax, ymax)\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 18\n\n\n\nThe short_name and concept_id search parameters can be used to request one or multiple collections per request, but the doi parameter can only request a single collection.\n&gt; concept_ids = [‘C2723754864-GES_DISC’, ‘C1646609808-NSIDC_ECS’]\n\nUse the cloud_hosted search parameter only to search for data assets available from NASA’s Earthdata Cloud.\nThere are even more search parameters that can be passed to help refine our search, however those parameters do have to be populated in the CMR record to be leveraged. A non exhaustive list of examples are below:\n\nday_night_flag = 'day'\n\ncloud_cover = (0, 10)\n\n\n\n# col_ids = ['C2723754864-GES_DISC', 'C1646609808-NSIDC_ECS', 'C2531308461-NSIDC_ECS', 'C2537927247-NSIDC_ECS']    # Specify a list of collections to pass to the search\n\n# results = earthaccess.search_data(\n#     concept_id = col_ids,\n#     #cloud_hosted = True,\n#     temporal = date_range,\n#     bounding_box = bbox,\n# )\n\n\n\n\nWorking with earthaccess returns\nearthaccess provides several convenience methods to help streamline processes that historically have be painful when done using traditional methods. Following the search for data, you’ll likely take one of two pathways with those results. You may choose to download the assets that have been returned to you or you may choose to continue working with the search results within the Python environment.\n\nDownload earthaccess results\nIn some cases you may want to download your assets. earthaccess makes downloading the data from the search results very easy using the earthaccess.download() function.\n\ndownloaded_files = earthaccess.download(\n    results[0:9],\n    local_path='../../NOAAHackDay-Dec-2023/data',\n)\n\n Getting 9 granules, approx download size: 0.27 GB\n\n\n\n\n\n\n\n\n\n\n\nearthaccess did a lot of heavy lifting for us. It identified the downloadable links, passed our Earthdata Login credentials, and save off the file with the proper name. Amazing right!?\nWe’re going to remove those files to keep our space clean.\n\n!rm ../../NOAAHackDay-Dec-2023/data/*.nc4\n\n\n\nExplore earthaccess search response\n\nprint(f'The results variable is a {type(results)} of {type(results[0])}')\n\nThe results variable is a &lt;class 'list'&gt; of &lt;class 'earthaccess.results.DataGranule'&gt;\n\n\n\nlen(results)\n\n18\n\n\nWe can explore the first item (earthaccess.results.DataGranule) in our list.\n\nitem = results[0]\ntype(item)\n\nearthaccess.results.DataGranule\n\n\nEach item contains three keys that can be used to explore the item\n\nitem.keys()\n\ndict_keys(['meta', 'umm', 'size'])\n\n\n\nitem['umm']\n\n{'RelatedUrls': [{'URL': 'https://data.gesdisc.earthdata.nasa.gov/data/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'GET DATA', 'Description': 'Download 3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4'}, {'URL': 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'GET DATA VIA DIRECT ACCESS', 'Description': 'This link provides direct download access via S3 to the granule'}, {'URL': 'https://gpm1.gesdisc.eosdis.nasa.gov/opendap/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'Type': 'USE SERVICE API', 'Subtype': 'OPENDAP DATA', 'Description': 'The OPENDAP location for the granule.', 'MimeType': 'application/x-netcdf-4'}, {'URL': 'https://data.gesdisc.earthdata.nasa.gov/s3credentials', 'Type': 'VIEW RELATED INFORMATION', 'Description': 'api endpoint to retrieve temporary credentials valid for same-region direct s3 access'}], 'SpatialExtent': {'HorizontalSpatialDomain': {'Geometry': {'BoundingRectangles': [{'WestBoundingCoordinate': -180.0, 'EastBoundingCoordinate': 180.0, 'NorthBoundingCoordinate': 90.0, 'SouthBoundingCoordinate': -90.0}]}}}, 'ProviderDates': [{'Date': '2020-02-27T16:10:05.000Z', 'Type': 'Insert'}, {'Date': '2020-02-27T16:10:05.000Z', 'Type': 'Update'}], 'CollectionReference': {'ShortName': 'GPM_3IMERGDF', 'Version': '06'}, 'DataGranule': {'DayNightFlag': 'Unspecified', 'Identifiers': [{'Identifier': '3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'IdentifierType': 'ProducerGranuleId'}], 'ProductionDateTime': '2020-02-27T16:10:05.000Z', 'ArchiveAndDistributionInformation': [{'Name': 'Not provided', 'Size': 29.92357635498047, 'SizeUnit': 'MB'}]}, 'TemporalExtent': {'RangeDateTime': {'BeginningDateTime': '2019-11-19T00:00:00.000Z', 'EndingDateTime': '2019-11-19T23:59:59.999Z'}}, 'GranuleUR': 'GPM_3IMERGDF.06:3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4', 'MetadataSpecification': {'URL': 'https://cdn.earthdata.nasa.gov/umm/granule/v1.6.5', 'Name': 'UMM-G', 'Version': '1.6.5'}}\n\n\n\n\nGet data URLs / S3 URIs\nGet links to data. The data_links() method is used to return the URL(s)/data link(s) for the item. By default the method returns the HTTPS URL to download or access the item.\n\nitem.data_links()\n\n['https://data.gesdisc.earthdata.nasa.gov/data/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4']\n\n\nThe data_links() method can also be used to get the s3 URI when we want to perform direct s3 access of the data in the cloud. To get the s3 URI, pass access = 'direct' to the method.\n\nitem.data_links(access='direct')\n\n['s3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4']\n\n\nIf we want to extract all of the data links from our search results and add or save them to a list, we can.\n\ndata_link_list = []\n\nfor granule in results:\n    for asset in granule.data_links(access='direct'):\n        data_link_list.append(asset)\n        \n\n\ndata_link_list[0:9]\n\n['s3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191119-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191120-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191121-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191122-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191123-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191124-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191125-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191126-S000000-E235959.V06.nc4',\n 's3://gesdisc-cumulus-prod-protected/GPM_L3/GPM_3IMERGDF.06/2019/11/3B-DAY.MS.MRG.3IMERG.20191127-S000000-E235959.V06.nc4']\n\n\nWe can pass or read these lists of data links into libraries like xarray, rioxarray, or gdal, but earthaccess has a built-in module for easily reading these data links in.\n\n\nOpen results in xarray\nWe use earthaccess’s open() method to make a connection to and open the files from our search result.\n\nfileset = earthaccess.open(results)\n\n Opening 18 granules, approx size: 0.53 GB\n\n\n\n\n\n\n\n\n\n\n\nThen we pass the fileset object to xarray.\n\nds = xr.open_mfdataset(fileset, chunks = {})\n\nSome really cool things just happened here! Not only were we able to seamlessly stream our earthaccess search results into a xarray dataset using the open_mfdataset() (multi-file) method, but earthaccess whether we were working from within AWS us-west-2 and could use direct S3 access or if not, would use https. We didn’t have to create a session or a filesystem to authenticate and connect to the data. earthaccess did this for us using the auth object we created at the beginning of this tutorial.\nLet’s take a quick lock at our xarray dataset\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                    (time: 18, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                        (lon) float32 -179.9 -179.8 ... 179.9 179.9\n  * lat                        (lat) float32 -89.95 -89.85 ... 89.85 89.95\n  * time                       (time) object 2019-11-19 00:00:00 ... 2019-12-...\nDimensions without coordinates: nv\nData variables:\n    precipitationCal           (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt       (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt_cond  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation            (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt_cond   (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt            (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                  (time, nv) object dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes:\n    BeginDate:       2019-11-19\n    BeginTime:       00:00:00.000Z\n    EndDate:         2019-11-19\n    EndTime:         23:59:59.999Z\n    FileHeader:      StartGranuleDateTime=2019-11-19T00:00:00.000Z;\\nStopGran...\n    InputPointer:    3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B....\n    title:           GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 ...\n    DOI:             10.5067/GPM/IMERGDF/DAY/06\n    ProductionTime:  2020-02-27T16:09:48.308Zxarray.DatasetDimensions:time: 18lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.8 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95   , -179.84999, -179.75   , ...,  179.75002,  179.85002,\n        179.95   ], dtype=float32)lat(lat)float32-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95    , -89.85    , -89.75    , ...,  89.75    ,  89.850006,\n        89.95001 ], dtype=float32)time(time)object2019-11-19 00:00:00 ... 2019-12-...standard_name :timebounds :time_bndsarray([cftime.DatetimeJulian(2019, 11, 19, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 20, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 21, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 22, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 23, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 24, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 25, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 26, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 27, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 28, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 29, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 30, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 1, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 2, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 3, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 4, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 5, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 6, 0, 0, 0, 0, has_year_zero=False)],\n      dtype=object)Data variables: (9)precipitationCal(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mmlong_name :Daily accumulated precipitation (combined microwave-IR) estimate\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nprecipitationCal_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitationCal retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprecipitationCal_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly precipitationCal retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nHQprecipitation\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm\n\nlong_name :\n\nDaily accumulated High Quality precipitation from all available MW sources\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nHQprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly HQprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nHQprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly HQprecipitation retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm\n\nlong_name :\n\nDaily total error of precipitation estimate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(time, nv)\n\n\nobject\n\n\ndask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n288 B\n16 B\n\n\nShape\n(18, 2)\n(1, 2)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nobject numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.84999084472656,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.34999084472656,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.15000915527344,  179.25001525878906,\n                179.3500213623047,   179.4499969482422,   179.5500030517578,\n               179.65000915527344,  179.75001525878906,   179.8500213623047,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([-89.94999694824219,  -89.8499984741211,             -89.75,\n              -89.64999389648438, -89.54999542236328, -89.44999694824219,\n               -89.3499984741211,             -89.25, -89.14999389648438,\n              -89.04999542236328,\n              ...\n               89.05000305175781,  89.15000915527344,              89.25,\n               89.35000610351562,  89.45001220703125,  89.55000305175781,\n               89.65000915527344,              89.75,  89.85000610351562,\n               89.95001220703125],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(CFTimeIndex([2019-11-19 00:00:00, 2019-11-20 00:00:00, 2019-11-21 00:00:00,\n             2019-11-22 00:00:00, 2019-11-23 00:00:00, 2019-11-24 00:00:00,\n             2019-11-25 00:00:00, 2019-11-26 00:00:00, 2019-11-27 00:00:00,\n             2019-11-28 00:00:00, 2019-11-29 00:00:00, 2019-11-30 00:00:00,\n             2019-12-01 00:00:00, 2019-12-02 00:00:00, 2019-12-03 00:00:00,\n             2019-12-04 00:00:00, 2019-12-05 00:00:00, 2019-12-06 00:00:00],\n            dtype='object', length=18, calendar='julian', freq='D'))Attributes: (9)BeginDate :2019-11-19BeginTime :00:00:00.000ZEndDate :2019-11-19EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2019-11-19T00:00:00.000Z;\nStopGranuleDateTime=2019-11-19T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S003000-E005959.0030.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S010000-E012959.0060.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S013000-E015959.0090.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S020000-E022959.0120.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S023000-E025959.0150.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S030000-E032959.0180.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S033000-E035959.0210.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S040000-E042959.0240.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S043000-E045959.0270.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S050000-E052959.0300.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S053000-E055959.0330.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S060000-E062959.0360.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S063000-E065959.0390.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S070000-E072959.0420.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S073000-E075959.0450.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S080000-E082959.0480.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S083000-E085959.0510.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S090000-E092959.0540.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S093000-E095959.0570.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S100000-E102959.0600.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S103000-E105959.0630.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S110000-E112959.0660.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S113000-E115959.0690.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S120000-E122959.0720.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S123000-E125959.0750.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S130000-E132959.0780.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S133000-E135959.0810.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S140000-E142959.0840.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S143000-E145959.0870.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S150000-E152959.0900.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S153000-E155959.0930.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S160000-E162959.0960.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S163000-E165959.0990.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S170000-E172959.1020.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S173000-E175959.1050.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S180000-E182959.1080.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S183000-E185959.1110.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S190000-E192959.1140.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S193000-E195959.1170.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S200000-E202959.1200.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S203000-E205959.1230.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S210000-E212959.1260.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S213000-E215959.1290.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S220000-E222959.1320.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S223000-E225959.1350.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S230000-E232959.1380.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S233000-E235959.1410.V06B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/06ProductionTime :2020-02-27T16:09:48.308Z",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#resources",
    "href": "tutorials/python/1-earthaccess.html#resources",
    "title": "Data discovery with earthaccess",
    "section": "Resources",
    "text": "Resources\n\nNASA’s Common Metadata Repository (CMR) API\n\nearthaccess repository\nearthaccess documentation\nEarthdata Search",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "support.html#thank-you-for-inspiration-and-content",
    "href": "support.html#thank-you-for-inspiration-and-content",
    "title": "Acknowledgements",
    "section": "Thank you for inspiration and content!",
    "text": "Thank you for inspiration and content!\nThank you to the open science community that has created software, teaching resources, and workflows that we have been able to build off of and be inspired by. These include: NASA Openscapes • OceanHackWeek • SnowEx Hackweek • eScience Institute, University of Washington • ICESat-2 Hackweek • Project Jupyter • Pangeo Project • CryoCloud"
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "11-22 September 2023"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "",
    "text": "Welcome to the NOAA Fisheries workshop focused on geospatial analysis using ocean ‘big data’. Today, we are focused on using data from NASA EarthData but the skills you will learn are transferable to other ways that you might get earth data, e.g. NESDIS, NCEI, ERDDAP servers, Copernicus, etc.\nThis session will also introduce to working with JupyterHubs. We will use both Jupyter Lab (Python) and RStudio (R) within our JupyterHub. Go to set-up for the basic orientation and how to get on the JupyterHub.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#topics-for-may-15-2024",
    "href": "index.html#topics-for-may-15-2024",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "Topics for May 15, 2024",
    "text": "Topics for May 15, 2024\n\nIntroduction to working with earth data in the cloud and NASA Earth Data\nOrientation on our JupyterHub\nTutorial 1: Searching for resources in NASA Earth Data\nTutorial 2: Points and shapefiles\nTutorial 3: Subsetting your earth data with in a region (shapefile)\nTutorial 4: Getting values at points (along a track or transect)",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "Resources",
    "text": "Resources\n\nCoastWatch GitHub organization for many more training modules for working with satellite data in Python and R\nNASA EarthData Cloudbook for many tutorials on using satellite data in Python and R and NASA Earth Data",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#thank-you-for-inspiration-and-content",
    "href": "index.html#thank-you-for-inspiration-and-content",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "Thank you for inspiration and content!",
    "text": "Thank you for inspiration and content!\nThank you to the open science community that has created software, teaching resources, and workflows that we have been able to build off of and be inspired by. These include: NASA Openscapes • OceanHackWeek • SnowEx Hackweek • eScience Institute, University of Washington • ICESat-2 Hackweek • Project Jupyter • Pangeo Project • CryoCloud",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "content/notebooks.html#summary",
    "href": "content/notebooks.html#summary",
    "title": "RMarkdown, R, Git",
    "section": "Summary",
    "text": "Summary\nIn this session, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nVersion Control (code management using git)\nProgramming in Python (using Jupyter Notebook)\nGeospatial Fundamentals (optional, self-study)\n\nYou will need a working knowledge of git and terminal for this hackathon. We will provide an overview of these topics and also share resources for self-paced learning."
  },
  {
    "objectID": "content/notebooks.html#introduction-command-line-terminalshell",
    "href": "content/notebooks.html#introduction-command-line-terminalshell",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Command Line (Terminal/Shell)",
    "text": "Introduction :: Command Line (Terminal/Shell)\n\nShell Basics\n\nWhat is Terminal or Shell?\nNavigating Files and Directories\nWorking with Files and Directories\n\n\n\nShell: More Details\nDetailed self-paced lesson on shell: Shell Lesson from Software Carpentry"
  },
  {
    "objectID": "content/notebooks.html#introduction-version-control-git-and-github",
    "href": "content/notebooks.html#introduction-version-control-git-and-github",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Version Control (Git and Github)",
    "text": "Introduction :: Version Control (Git and Github)\n\nWhat is version control, git, github, and how to set it up?\nVersion control is managing and tracking changes to your documents (program source code, images, websites, data files, etc.). git is a popular tool used for version control of software code. github.com is popular platform that provides remote server hosting for git repositories. A repository is a collection of various files that you are tracking for changes and versions (think of it as a directory with files that are being tracked for changes, using git for taking snapshots of versions as you are developing).\nThis section is a step-by-step guide to set up git on your 2i2c JupyterHub instance (referred to as 2i2c JupyterHub in these instruction). We will also configure git to use your github.com account for managing your repositories hosted on github.com. There are 5 main steps with substeps, includes instruction for addressing github’s new approach for token authentication.\n\n\nStep 1: Create a github account\nTo complete the setup, you will need an account on github.com. If you don’t have an account, please visit github.com, create an account (free) and come back to this guide for setting up git.\n\n\nStep 2: Fork a repository\nA fork is a copy of a repository from another github account (for example NASA-Openscapes account) to your github account (for example, my account virdi) that then you have permission to edit. To help you finish this setup correctly, we have created a demo repository on Openscapes github account named check_github_setup. You can fork this repository into your github account following these steps:\n\nLog in to your github.com account\nGo to the demo repository at NASA-Openscapes github\n\n\n\nDemo repository on NASA-Openscapes github\n\n\nClick on the fork icon in the top right corner, as shown in the image below and click your user name if prompted to do so\n\n\n\n\nStep 3: Clone the repository that you just forked\nNow you have a fork of the demo repository in your github account that we can clone it in your 2i2c instance. In the code below, commands beginning with git is a git command for version control and synching; commands that don’t start with git are bash/linux/command line commands.\n\nStart your 2i2c JupyterHub and open a terminal\nFile &gt;&gt; New &gt;&gt; Terminal\nMake sure you are in your home directory by usingpwd command and verifying the output as below\n/home/jovyan\n\nConfigure git with your name and email address.\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\nNote: This name and email could be different from your github.com credentials. Remember git is a program that keeps track of your changes locally (on 2i2c JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by git, the email/name used in git configuration will show up next to your contributions on github.com when you push your repository to github.com (git push is discussed in a later step).\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git Jupyter lab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "content/notebooks.html#introduction-programming-in-python",
    "href": "content/notebooks.html#introduction-programming-in-python",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python"
  },
  {
    "objectID": "content/notebooks.html#introduction-programming-in-python-1",
    "href": "content/notebooks.html#introduction-programming-in-python-1",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python\nSwitch to Jupyter Notebook for an introduction to programming in Python\n\nVariables (and mathematical operations)\nData Structures (list, tuple, dict)\nFlow Control using loops (for, while)\nConditionals (if, else, elif)\nFunctions\nErrors and Exceptions (understanding and handling errors)\nUsing modules (libraries, packages)\n\npandas: high-performance, easy-to-use data structures and data analysis tools\nrioxarray: based on the rasterio package for working with rasters and xarray\n\n\n\nPython Learning Resources\nSelf-paced lesson on Programming with Python from Software Carpentry"
  },
  {
    "objectID": "content/notebooks.html#introduction-geospatial-fundamentals-optional",
    "href": "content/notebooks.html#introduction-geospatial-fundamentals-optional",
    "title": "RMarkdown, R, Git",
    "section": "Introduction :: Geospatial Fundamentals (Optional)",
    "text": "Introduction :: Geospatial Fundamentals (Optional)\nDetailed self-paced lesson on Fundamentals of Geospatial Raster and Vector Data with Python from Data Carpentry\nThe end!"
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Week 1 Tutorials",
    "section": "",
    "text": "During week 1, participants will gain experience with the platforms used in collaborative science: GitHub and RMarkdown."
  },
  {
    "objectID": "content/index.html#prerequisites",
    "href": "content/index.html#prerequisites",
    "title": "Week 1 Tutorials",
    "section": "Prerequisites",
    "text": "Prerequisites\nPlease follow the set up prerequisites"
  },
  {
    "objectID": "content/index.html#content",
    "href": "content/index.html#content",
    "title": "Week 1 Tutorials",
    "section": "Content",
    "text": "Content\n\nThe R language and RStudio\nIntro to RStudio\nIntroduction to Git and GitHub"
  },
  {
    "objectID": "content/earthdata.html#overview",
    "href": "content/earthdata.html#overview",
    "title": "Earthdata Login",
    "section": "Overview",
    "text": "Overview"
  },
  {
    "objectID": "content/earthdata.html#why-do-i-need-an-earthdata-login",
    "href": "content/earthdata.html#why-do-i-need-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "Why do I need an Earthdata login?",
    "text": "Why do I need an Earthdata login?\nWe will be teaching you ways to programmatically access NASA remote-sensing data from within your scripts. You will need to enter your Earthdata username and password in order for this to work."
  },
  {
    "objectID": "content/earthdata.html#getting-an-earthdata-login",
    "href": "content/earthdata.html#getting-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "Getting an Earthdata login",
    "text": "Getting an Earthdata login\nIf you do not already have an Earthdata login, then navigate to the Earthdata Login page, a username and password, and then record this somewhere for use during the tutorials:"
  },
  {
    "objectID": "content/earthdata.html#configure-programmatic-access-to-nasa-servers",
    "href": "content/earthdata.html#configure-programmatic-access-to-nasa-servers",
    "title": "Earthdata Login",
    "section": "Configure programmatic access to NASA servers",
    "text": "Configure programmatic access to NASA servers\nIf you use web interfaces to retrieve nasa data such as Earthdata Search you are prompted to login. We will be using software to retrieve data from NASA Servers during the hackweek, so you must store your credentials on the JupyterHub. Run the following commands on the JupyterHub in a terminal replacing your Earthdata login username and password:\necho \"machine urs.earthdata.nasa.gov login EARTHDATA_LOGIN password EARTHDATA_PASSWORD\" &gt; ~/.netrc\nchmod 0600 .netrc"
  },
  {
    "objectID": "content/04-intro-sdm.html#big-picture",
    "href": "content/04-intro-sdm.html#big-picture",
    "title": "Intro to SDM",
    "section": "Big Picture",
    "text": "Big Picture\nIn the broader context, our goal is to uncover where species are likely to be found, not just for their protection but also to strategically plan conservation efforts and to help manage fisheries. We aim to discover where these species are located and anticipate how their habitats might shift in the future.\nBut handling all this data manually is virtually impossible. It’s like trying to piece together a complex puzzle with millions of tiny pieces.\nSpecies Distribution Modeling (SDM) combined with big data analytics comes into play. SDM helps us make sense of this vast environmental data. We can extract meaningful patterns and relationships between the environment and species distribution."
  },
  {
    "objectID": "content/04-intro-sdm.html#nasa-arset",
    "href": "content/04-intro-sdm.html#nasa-arset",
    "title": "Intro to SDM",
    "section": "NASA ARSET",
    "text": "NASA ARSET\nI am going to be showing some slides from NASA ARSET’ Training Course on Species Distribution Modeling (here. This is a 4.5 hour webinar focusing on an R package called Wallace, which I won’t be talking about as it is more focused on land SDMs. But the first lecture gives a good general overview of SDMs.\nMcCullum, A.; Torres-Pérez, J.; Bengtsson, Z.; Johnson, E.; Paz Velez, A.; Blair, M. (2021). Species Distribution Modeling with Remote Sensing. NASA Applied Remote Sensing Training Program (ARSET). https://appliedsciences.nasa.gov/join-mission/training/english/arset-species-distribution-modeling-remote-sensing\nNASA ARSET is the NASA Applied Remote Sensing Training (ARSET) Program and they have virtual and on-line trainings for using remote-sensing data. Their Fundamentals of Remote Sensing Course is a good overview."
  },
  {
    "objectID": "content/04-intro-sdm.html#slides",
    "href": "content/04-intro-sdm.html#slides",
    "title": "Intro to SDM",
    "section": "Slides",
    "text": "Slides"
  },
  {
    "objectID": "content/03-ai.html",
    "href": "content/03-ai.html",
    "title": "AI Assisted Programming",
    "section": "",
    "text": "2023 has seen an dramatic shift toward a new workflow for programming and learning to program: AI-Assisted Programming. Using AI as your personal coding buddy and coach is the new way to work. But you need to learn how to interact with your AI helper and ask it questions.\nWe are going to watch a presentation given by Myranda Shirk, Senior Data Scientist, Vanderbilt University, Knoxville, US. This presentation was given at OceanHackWeek 2023 at the University of Washington in August 2023. Myranda will give you an overview of the current AI platforms and then demo how to interact with them. During this hackweek, you get a lot of practice with AI assisted programming and AI assisted brainstorming.\nOne important thing to note is that the chatGPT tool that Myranda used (code interpreter) is now called Advanced Data Analytics.\nVideo: https://youtu.be/JCHa-yGgtr4?si=WV956qZkSEVvy-CQ\nLecture Notes: https://oceanhackweek.org/ohw23/tutorials/02-Wed/ai_assisted_programming_ohw.html"
  },
  {
    "objectID": "content/02-quarto.html",
    "href": "content/02-quarto.html",
    "title": "Intro to Quarto",
    "section": "",
    "text": "Quarto was announced at the 2022 RStudio Conference in this great keynote talk: Mine Çetinkaya-Rundel & Julia Stewart Lowndes | Hello Quarto. I am going to start by showing you 2 clips from this keynote."
  },
  {
    "objectID": "content/02-quarto.html#what-does-quarto-and-rmarkdown-do",
    "href": "content/02-quarto.html#what-does-quarto-and-rmarkdown-do",
    "title": "Intro to Quarto",
    "section": "What does Quarto (and RMarkdown) do?",
    "text": "What does Quarto (and RMarkdown) do?\n\nQuarto is bundled and comes pre-installed with RStudio v2022.07.1 and beyond!"
  },
  {
    "objectID": "content/02-quarto.html#lets-learn-by-creating",
    "href": "content/02-quarto.html#lets-learn-by-creating",
    "title": "Intro to Quarto",
    "section": "Let’s learn by creating!",
    "text": "Let’s learn by creating!\n\nOpen up the JupyterHub and navigate to RStudio.\nPlan B. You can open up RStudio on your laptop.\n\n\nCreate a basic Quarto document\nFile &gt; New File &gt; Quarto document\n\n\nCreate a basic Quarto presentation\nFile &gt; New File &gt; Quarto presentation\n\n\nCreate a basic Quarto book\nFile &gt; New Project &gt; Quarto book\n\n\nMake a bit more fancy Quarto book\nActivity for advanced R/GitHub users\n\nGo here https://github.com/nmfs-opensci/NOAA-quarto-book\nClick the “Use this template” button and make copy in your GitHub account and give it a different name. Make sure to click the checkbox to copy all branches. Change owner to your account. \nCopy YOUR repo URL. It’ll look like https://github.com/yourusername/my-quarto-book\nFile &gt; New Project &gt; Version Control and paste in your URL\nClick Create and then you can click the Build tab and render the book.\nMake some changes and push back to GitHub.\nTurn on GitHub Pages via Settings &gt; Pages and selecting the gh-pages branch. \nYour book will automatically be published to the web."
  },
  {
    "objectID": "content/02-quarto.html#intro-to-quarto-workshops",
    "href": "content/02-quarto.html#intro-to-quarto-workshops",
    "title": "Intro to Quarto",
    "section": "Intro to Quarto Workshops",
    "text": "Intro to Quarto Workshops\nThomas Mocke (Posit) has great videos on Quarto. I am using material from a 2-hour online workshop.\n\nContent\nVideo\nGitHub repo\n\nHe also gave a 2-day workshop if you want to learn Quarto indepth.\n\n2 day workshop\n\nMore workshop that you can watch and join on Posit YouTube"
  },
  {
    "objectID": "content/02-git-jupyter.html#summary",
    "href": "content/02-git-jupyter.html#summary",
    "title": "Git - Jupyter Lab",
    "section": "Summary",
    "text": "Summary\nIn this tutorial, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nNavigating around folders in Jupyter Lab\nVersion Control (code management using git)\nSetting up Git in Jupyter Lab\nThe Git GUI in Jupyter Lab\nBasic Git commands"
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-jupyter-lab",
    "href": "content/02-git-jupyter.html#introduction-jupyter-lab",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Jupyter Lab",
    "text": "Introduction :: Jupyter Lab\nWhen you start the JupyterHub, you will be in Jupyter Lab. From there you can click on the RStudio box and open RStudio. However for this tutorial, we will stay in Juptyer Lab."
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-terminalshell",
    "href": "content/02-git-jupyter.html#introduction-terminalshell",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Terminal/Shell",
    "text": "Introduction :: Terminal/Shell\nLog into the JupyterHub. If you do not see this\n\nThen go to File &gt; New Launcher\nClick on the “Terminal” box to open a new terminal window.\n\nShell or Terminal Basics\n\nWhat is Terminal or Shell?\nNavigating Files and Directories\nWorking with Files and Directories\nOptional: Detailed self-paced lesson on running scripts from the shell: Shell Lesson from Software Carpentry\n\nYou will need only basic navigation skills for this course: cd, ls and cat\n\npwd where am I\ncd nameofdir move into a directory\ncd .. move up a directory\nls list the files in the current directory\nls -a list the files including hidden files\nls -l list the files with more info\ncat filename print out the contents of a file\n\n\n\nLet’s try\nls\nls -a\ncd shared\nls\ncd shell-tutorial\ncat lesson1.sh\ncd ..\ncd ..\n\n\nClose the terminal\nJust click on the X in the terminal tab"
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-file-navigation",
    "href": "content/02-git-jupyter.html#introduction-file-navigation",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: File Navigation",
    "text": "Introduction :: File Navigation\nIn the far left, you will see a line of icons. The top one is a folder and allows us to move around our file system.\n\nClick on shared. Now you can see the files in the shared directory.\nClick on shell-tutorial. Then click on lesson1.sh. The file opens. You won’t be able to save changes here because you don’t have write permission on this drive.\nClick on the folder icon that looks like this. Click on the actual folder image. \nNow it should look like this folder /\nThis shows me doing this\n\nCreate a new folder.\n\nNext to the blue rectange with a +, is a grey folder with a +. Click that to create a new folder, called lesson-scripts.\nThen click on lesson-scripts to enter the folder\n\n\nCreate a new file\n\nCreate with File &gt; New &gt; Text file\nThe file will open and you can edit it.\nSave with File &gt; Save Text\nDelete the file by right-clicking on it and clicking “Delete”"
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-version-control-git",
    "href": "content/02-git-jupyter.html#introduction-version-control-git",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Version Control (Git)",
    "text": "Introduction :: Version Control (Git)\n\nWhat is version control, git, github, and how to set it up?\nVersion control is managing and tracking changes to your documents (program source code, images, websites, data files, etc.). git is a popular tool used for version control of software code. github.com is popular platform that provides remote server hosting for git repositories. A repository is a collection of various files that you are tracking for changes and versions. Currently GitHub is the most popular platform for file sharing code and code packages.\nThis section is a step-by-step guide to set up git on our JupyterHub. We will also configure git to use your github.com account for managing your repositories hosted on github.com. There are 5 main steps.\n\n\nStep 1: Create a GitHub account\nTo complete the setup, you will need an account on github.com. If you don’t have an account, please visit github.com, create an account (free) and come back to this guide for setting up git.\n\n\nStep 2: Clone a repository\nWe have created a demo repository for you to clone:\nhttps://github.com/nmfs-opensci/Git-Lesson\n\nStart your JupyterHub\nClick on the Git icon\n\n\n\nClick “Clone a Repository”\nWhere it says “Enter the URI of the remote Git repository”, paste in the URL https://github.com/nmfs-opensci/Git-Lesson\nThe folder appears and you can enter the folder and edit and create files.\n\n\nYour task: Create a file with your name and save to the Git-Lesson folder"
  },
  {
    "objectID": "content/02-git-jupyter.html#step-3",
    "href": "content/02-git-jupyter.html#step-3",
    "title": "Git - Jupyter Lab",
    "section": "Step 3:",
    "text": "Step 3:\nConfigure git with your name and email address.\n``` bash\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\n```\n\n**Note:** This name and email could be different from your github.com credentials. Remember `git` is a program that keeps track of your changes locally (on the JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by `git`, the email/name used in git configuration will show up next to your contributions on github.com when you `push` your repository to github.com (`git push` is discussed in a later step).\n\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git Jupyter lab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#log-into-the-jupyterhub",
    "href": "content/01-intro-to-jupyterhub.html#log-into-the-jupyterhub",
    "title": "Intro to JupyterHubs",
    "section": "Log into the JupyterHub",
    "text": "Log into the JupyterHub\nGo to https://dhub.opensci.live/. Click “Login to continue”. You will be asked to log in with your GitHub Account, if you are not logged in already.\n\nImage type: Python or R\nNext you select your image type. We have two different R images and two Python images. The images have geospatial libraries pre-loaded.\n\n\nVirtual Machine size\nYou’ll see something similar to this that allows you to choose a large virtual machine if your project needs it. For the tutorials, you will only need the Small Virtual Machine. Please only choose the large machines if you run out of RAM as the larger machines cost us more.\n\n\n\nMachine Profiles\n\n\n\n\nStart up\nAfter we select our server type and click on start, JupyterHub will allocate our instance using Amazon Web Services (AWS). This may take several minutes.\n\n\n\nJupyterhub Spawning",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#open-rstudio",
    "href": "content/01-intro-to-jupyterhub.html#open-rstudio",
    "title": "Intro to JupyterHubs",
    "section": "Open RStudio",
    "text": "Open RStudio\nWhen you are in the Jupyter Lab tab (note the Jupyter Logo), you will see a Launcher page. If you don’t see this, go to File &gt; New Launcher.\n\n\n\nJupyterhub Launcher\n\n\n\nOpen RStudio by clicking on the “RStudio” box in the Launcher tab:\n\n We will be mainly using RStudio in this course.",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#end-your-session",
    "href": "content/01-intro-to-jupyterhub.html#end-your-session",
    "title": "Intro to JupyterHubs",
    "section": "End your session",
    "text": "End your session\nWhen you are finished working for the day it is important to log out of the JupyterHub. When you keep a session active it uses up AWS resources (costs money) and keeps a series of virtual machines deployed.\n\n\n\n\n\n\nCaution\n\n\n\nYou log out from the Jupyter Lab tab not the RStudio tab.\n\n\nFrom the Jupyter Lab tab, do one of two things to stop the server:\n\nLog out File -&gt; Log Out and click “Log Out”!\nor File -&gt; Hub Control Panel -&gt; Stop My Server\n\n\n\n\n\n\n\nTip\n\n\n\nCan’t find the Jupyter Lab tab? Go to https://dhub.opensci.live/hub/home",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#restart-your-server",
    "href": "content/01-intro-to-jupyterhub.html#restart-your-server",
    "title": "Intro to JupyterHubs",
    "section": "Restart your server",
    "text": "Restart your server\nSometimes the server will crash/stop. This can happen if too many people use a lot of memory all at once. If that happens, go to the Jupyter Lab tab and then File -&gt; Hub Control Panel -&gt; Stop My Server and then Start My Server. You shouldn’t lose your work unless you were uploading a file.",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#your-files",
    "href": "content/01-intro-to-jupyterhub.html#your-files",
    "title": "Intro to JupyterHubs",
    "section": "Your files",
    "text": "Your files\nWhen you start your server, you will have access to your own virtual drive space. No other users will be able to see or access your files. You can upload files to your virtual drive space and save files here. You can create folders to organize your files. You personal directory is home/jovyan. Everyone has the same home directory but your files are separate and cannot be seen by others.\nThere are a number of different ways to create new files. We will practice this in the RStudio lecture.\n\nWill I lose all of my work?\nLogging out will NOT cause any of your work to be lost or deleted. It simply shuts down some resources. It would be equivalent to turning off your desktop computer at the end of the day.",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#shared-files",
    "href": "content/01-intro-to-jupyterhub.html#shared-files",
    "title": "Intro to JupyterHubs",
    "section": "Shared files",
    "text": "Shared files\n\n\n\nShared folder\n\n\nIn the file panel, you will see a folder called shared. These are read-only shared files. There are two main folders:\n\ndata The folder with data files\n2023-Hackbook The full Git repository with this website\n\nYou will also see shared-public. This is a read-write folder for you to put files for everyone to see and use. You can create a team folder here for shared data and files. Note, everyone can see and change these so be careful to communicate with your team so multiple people don’t work on the same file at the same time. You can also create folders for each team member and agree not to change other team members files.\nYou will also see other folders of Python content for the Python users. We will have a separate introduction to Jupyter Notebooks.",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#python-users",
    "href": "content/01-intro-to-jupyterhub.html#python-users",
    "title": "Intro to JupyterHubs",
    "section": "**Python users",
    "text": "**Python users\nYou can open a Jupyter Notebook by clicking on the “Python 3” box. In the Launcher tab:\n\n\n\nJupyterhub Launcher\n\n\nJupyter notebooks are a very common way to share Python code and tutorials. Because we are focusing on R in this course, we will not use Jupyter notebooks much but we have many Juptyer notebooks that you can experiment with in the python-tutorials folder. Get an overview of Jupyter Lab: Intro to Jupyter Lab Learn about the geosciences tools in Python\nNote: Python users can run Python in RStudio and R users can run R in Jupyter Notebooks.",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#faq",
    "href": "content/01-intro-to-jupyterhub.html#faq",
    "title": "Intro to JupyterHubs",
    "section": "FAQ",
    "text": "FAQ\nWhy do we have the same home directory as /home/jovyan? /home/jovyan is the default home directory for ‘jupyter’ based images/dockers. It is the historic home directory for Jupyter deployments.\nCan other users see the files in my /home/jovyan folder? No, other users can not see your credentials.\n\nAcknowledgements\nSome sections of this document have been taken from hackweeks organized by the University of Washington eScience Institute and Openscapes.",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "coc.html",
    "href": "coc.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We are dedicated to providing a harassment-free learning experience for everyone regardless of gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age or religion. We do not tolerate harassment of participants in any form. Sexual language and imagery is not appropriate either in-person or virtual form, including the Discussion boards and Slack workspace. Participants (including event volunteers and organizers) violating these rules may be sanctioned or expelled from the event at the discretion of the organizers.",
    "crumbs": [
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#definition-of-harassment",
    "href": "coc.html#definition-of-harassment",
    "title": "Code of Conduct",
    "section": "Definition of Harassment",
    "text": "Definition of Harassment\nHarassment includes, but is not limited to:\n\nVerbal comments that reinforce social structures of domination related to gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age, religion.\nSexual images in public spaces\nDeliberate intimidation, stalking, or following\nHarassing photography or recording\nSustained disruption of talks or other events\nInappropriate physical contact\nUnwelcome sexual attention\nAdvocating for, or encouraging, any of the above behavior",
    "crumbs": [
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#expectations",
    "href": "coc.html#expectations",
    "title": "Code of Conduct",
    "section": "Expectations",
    "text": "Expectations\nParticipants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, the organizers retain the right to take any actions to keep the event a welcoming environment for all participants. This includes warning the offender or expulsion from the event.\nThe organizers may take action to redress anything designed to, or with the clear impact of, disrupting the event or making the environment hostile for any participants. We expect participants to follow these rules at all the event venues and event-related social activities.",
    "crumbs": [
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#reporting-a-violation",
    "href": "coc.html#reporting-a-violation",
    "title": "Code of Conduct",
    "section": "Reporting a violation",
    "text": "Reporting a violation\nHarassment and other code of conduct violations reduce the value of the event for everyone. If someone makes you or anyone else feel unsafe or unwelcome, please report it as soon as possible.\nIf you feel comfortable contacting someone associated with our event, you may speak with one of the event organizers in person or contact an organizer on a private Slack channel.",
    "crumbs": [
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "cloud-paradigm.html",
    "href": "cloud-paradigm.html",
    "title": "Cloud Paradigm",
    "section": "",
    "text": "Slides that introduce NASA Earthdata Cloud & the Cloud Paradigm."
  },
  {
    "objectID": "content/01-intro-to-cloud.html",
    "href": "content/01-intro-to-cloud.html",
    "title": "Intro the Cloud",
    "section": "",
    "text": "::: {.callout-note icon=false}\nLecture on NASA earth data in the cloud by Michele Thornton (NASA Openscapes) Video",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Geoscience cloud tools"
    ]
  },
  {
    "objectID": "content/01-welcome.html",
    "href": "content/01-welcome.html",
    "title": "Welcome",
    "section": "",
    "text": "Introduction to working with earth data in the cloud and NASA Earth Data\nOrientation on our JupyterHub\nTutorial 1: Searching for resources in NASA Earth Data\nTutorial 2: Points and shapefiles\nTutorial 3: Subsetting your earth data with in a region (shapefile)\nTutorial 4: Getting values at points (along a track or transect)",
    "crumbs": [
      "Tutorials",
      "Welcome",
      "Welcome"
    ]
  },
  {
    "objectID": "content/02-github-2.html#import-a-github-repository",
    "href": "content/02-github-2.html#import-a-github-repository",
    "title": "GitHub - Lecture 2",
    "section": "Import a GitHub repository",
    "text": "Import a GitHub repository\n\nIn your browser, navigate to https://github.com/nmfs-opensci/Quarto-Website\nCopy the URL\nClick on the “+” in the top right (on GitHub) and select “import repository”\nFollow instructions to import to your GitHub account\nNow you have your OWN copy of Quarto-Website\nCopy the URL for your OWN copy. It will look like this\n\nhttps://github.com/yourgithubusername/Quarto-Website"
  },
  {
    "objectID": "content/02-github-2.html#clone-a-github-repository-into-rstudio",
    "href": "content/02-github-2.html#clone-a-github-repository-into-rstudio",
    "title": "GitHub - Lecture 2",
    "section": "Clone a GitHub repository into RStudio",
    "text": "Clone a GitHub repository into RStudio\n\nLogin to the JupyterHub. You might have to wait awhile for the page to load.\nClick on the RStudio button when the Launcher appears \nClick on the tab that opens with the R in a circle. You should see this \nClick File &gt; New Project &gt; Version Control &gt; Git\nPaste the URL into the box\nClick “Create Project”\nThe project is created and the Git tab appears in the upper right panel.\n\nCongratulations! You pulled changes from GitHub into the JupyterHub!"
  },
  {
    "objectID": "content/02-github-2.html#lets-explore-the-files",
    "href": "content/02-github-2.html#lets-explore-the-files",
    "title": "GitHub - Lecture 2",
    "section": "Let’s explore the files",
    "text": "Let’s explore the files\n\nThis happens to be a website. Let’s build it using the Build tab in the upper right panel.\nClick “Render Website”. The website should build and appear.\n\n\nIf it doesn’t open automatically, go to docs &gt; index.html, right click and open that in a browser.\n\n\nOpen the about.qmd file. Let’s edit that! You can use the “Source” or “Visual” editor.\nWhen you have made some edits, click “Render” to see how it looks.\nYou can also click Build &gt; Render Website to re-create the whole website."
  },
  {
    "objectID": "content/02-github-2.html#set-up-authentication",
    "href": "content/02-github-2.html#set-up-authentication",
    "title": "GitHub - Lecture 2",
    "section": "Set up authentication",
    "text": "Set up authentication\nYou need to tell GitHub who you are so you can push your local changes up to GitHub. There are a few ways to do this. I am going to show you a way that works on any computer, including a virtual computer like the JupyterHub.\n\nStep 1: Generate a Personal Access Token\nWe are going to generate a classic token.\n\nGo to https://github.com/settings/tokens\nClick Generate new token &gt; Generate new token (classic)\nWhen the pop-up shows up, fill in a description, click the “repo” checkbox, and then scroll to bottom to click “Generate”.\nSAVE the token. You need it for the next step.\n\n\n\nStep 2: Tell Git who your are\n\nReturn to RStudio\nClick the terminal tab in the bottom right panel\nPaste these 3 lines of code into the terminal\n\ngit config --global user.email \"&lt;your email&gt;\"\ngit config --global user.name \"&lt;your name&gt;\"\ngit config --global pull.rebase false\ngit config --global credential.helper store\n\n\nStep 3: Push changes up to GitHub\n\nClick the Git tab (upper right panel)\nClick the checkboxes next to what changes you want to push\nClick “Commit”\nFill out a comment and click “Commit”\nClose the pop-ups\nClick Push\n\nFull instructions with ways to do this from R"
  },
  {
    "objectID": "content/02-github-2.html#optional-make-your-website-live",
    "href": "content/02-github-2.html#optional-make-your-website-live",
    "title": "GitHub - Lecture 2",
    "section": "Optional: Make your website live!",
    "text": "Optional: Make your website live!\nFor those who get through all the steps and want to play around more.\n\nGo to your Quarto Website repository on Github\nGo to Settings &gt; Pages (in left navbar)\nYou need to select the branch and the folder where the webpage files are. In this case, they are in docs \nThe URL where your website will appear is shown.\n\nHave you noticed that people have personal websites at username.github.io? How did they do that? If you create a repo named username.github.io in GitHub, it will automatically appear with that URL. Look for a repo with that name in someone’s GitHub account if you see that they use that as their personal website."
  },
  {
    "objectID": "content/02-rstudio.html#open-rstudio-in-the-jupyterhub",
    "href": "content/02-rstudio.html#open-rstudio-in-the-jupyterhub",
    "title": "RStudio - R",
    "section": "Open RStudio in the JupyterHub",
    "text": "Open RStudio in the JupyterHub\n\nLogin the JupyterHub\nClick on the RStudio button when the Launcher appears \nLook for the browser tab with the RStudio icon"
  },
  {
    "objectID": "content/02-rstudio.html#basic-navigation",
    "href": "content/02-rstudio.html#basic-navigation",
    "title": "RStudio - R",
    "section": "Basic Navigation",
    "text": "Basic Navigation\n\n\n\nRStudio Panels"
  },
  {
    "objectID": "content/02-rstudio.html#create-an-rstudio-project",
    "href": "content/02-rstudio.html#create-an-rstudio-project",
    "title": "RStudio - R",
    "section": "Create an RStudio project",
    "text": "Create an RStudio project\n\nOpen RStudio\nIn the file panel, click on the Home icon to make sure you are in your home directory\nFrom the file panel, click “New Project” to create a new project\nIn the pop up, select New Directory and then New Project\nName it sandbox\nClick on the dropdown in the upper right corner to select your sandbox project\nClick on Tools &gt; Project Options &gt; General and change the first 2 options about saving and restoring the workspace to “No”"
  },
  {
    "objectID": "content/02-rstudio.html#installing-packages",
    "href": "content/02-rstudio.html#installing-packages",
    "title": "RStudio - R",
    "section": "Installing packages",
    "text": "Installing packages\nIn the bottom right panel, select the Packages tab, click install and then start typing the name of the package. Then click Install.\nThe JupyterHub comes with many packages already installed so you shouldn’t have to install many packages.\nWhen you want to use a package, you first need to load it with\nlibrary(hello)\nYou will see this in the tutorials. You might also see something like\nhello::thefunction()\nThis is using thefunction() from the hello package.\n\n\n\n\n\n\nNote\n\n\n\nPython users. In R, you will always call a function like funtion(object) and never like object.function(). The exception is something called ‘piping’ in R, which I have never seen in Python. In this case you pass objects left to right. Like object %&gt;% function(). Piping is very common in modern R but you won’t see it much in R from 10 years ago."
  },
  {
    "objectID": "content/02-rstudio.html#uploading-and-downloading-files",
    "href": "content/02-rstudio.html#uploading-and-downloading-files",
    "title": "RStudio - R",
    "section": "Uploading and downloading files",
    "text": "Uploading and downloading files\nNote, Upload and download is only for the JupyterHub not on RStudio on your computer.\n\nUploading is easy.\nLook for the Upload button in the Files tab of the bottom right panel.\n\n\nDownload is less intuitive.\n\nClick the checkbox next to the file you want to download. One only.\nClick the “cog” icon in the Files tab of the bottom right panel. Then click Export."
  },
  {
    "objectID": "content/02-rstudio.html#creating-files",
    "href": "content/02-rstudio.html#creating-files",
    "title": "RStudio - R",
    "section": "Creating files",
    "text": "Creating files\nWhen you start your server, you will have access to your own virtual drive space. No other users will be able to see or access your files. You can upload files to your virtual drive space and save files here. You can create folders to organize your files. You personal directory is home/rstudio. Everyone has the same home directory but your files are separate and cannot be seen by others.\nPython users: If you open a Python image instead of the R image, your home is home/jovyan.\nThere are a number of different ways to create new files. Let’s practice making new files in RStudio.\n\nR Script\n\nOpen RStudio\nIn the upper right, make sure you are in your sandbox project.\nFrom the file panel, click on “New Blank File” and create a new R script.\nPaste\n\nprint(\"Hello World\")\n1+1\nin the script. 7. Click the Source button (upper left of your new script file) to run this code. 8. Try putting your cursor on one line and running that line of code by clicking “Run” 9. Try selecting lines of code and running that by clicking “Run”\n\n\ncsv file\n\nFrom the file panel, click on “New Blank File” and create a Text File.\nThe file will open in the top left corner. Paste in the following:\n\nname, place, value\nA, 1, 2\nB, 10, 20\nC, 100, 200\n\nClick the save icon (above your new file) to save your csv file\n\n\n\nA Rmarkdown document\nNow let’s create some more complicated files using the RStudio template feature.\n\nFrom the upper left, click File -&gt; New File -&gt; RMarkdown\nClick “Ok” at the bottom.\nWhen the file opens, click Knit (icon at top of file).\nIt will ask for a name. Give it one and save.\nYou file will render into html.\n\nReference sheet for writing in RMarkdown or go to Help &gt; Markdown Quick Reference\n\n\nA Rmarkdown presentation\n\nFrom the upper left, click File -&gt; New File -&gt; RMarkdown\nClick “Presentation” on left of the popup and click “Ok” at the bottom.\nWhen the file opens, click Knit (icon at top of file).\nIt will ask for a name. Give it one and save.\nYou file will render into html.\n\n\n\n(advanced) An interactive application\n\nFrom the upper left, click File -&gt; New File -&gt; Shiny Web App\nIn the popup, give the app a name and make sure the app is saved to my-files\nWhen the file opens, Run App (icon at top of file).\n\n\n\nAnd many more\nPlay around with creating other types of documents using templates. Especially if you already use RStudio."
  },
  {
    "objectID": "content/02-rstudio.html#more-tips",
    "href": "content/02-rstudio.html#more-tips",
    "title": "RStudio - R",
    "section": "More tips",
    "text": "More tips\nLearn some tips and tricks from these\n\nhttps://colorado.posit.co/rsc/the-unknown/into-the-unknown.html\nhttps://www.dataquest.io/blog/rstudio-tips-tricks-shortcuts/"
  },
  {
    "objectID": "content/02-rstudio.html#plotting-a-netcdf-file",
    "href": "content/02-rstudio.html#plotting-a-netcdf-file",
    "title": "RStudio - R",
    "section": "Plotting a netCDF file",
    "text": "Plotting a netCDF file\n\nhttps://pjbartlein.github.io/REarthSysSci/netCDF.html\nhttps://r-spatial.github.io/sf/articles/sf1.html\n\nwebpage:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg.graph?sst%5B(2023-08-27T12:00:00Z)%5D%5B(0.0)%5D%5B(-7.8):(44.8)%5D%5B(39.7):(92.3)%5D&.draw=surface&.vars=longitude%7Clatitude%7Csst&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\nurl from the dropdown on that page\nurl &lt;- https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg.nc?sst%5B(2023-08-27T12:00:00Z)%5D%5B(0.0)%5D%5B(-7.875):(44.875)%5D%5B(39.625):(92.375)%5D&.draw=surface&.vars=longitude%7Clatitude%7Csst&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\n\nOpen an R script\n\nAdd this code.\n\nlibrary(ggplot2) # package for plotting\nlibrary(sf)\nlibrary(stars)\nlibrary(dplyr)\n\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg.nc?sst%5B(2023-08-27T12:00:00Z)%5D%5B(0.0)%5D%5B(-7.875):(44.875)%5D%5B(39.625):(92.375)%5D&.draw=surface&.vars=longitude%7Clatitude%7Csst&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\"\n\nfil &lt;- \"sst.nc\"\nif(!exists(fil)){\n  download.file(url=url, destfile=fil)\n}\n\nstars_object &lt;- raster::raster(fil) %&gt;% st_as_stars()\nggplot() + geom_stars(data = stars_object)"
  },
  {
    "objectID": "content/03-git-rstudio.html#what-is-git-and-github",
    "href": "content/03-git-rstudio.html#what-is-git-and-github",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "What is Git and GitHub?",
    "text": "What is Git and GitHub?\nGit A program to track your file changes and create a history of those changes. Creates a ‘container’ for a set of files called a repository.\nGitHub A website to host these repositories and allow you to sync local copies (on your computer) to the website. Lots of functionality built on top of this."
  },
  {
    "objectID": "content/03-git-rstudio.html#some-basic-git-jargon",
    "href": "content/03-git-rstudio.html#some-basic-git-jargon",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Some basic Git jargon",
    "text": "Some basic Git jargon\n\nRepo Repository. It is your code and the record of your changes. This record and also the status of your repo is a hidden folder called .git . You have a local repo and a remote repo. The remote repo is on GitHub (for in our case) is called origin. The local repo is on the JupyterHub.\nStage Tell Git which changes you want to commit (write to the repo history).\nCommit Write a note about what change the staged files and “commit” that note to the repository record. You are also tagging this state of the repo and you could go back to this state if you wanted.\nPush Push local changes (commits) up to the remote repository on GitHub (origin).\nPull Pull changes on GitHub into the local repository on the JupyterHub.\nGit GUIs A graphical interface for Git (which is command line). Today I will use jupyterlab-git which we have installed on JupyterHub.\nShell A terminal window where we can issue git commands."
  },
  {
    "objectID": "content/03-git-rstudio.html#overview",
    "href": "content/03-git-rstudio.html#overview",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Overview",
    "text": "Overview\nToday I will cover the four basic Git/GitHub skills. The goal for today is to first get you comfortable with the basic skills and terminology. We will use what is called a “trunk-based workflow”.\n\nSimple Trunk-based Workflow:\n\nMake local (on your computer) changes to code.\nRecord what those changes were about and commit to the code change record (history).\nPush those changes to your remote repository (aka origin)\n\nWe’ll do this"
  },
  {
    "objectID": "content/03-git-rstudio.html#setting-up-git",
    "href": "content/03-git-rstudio.html#setting-up-git",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Setting up Git",
    "text": "Setting up Git\nYou should have gotten this done on Tuesday but if not here are the instructions\nBefore we can work with Git in the JupyterHub, we need to do some set up.\n\nTell Git who you are and to store your credentials (GitHub login info)\n\nShow me\nPaste this into a terminal window:\ngit config --global user.email \"&lt;your email&gt;\"\ngit config --global user.name \"&lt;your name&gt;\"\ngit config --global pull.rebase false\ngit config --global credential.helper store\n\nGet a Personal Access Token from GitHub\n\nCopy the token! You will need it in the next step.\nShow me Note, one change to this video is that you need to specify that you want a classic token.\n\nTrigger Git to ask for your password (that personal access token)\n\nYou can do this by cloning a private repo. In the Terminal, issue this command\ngit clone https://github.com/nmfs-opensci/github_setup_check\nIt will ask for your GitHub username and password. At the password part, paste in the Personal Access Token."
  },
  {
    "objectID": "content/03-git-rstudio.html#git-tab",
    "href": "content/03-git-rstudio.html#git-tab",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Git tab",
    "text": "Git tab\nWhen the instructions say to use or open or click the Git tab,"
  },
  {
    "objectID": "content/03-git-rstudio.html#the-key-skills",
    "href": "content/03-git-rstudio.html#the-key-skills",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "The Key Skills",
    "text": "The Key Skills\n\nSkill 1: Create a blank repo on GitHub\nSkill 2: Clone your GitHub repo to RStudio\nSkill 3: Make some changes and commit those local changes\nSkill 4: Push the changes to GitHub\nSkill 1b: Copy someone else’s GitHub repository"
  },
  {
    "objectID": "content/03-git-rstudio.html#lets-see-it-done",
    "href": "content/03-git-rstudio.html#lets-see-it-done",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Let’s see it done!",
    "text": "Let’s see it done!\n\nSkill 1: Create a blank repo on GitHub\n\nClick the + in the upper left from YOUR GitHub page.\nGive your repo the name Test and make sure it is public.\nClick new and check checkbox to add the Readme file and .gitignore\nCopy the URL of your new repo. It’s in the browser where you normally see a URL.\n\nShow me\n\n\nSkill 2: Clone your repo to the RStudio\nIn RStudio we do this by making a new project.\n\nCopy the URL of your repo. https://www.github.com/yourname/Test\nFile &gt; New Project &gt; Version Control &gt; Git\nPast in the URL of your repo from Step 1\nCheck that it is being created in your Home directory which will be denoted ~ in the JupyterHub.\nClick Create.\n\nShow me\n\n\nSkill 3: Make some changes and commit your changes\nThis writes a note about what changes you have made. It also marks a ‘point’ in time that you can go back to if you need to.\n\nMake some changes to the README.md file in the Test repo.\nClick the Git tab, and stage the change(s) by checking the checkboxes next to the files listed.\nClick the Commit button.\nAdd a commit comment, click commit.\n\nShow me\n\n\nSkill 4: Push changes to GitHub / Pull changes from GitHub\nTo push changes you committed in Skill #3\n\nFrom Git tab, click on the Green up arrow that says Push.\nTo pull changes on GitHub that are not on your local computer:\nMake some changes directly on GitHub (not in RStudio)\nFrom Git tab, click on the down arrow that says Pull.\n\nShow me\n\n\nPair-activity 1\nIn RStudio,\n\nMake a copy of README.md\nRename it to .md\nAdd some text.\nStage and commit the added file.\nPush to GitHub.\n\nTry before watching.\nShow me in RStudio – Show me in the shell – Show me in jupyter-git\n\n\nPair-activity 2\nAll of this activity is in RStudio.\n\nClone this repo https://github.com/nmfs-opensci/git-basics to RStudio and create a new project\nNavigate to the files in your new project, create a filed called to &lt;yourname&gt;.md. Use your actual name so the filename is different from everyone elses.\nStage and then commit that new file.\nPush to GitHub.\nMake some more changes and push to GitHub.\nPull in your partner’s (and everyone elses) changes\n\nShow me in RStudio – Show me in JupyterLab\n\n\nPair-activity 3\nYou can copy your own or other people’s repos1.\n\nIn a browser, go to the GitHub repository https://github.com/RWorkflow-Workshops/Week5\nCopy its URL.\nNavigate to your GitHub page: click your icon in the upper right and then ‘your repositories’\nClick the + in top right and click import repository. Paste in the URL and give your repo a name.\nUse Skill #1 to clone your new repo to RStudio and create a new project"
  },
  {
    "objectID": "content/data.html",
    "href": "content/data.html",
    "title": "Data",
    "section": "",
    "text": "Indian Ocean and Bay of Bengal Data\nStudents will learn how to access remote-sensing data in the cloud (meaning on-line), but we have also prepared an “analysis ready” data set for students. This will be available on a shared drive and we will introduce the students to the techniques for accessing large datasets without loading them into memory.\n\n\nBounding box\n\nlatitude: -12deg to 32deg\nlongitude: 42deg to 102deg\ngrid: 0.25 deg\ncenters: 0, 0.25, 0.5., 0.75\n\n\n\nDatasets: ERA5\n\nu wind\nv wind\nwind speed\nwind direction\nair temperature @ 2m\nsea surface temperature\n\n\n\nCopernicus\n\nsea level anomaly\nchlorophyll concentration\n\n\n\nSRTM30_PLUS\n\nBathymetry\n\nReferences\n\nhttps://topex.ucsd.edu/WWW_html/srtm30_plus.html\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/usgsCeSrtm30v6.html\n\n\n\n1-km MUR SST\n\nsea surface temperature"
  },
  {
    "objectID": "content/git.html#summary",
    "href": "content/git.html#summary",
    "title": "Git - Jupyter Lab",
    "section": "Summary",
    "text": "Summary\nIn this tutorial, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nNavigating around folders in Jupyter Lab\nVersion Control (code management using git)\nSetting up Git in Jupyter Lab\nThe Git GUI in Jupyter Lab\nBasic Git commands"
  },
  {
    "objectID": "content/git.html#introduction-jupyter-lab",
    "href": "content/git.html#introduction-jupyter-lab",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Jupyter Lab",
    "text": "Introduction :: Jupyter Lab\nWhen you start the JupyterHub, you will be in Jupyter Lab. From there you can click on the RStudio box and open RStudio. However for this tutorial, we will stay in Juptyer Lab."
  },
  {
    "objectID": "content/git.html#introduction-terminalshell",
    "href": "content/git.html#introduction-terminalshell",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Terminal/Shell",
    "text": "Introduction :: Terminal/Shell\nLog into the JupyterHub. If you do not see this\n\nThen go to File &gt; New Launcher\nClick on the “Terminal” box to open a new terminal window.\n\nShell or Terminal Basics\n\nWhat is Terminal or Shell?\nNavigating Files and Directories\nWorking with Files and Directories\nOptional: Detailed self-paced lesson on running scripts from the shell: Shell Lesson from Software Carpentry\n\nYou will need only basic navigation skills for this course: cd, ls and cat\n\npwd where am I\ncd nameofdir move into a directory\ncd .. move up a directory\nls list the files in the current directory\nls -a list the files including hidden files\nls -l list the files with more info\ncat filename print out the contents of a file\n\n\n\nLet’s try\nls\nls -a\ncd shared\nls\ncd shell-tutorial\ncat lesson1.sh\ncd ..\ncd ..\n\n\nClose the terminal\nJust click on the X in the terminal tab"
  },
  {
    "objectID": "content/git.html#introduction-file-navigation",
    "href": "content/git.html#introduction-file-navigation",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: File Navigation",
    "text": "Introduction :: File Navigation\nIn the far left, you will see a line of icons. The top one is a folder and allows us to move around our file system.\n\nClick on shared. Now you can see the files in the shared directory.\nClick on shell-tutorial. Then click on lesson1.sh. The file opens. You won’t be able to save changes here because you don’t have write permission on this drive.\nClick on the folder icon that looks like this. Click on the actual folder image. \nNow it should look like this folder /\nThis shows me doing this\n\nCreate a new folder.\n\nNext to the blue rectange with a +, is a grey folder with a +. Click that to create a new folder, called lesson-scripts.\nThen click on lesson-scripts to enter the folder\n\n\nCreate a new file\n\nCreate with File &gt; New &gt; Text file\nThe file will open and you can edit it.\nSave with File &gt; Save Text\nDelete the file by right-clicking on it and clicking “Delete”"
  },
  {
    "objectID": "content/git.html#introduction-version-control-git",
    "href": "content/git.html#introduction-version-control-git",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Version Control (Git)",
    "text": "Introduction :: Version Control (Git)\n\nWhat is version control, git, github, and how to set it up?\nVersion control is managing and tracking changes to your documents (program source code, images, websites, data files, etc.). git is a popular tool used for version control of software code. github.com is popular platform that provides remote server hosting for git repositories. A repository is a collection of various files that you are tracking for changes and versions. Currently GitHub is the most popular platform for file sharing code and code packages.\nThis section is a step-by-step guide to set up git on our JupyterHub. We will also configure git to use your github.com account for managing your repositories hosted on github.com. There are 5 main steps.\n\n\nStep 1: Create a GitHub account\nTo complete the setup, you will need an account on github.com. If you don’t have an account, please visit github.com, create an account (free) and come back to this guide for setting up git.\n\n\nStep 2: Clone a repository\nWe have created a demo repository for you to clone:\nhttps://github.com/nmfs-opensci/Git-Lesson\n\nStart your JupyterHub\nClick on the Git icon\n\n\n\nClick “Clone a Repository”\nWhere is says “Enter the URI of the remote Git repository”, paste in the URL https://github.com/nmfs-opensci/Git-Lesson\nThe folder appears and you can enter the folder and edit and create files.\n\n\nYour task: Create a file with your name and save to the Git-Lesson folder"
  },
  {
    "objectID": "content/git.html#step-3",
    "href": "content/git.html#step-3",
    "title": "Git - Jupyter Lab",
    "section": "Step 3:",
    "text": "Step 3:\nConfigure git with your name and email address.\n``` bash\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\n```\n\n**Note:** This name and email could be different from your github.com credentials. Remember `git` is a program that keeps track of your changes locally (on 2i2c JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by `git`, the email/name used in git configuration will show up next to your contributions on github.com when you `push` your repository to github.com (`git push` is discussed in a later step).\n\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git Jupyter lab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "content/jupyter-notebooks.html#summary",
    "href": "content/jupyter-notebooks.html#summary",
    "title": "Jupyter Notebooks - Python",
    "section": "Summary",
    "text": "Summary\nIn this tutorial, we will provide a brief introduction to:\n\nJupyter Notebooks in the JupyterHub\nProgramming in Python (using Jupyter Notebook)\nGeospatial Fundamentals (optional, self-study)\nCommand line (terminal/shell)\nVersion Control (code management using git)"
  },
  {
    "objectID": "content/jupyter-notebooks.html#introduction-programming-in-python",
    "href": "content/jupyter-notebooks.html#introduction-programming-in-python",
    "title": "Jupyter Notebooks - Python",
    "section": "Introduction :: Programming in Python",
    "text": "Introduction :: Programming in Python\nSwitch to Jupyter Notebook for an introduction to programming in Python\n\nVariables (and mathematical operations)\nData Structures (list, tuple, dict)\nFlow Control using loops (for, while)\nConditionals (if, else, elif)\nFunctions\nErrors and Exceptions (understanding and handling errors)\nUsing modules (libraries, packages)\n\npandas: high-performance, easy-to-use data structures and data analysis tools\nrioxarray: based on the rasterio package for working with rasters and xarray\n\n\n\nPython Learning Resources\nSelf-paced lesson on Programming with Python from Software Carpentry"
  },
  {
    "objectID": "content/jupyter-notebooks.html#introduction-geospatial-fundamentals-optional",
    "href": "content/jupyter-notebooks.html#introduction-geospatial-fundamentals-optional",
    "title": "Jupyter Notebooks - Python",
    "section": "Introduction :: Geospatial Fundamentals (Optional)",
    "text": "Introduction :: Geospatial Fundamentals (Optional)\nDetailed self-paced lesson on Fundamentals of Geospatial Raster and Vector Data with Python from Data Carpentry"
  },
  {
    "objectID": "content/jupyter-notebooks.html#jupyter-notebooks-in-earth-sciences",
    "href": "content/jupyter-notebooks.html#jupyter-notebooks-in-earth-sciences",
    "title": "Jupyter Notebooks - Python",
    "section": "Jupyter Notebooks in Earth Sciences",
    "text": "Jupyter Notebooks in Earth Sciences\nThere are many Jupyter Notebooks that you can copy and run in our JupyterHub. Note our JupyterHub is set up for geospatial research and connection to NASA’s data in the cloud. It is also set up for parallel processing with Dask.\n\nNASA Cloud Hackweek 2022\nOceanHackWeek\nICESat-2 Hackweeks"
  },
  {
    "objectID": "content/jupyter-notebooks.html#pythonconda-environments",
    "href": "content/jupyter-notebooks.html#pythonconda-environments",
    "title": "Jupyter Notebooks - Python",
    "section": "Python/Conda environments",
    "text": "Python/Conda environments\nPython users can create conda environments if they need to install modules. You create a environments.yml file like this:\nname: nsidc\nchannels:\n  - conda-forge\ndependencies:\n  - ipykernel\n  - awscli~=1.21.4\n  - requests\n  - pip\nAnd then in a terminal do this to activate the environment.\nconda env create -f environment.yml --name myenv\nconda activate myenv\nconda list"
  },
  {
    "objectID": "content/shell.html#summary",
    "href": "content/shell.html#summary",
    "title": "Terminal or Shell",
    "section": "Summary",
    "text": "Summary\nIn this tutorial, we will provide a brief introduction to\n\nWhat is the terminal/shell\nHow to get to the terminal in Jupyter Lab and RStudio\nNavigating around folders in the terminal\nClosing the terminal window"
  },
  {
    "objectID": "content/shell.html#what-is-the-terminal-or-shell",
    "href": "content/shell.html#what-is-the-terminal-or-shell",
    "title": "Terminal or Shell",
    "section": "What is the terminal or shell?",
    "text": "What is the terminal or shell?\nA way to interact with your computer from text commands instead of a graphical user interface (GUI). There are a few different types of shells and there are slight differences in syntax. However, we will be using very basic commands so the syntax difference won’t affect us.\nWhen in a terminal window you can type echo $0 to find out what shell type you are in."
  },
  {
    "objectID": "content/shell.html#introduction-terminalshell",
    "href": "content/shell.html#introduction-terminalshell",
    "title": "Terminal or Shell",
    "section": "Introduction :: Terminal/Shell",
    "text": "Introduction :: Terminal/Shell\n\nRStudio\nLog into the JupyterHub. If you do not see this\n\nThen go to File &gt; New Launcher\nClick on the RStudio box to open RStudio.\n\n\nJupyter Lab\nLog into the JupyterHub. If you do not see this\n\nThen go to File &gt; New Launcher\nClick on the “Terminal” box to open a new terminal window.\n\n\nShell or Terminal Basics\n\nWhat is Terminal or Shell?\nNavigating Files and Directories\nWorking with Files and Directories\nOptional: Detailed self-paced lesson on running scripts from the shell: Shell Lesson from Software Carpentry\n\nYou will need only basic navigation skills for this course: cd, ls and cat\n\npwd where am I\ncd nameofdir move into a directory\ncd .. move up a directory\nls list the files in the current directory\nls -a list the files including hidden files\nls -l list the files with more info\ncat filename print out the contents of a file\n\n\n\nLet’s try\nls\nls -a\ncd shared\nls\ncd shell-tutorial\ncat lesson1.sh\ncd ..\ncd ..\n\n\nClose the terminal\nJust click on the X in the terminal tab"
  },
  {
    "objectID": "content/shell.html#introduction-file-navigation",
    "href": "content/shell.html#introduction-file-navigation",
    "title": "Terminal or Shell",
    "section": "Introduction :: File Navigation",
    "text": "Introduction :: File Navigation\nIn the far left, you will see a line of icons. The top one is a folder and allows us to move around our file system.\n\nClick on shared. Now you can see the files in the shared directory.\nClick on shell-tutorial. Then click on lesson1.sh. The file opens. You won’t be able to save changes here because you don’t have write permission on this drive.\nClick on the folder icon that looks like this. Click on the actual folder image. \nNow it should look like this folder /\nThis shows me doing this\n\nCreate a new folder.\n\nNext to the blue rectange with a +, is a grey folder with a +. Click that to create a new folder, called lesson-scripts.\nThen click on lesson-scripts to enter the folder\n\n\nCreate a new file\n\nCreate with File &gt; New &gt; Text file\nThe file will open and you can edit it.\nSave with File &gt; Save Text\nDelete the file by right-clicking on it and clicking “Delete”"
  },
  {
    "objectID": "content/shell.html#introduction-version-control-git",
    "href": "content/shell.html#introduction-version-control-git",
    "title": "Terminal or Shell",
    "section": "Introduction :: Version Control (Git)",
    "text": "Introduction :: Version Control (Git)\n\nWhat is version control, git, github, and how to set it up?\nVersion control is managing and tracking changes to your documents (program source code, images, websites, data files, etc.). git is a popular tool used for version control of software code. github.com is popular platform that provides remote server hosting for git repositories. A repository is a collection of various files that you are tracking for changes and versions. Currently GitHub is the most popular platform for file sharing code and code packages.\nThis section is a step-by-step guide to set up git on our JupyterHub. We will also configure git to use your github.com account for managing your repositories hosted on github.com. There are 5 main steps.\n\n\nStep 1: Create a GitHub account\nTo complete the setup, you will need an account on github.com. If you don’t have an account, please visit github.com, create an account (free) and come back to this guide for setting up git.\n\n\nStep 2: Clone a repository\nWe have created a demo repository for you to clone:\nhttps://github.com/nmfs-opensci/Git-Lesson\n\nStart your JupyterHub\nClick on the Git icon\n\n\n\nClick “Clone a Repository”\nWhere is says “Enter the URI of the remote Git repository”, paste in the URL https://github.com/nmfs-opensci/Git-Lesson\nThe folder appears and you can enter the folder and edit and create files.\n\n\nYour task: Create a file with your name and save to the Git-Lesson folder"
  },
  {
    "objectID": "content/shell.html#step-3",
    "href": "content/shell.html#step-3",
    "title": "Terminal or Shell",
    "section": "Step 3:",
    "text": "Step 3:\nConfigure git with your name and email address.\n``` bash\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\n```\n\n**Note:** This name and email could be different from your github.com credentials. Remember `git` is a program that keeps track of your changes locally (on 2i2c JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by `git`, the email/name used in git configuration will show up next to your contributions on github.com when you `push` your repository to github.com (`git push` is discussed in a later step).\n\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git Jupyter lab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Overview",
    "section": "",
    "text": "The the era of big data in the earth sciences is here and learning how to effectively use oceanographic remote-sensing data, both in the cloud and on your computer, is a core skill for modern fisheries science and management. Learning how to access cloud-based data, visualize these data, use these data in models, and use the tools of modern reproducible and collaborative science is the main goal of this course. Through the course, participants will gain experience with assessing remote-sensing data in the cloud, R and RStudio, Python and Jupyter notebooks, and collaborating with Git and GitHub.",
    "crumbs": [
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#aims-and-objectives",
    "href": "overview.html#aims-and-objectives",
    "title": "Overview",
    "section": "Aims and Objectives",
    "text": "Aims and Objectives\n\nLearn how to discover and use oceanographic remote-sensing data for species distribution modeling and other fisheries applications\nFamiliarize participants with using remote-sensing data and geospatial tools in R and Python code.\nObtain hands-on experience in using remote-sensing data and other earth data in science workflows by working together on a group project.",
    "crumbs": [
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#what-is-a-hackweek",
    "href": "overview.html#what-is-a-hackweek",
    "title": "Overview",
    "section": "What is a hackweek?",
    "text": "What is a hackweek?\nA hackweek is a participant-driven workshop that blends data science education, community building, and project work over a short period of time (one to two weeks). The events are highly immersive and allow participants to work directly with data science professionals to co-shape projects and educational outcomes. Hackweeks help individuals and teams engage more effectively in open and reproducible science. - eScience Institute, University of Washington, Seattle USA\nThe hackweek model has become a vital tool in the data science community, fostering idea exchange through modern data analysis workflow training. Unlike traditional academic events, hackweeks offer intensive, interactive learning, including tutorials on cutting-edge methods, peer-based learning, and collaborative on-site projects. Unlike hackathons, which emphasize software development, hackweeks prioritize education and open-ended projects, benefiting fields needing both expertise and efficient computational workflows for idea exchange and discovery. The hackweek model is now widely used in many fields: Astrohackweek, Neurohackweek, Geohackweek, OceanHackWeek, ICESat-2 Hackweek, SnowEx Hackweek, NASA Cloud Hackathon. The NOAA HackDays content and format is modeled off the University of Washington eScience Hackweek model.",
    "crumbs": [
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#code-of-conduct",
    "href": "overview.html#code-of-conduct",
    "title": "Overview",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nThe NOAA HackDays events are a safe learning space and all participants are required to abide by our Code of Conduct.",
    "crumbs": [
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Set-up",
    "section": "",
    "text": "To work on the JupyterHub for the workshop:",
    "crumbs": [
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "setup.html#get-on-the-jupyterhub",
    "href": "setup.html#get-on-the-jupyterhub",
    "title": "Set-up",
    "section": "Get on the JupyterHub",
    "text": "Get on the JupyterHub\nOnce you have submitted your GitHub username and have been accepted as a member of the DaskHub team on the nmfs-opensci organization, you can log-into the JupyterHub.\nhttps://dhub.opensci.live/\n\nMake sure to choose an R image or else you will not see the RStudio Server button. Watch a video of the login process and basic JupyterHub orientation.\nhome directory is yours and no one else can see it. To share files, you can connect to a GitHub repository or use the shared directory. Everyone can read and write to this directory. Please don’t delete content that is not your own.",
    "crumbs": [
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "setup.html#set-up-authentication-to-github",
    "href": "setup.html#set-up-authentication-to-github",
    "title": "Set-up",
    "section": "Set up authentication to GitHub",
    "text": "Set up authentication to GitHub\nYou need to tell GitHub who you are so you can push your local changes up to GitHub. There are a few ways to do this. I am going to show you a way that works on any computer, including a virtual computer like the JupyterHub.\n\nStep 1: Generate a Personal Access Token\nWe are going to generate a classic token.\n\nGo to https://github.com/settings/tokens\nClick Generate new token &gt; Generate new token (classic)\nWhen the pop-up shows up, fill in a description, click the “repo” checkbox, and then scroll to bottom to click “Generate”.\nFor scope, select “repo”.\nSAVE the token. You need it for the next step.\n\n\n\nStep 2: Tell Git who your are\n\nOpen a terminal. In Jupyter Lab, you will see a box labelled “Terminal” on the Launcher window. In RStudio, you will see a tab (usually in lower left) with the label “Terminal”\nPaste these 3 lines of code into the terminal\n\ngit config --global user.email \"&lt;your email&gt;\"\ngit config --global user.name \"&lt;your name&gt;\"\ngit config --global pull.rebase false\ngit config --global credential.helper store\nReplace \"&lt;your email&gt;\" with something like jane.doe@noaa.gov. Replace \"&lt;your name&gt;\" with something like \"Jane Doe\". Notice the quotes.\n\n\nStep 3: Trigger git to ask for your password\nThere are a few ways to do this.\n\nClone a repo, make a change, and then commit and push the change\nClone a private repo\n\nOption b is easiest if you are new to Git and GitHub.\n\nOpen a terminal window\nMake sure you are in the home directory by typing cd ~\nClone a repo and create an RStudio project. File &gt; New Project &gt; Version Control &gt; Git. Paste in this URL https://github.com/nmfs-opensci/github_setup_check and make sure it is creating the repo at ~ (home directory).\nYou will be asked for your GitHub username and password. For the password, enter the PERSONAL ACCESS TOKEN from Step 1.\n\nWatch a video of these 4 steps\nFull instructions with other ways to do this from R",
    "crumbs": [
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "team.html#organizers-and-instructors",
    "href": "team.html#organizers-and-instructors",
    "title": "Our Team",
    "section": "Organizers and Instructors",
    "text": "Organizers and Instructors\n\n\nEli Holmes\n\n\nNOAA Fisheries\nwebpage • GitHub • ORCID\n\n\nSunny Hospital\n\nNOAA CoastWatch PolarWatch\nGitHub\n\n\nMatt Grossi\n\n\nEmily Markowitz\n\n\n\n\nMore\n\n\nMore\n\n\nMore\n\n\nMore",
    "crumbs": [
      "Welcome",
      "Our Team"
    ]
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#summary",
    "href": "tutorials/python/2-subset-and-plot.html#summary",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Summary",
    "text": "Summary\nIn this examples we will use the xarray and earthaccess to subset data and make figures.",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#learning-objectives",
    "href": "tutorials/python/2-subset-and-plot.html#learning-objectives",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExtract variables, temporal slices, and spatial slices from an xarray dataset\nPlot data and exclude data points via boolean conditions, using xarray, cartopy, and matplotlib\n\n\nImport Required Packages\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\nfrom pprint import pprint\n\nimport earthaccess\nimport xarray as xr\nxr.set_options(display_expand_attrs=False)\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\n%matplotlib inline",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#authenticate-to-nasa-earthdata",
    "href": "tutorials/python/2-subset-and-plot.html#authenticate-to-nasa-earthdata",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Authenticate to NASA Earthdata",
    "text": "Authenticate to NASA Earthdata\nWe will authenticate our Earthaccess session, and then open the results like we did in the Search & Discovery section.\n\n# Bug on dhub settings is setting the home to /home/rstudio\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\nEDL_USERNAME and EDL_PASSWORD are not set in the current environment, try setting them or use a different strategy (netrc, interactive)\nYou're now authenticated with NASA Earthdata Login\nUsing token with expiration date: 01/29/2024\nUsing .netrc file for EDL",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "href": "tutorials/python/2-subset-and-plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3",
    "text": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3\n\nDataset\nWe will use the GPM IMERG Final Precipitation L3 Daily dataset for this tutorial. The IMERG Precipitation Rate provides the rain and snow rates in millimeters per hour (mm/hr). It is estimated by the Integrated Multi-satellitE Retrievals for Global Precipitation Measurement (GPM) (IMERG) algorithm. The IMERG algorithm uses passive-microwave data from the GPM constellation of satellites and infrared data from geosynchronous satellites. IMERG “morphs” observations to earlier or later times using wind from weather-model analyses. The daily IMERG dataset is derived from the half-hourly GPM_3IMERGHH. The derived result represents the final estimate of the daily mean precipitation rate in mm/day.\nLink to data on NASA Earthdata\nThe IMERG data has 0.1 x 0.1 degree latitude-longitude resolution (approximately 11 by 11 km at the Equator). The grid covers the globe, although precipitation cannot always be estimated near the Poles. The dataset and algorithm are described in the data user guide and the Algorithm Theoretical Basis Document (ATBD).\nPlease cite the dataset as: &gt; Huffman, G.J., E.F. Stocker, D.T. Bolvin, E.J. Nelkin, Jackson Tan (2023), GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07, Edited by Andrey Savtchenko, Greenbelt, MD, Goddard Earth Sciences Data and Information Services Center (GES DISC), https://doi.org/10.5067/GPM/IMERGDF/DAY/07\n\ncollection_id = 'C2723754864-GES_DISC'  # GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07 (GPM_3IMERGDF)\n# Seems to be a bug in the collection above so I am using older data\n\n# Bounds within which we search for data granules\ndate_start = \"2015-02-25\"\ndate_end = \"2015-02-26\"\ndate_range = (date_start, date_end)\nbbox = (-127.0761, 31.6444, -113.9039, 42.6310)  # min lon, min lat, max lon, max lat\n\n# For reference (e.g., to visualize in https://geojson.io/), here is a GeoJSON representing the above bounding box:\n# {\"type\": \"FeatureCollection\", \"features\": [{\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"LineString\", \"bbox\": [-127.0761, 31.6444, -113.9039, 42.631], \"coordinates\": [[-113.9039, 42.631], [-127.0761,42.631], [-127.0761, 31.6444], [-113.9039, 31.6444], [-113.9039, 42.631]]}}]}\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 2\n\n\n\nds = xr.open_mfdataset(earthaccess.open(results))\n\n Opening 2 granules, approx size: 0.05 GB\n\n\n\n\n\n\n\n\n\n\n\nNote that xarray works with “lazy” computation whenever possible. In this case, the metadata are loaded into JupyterHub memory, but the data arrays and their values are not — until there is a need for them.\nLet’s print out all the variable names.\n\nfor v in ds.variables:\n    print(v)\n\nprecipitation\nprecipitation_cnt\nprecipitation_cnt_cond\nMWprecipitation\nMWprecipitation_cnt\nMWprecipitation_cnt_cond\nrandomError\nrandomError_cnt\nprobabilityLiquidPrecipitation\nlon\nlat\ntime\ntime_bnds\n\n\nOf the variables listed above, we are interested in three variables: precipitation, precipitation_cnt_cond, and probabilityLiquidPrecipitation. Let’s print their attributes.\n\nds.variables['precipitation'].attrs\n\n{'units': 'mm/day',\n 'long_name': 'Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.'}\n\n\n\nds.variables['precipitation_cnt_cond'].attrs\n\n{'units': 'count',\n 'long_name': 'Count of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr'}\n\n\n\nds.variables['probabilityLiquidPrecipitation'].attrs\n\n{'units': 'percent',\n 'long_name': 'Probability of liquid precipitation',\n 'description': 'Probability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation.  Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.'}\n\n\n\n\nSubsetting\nIn addition to directly accessing the files archived and distributed by each of the NASA DAACs, many datasets also support services that allow us to customize the data via subsetting, reformatting, reprojection/regridding, and file aggregation. What does subsetting mean? To subset means to extract only the portions of a dataset that are needed for a given purpose.\nThere are three primary types of subsetting that we will walk through: 1. Temporal 2. Spatial 3. Variable\nIn each case, we will be excluding parts of the dataset that are not wanted using xarray. Note that “subsetting” is also called a data “transformation”.\n\nds.time.values\n\narray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')\n\n\nWe start with a subset that represents the U.S. state of California. Notice the dimensions of the Dataset and each variable — time, lon, lat, and ‘nv’ (number of vertices) for the bounds variable.\n\n# Display the full dataset's metadata\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                         (time: 2, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                             (lon) float32 -179.9 -179.9 ... 179.9 179.9\n  * lat                             (lat) float64 -89.95 -89.85 ... 89.85 89.95\n  * time                            (time) datetime64[ns] 2015-02-25 2015-02-26\nDimensions without coordinates: nv\nData variables:\n    precipitation                   (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt               (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt_cond          (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation                 (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt             (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt_cond        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                     (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt                 (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    probabilityLiquidPrecipitation  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                       (time, nv) datetime64[ns] dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes: (9)xarray.DatasetDimensions:time: 2lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.9 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95, -179.85, -179.75, ...,  179.75,  179.85,  179.95],\n      dtype=float32)lat(lat)float64-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95, -89.85, -89.75, ...,  89.75,  89.85,  89.95])time(time)datetime64[ns]2015-02-25 2015-02-26standard_name :timelong_name :timebounds :time_bndsarray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (10)precipitation(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nDaily mean High Quality precipitation rate from all available microwave sources. Formerly HQprecipitation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly MWprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly MWprecipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nRoot-mean-square error estimate for combined microwave-IR daily precipitation rate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprobabilityLiquidPrecipitation\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\npercent\n\nlong_name :\n\nProbability of liquid precipitation\n\ndescription :\n\nProbability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation. Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(time, nv)\n\n\ndatetime64[ns]\n\n\ndask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n32 B\n16 B\n\n\nShape\n(2, 2)\n(1, 2)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.85000610351562,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.35000610351562,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.14999389648438,              179.25,\n               179.35000610351562,   179.4499969482422,   179.5500030517578,\n               179.64999389648438,              179.75,  179.85000610351562,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([            -89.95, -89.85000000000001,             -89.75,\n                          -89.65,             -89.55,             -89.45,\n              -89.35000000000001,             -89.25,             -89.15,\n                          -89.05,\n              ...\n                           89.05,  89.15000000000002,  89.25000000000001,\n               89.35000000000001,              89.45,              89.55,\n               89.65000000000002,  89.75000000000001,  89.85000000000001,\n                           89.95],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(DatetimeIndex(['2015-02-25', '2015-02-26'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (9)BeginDate :2015-02-25BeginTime :00:00:00.000ZEndDate :2015-02-25EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2015-02-25T00:00:00.000Z;\nStopGranuleDateTime=2015-02-25T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20150225-S000000-E002959.0000.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S003000-E005959.0030.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S010000-E012959.0060.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S013000-E015959.0090.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S020000-E022959.0120.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S023000-E025959.0150.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S030000-E032959.0180.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S033000-E035959.0210.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S040000-E042959.0240.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S043000-E045959.0270.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S050000-E052959.0300.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S053000-E055959.0330.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S060000-E062959.0360.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S063000-E065959.0390.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S070000-E072959.0420.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S073000-E075959.0450.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S080000-E082959.0480.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S083000-E085959.0510.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S090000-E092959.0540.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S093000-E095959.0570.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S100000-E102959.0600.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S103000-E105959.0630.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S110000-E112959.0660.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S113000-E115959.0690.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S120000-E122959.0720.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S123000-E125959.0750.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S130000-E132959.0780.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S133000-E135959.0810.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S140000-E142959.0840.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S143000-E145959.0870.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S150000-E152959.0900.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S153000-E155959.0930.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S160000-E162959.0960.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S163000-E165959.0990.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S170000-E172959.1020.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S173000-E175959.1050.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S180000-E182959.1080.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S183000-E185959.1110.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S190000-E192959.1140.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S193000-E195959.1170.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S200000-E202959.1200.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S203000-E205959.1230.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S210000-E212959.1260.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S213000-E215959.1290.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S220000-E222959.1320.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S223000-E225959.1350.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S230000-E232959.1380.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S233000-E235959.1410.V07B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/07ProductionTime :2023-12-18T14:54:02.047Z\n\n\nNow we will prepare a subset. We’re using essentially the same spatial bounds as above; however, as opposed to the earthaccess inputs above, here we must provide inputs in the formats expected by xarray. Instead of a single, four-element, bounding box, we use Python slice objects, which are defined by starting and ending numbers.\n\nds_subset = ds.sel(time=date_start, lat=slice(31, 43), lon=slice(-125, -113)) \nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                         (lon: 120, lat: 120, nv: 2)\nCoordinates:\n  * lon                             (lon) float32 -124.9 -124.8 ... -113.1\n  * lat                             (lat) float64 31.05 31.15 ... 42.85 42.95\n    time                            datetime64[ns] 2015-02-25\nDimensions without coordinates: nv\nData variables:\n    precipitation                   (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    precipitation_cnt               (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    precipitation_cnt_cond          (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation                 (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation_cnt             (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    MWprecipitation_cnt_cond        (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    randomError                     (lon, lat) float32 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    randomError_cnt                 (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    probabilityLiquidPrecipitation  (lon, lat) int8 dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n    time_bnds                       (nv) datetime64[ns] dask.array&lt;chunksize=(2,), meta=np.ndarray&gt;\nAttributes: (9)xarray.DatasetDimensions:lon: 120lat: 120nv: 2Coordinates: (3)lon(lon)float32-124.9 -124.8 ... -113.2 -113.1units :degrees_eastlong_name :Longitudearray([-124.95, -124.85, -124.75, -124.65, -124.55, -124.45, -124.35, -124.25,\n       -124.15, -124.05, -123.95, -123.85, -123.75, -123.65, -123.55, -123.45,\n       -123.35, -123.25, -123.15, -123.05, -122.95, -122.85, -122.75, -122.65,\n       -122.55, -122.45, -122.35, -122.25, -122.15, -122.05, -121.95, -121.85,\n       -121.75, -121.65, -121.55, -121.45, -121.35, -121.25, -121.15, -121.05,\n       -120.95, -120.85, -120.75, -120.65, -120.55, -120.45, -120.35, -120.25,\n       -120.15, -120.05, -119.95, -119.85, -119.75, -119.65, -119.55, -119.45,\n       -119.35, -119.25, -119.15, -119.05, -118.95, -118.85, -118.75, -118.65,\n       -118.55, -118.45, -118.35, -118.25, -118.15, -118.05, -117.95, -117.85,\n       -117.75, -117.65, -117.55, -117.45, -117.35, -117.25, -117.15, -117.05,\n       -116.95, -116.85, -116.75, -116.65, -116.55, -116.45, -116.35, -116.25,\n       -116.15, -116.05, -115.95, -115.85, -115.75, -115.65, -115.55, -115.45,\n       -115.35, -115.25, -115.15, -115.05, -114.95, -114.85, -114.75, -114.65,\n       -114.55, -114.45, -114.35, -114.25, -114.15, -114.05, -113.95, -113.85,\n       -113.75, -113.65, -113.55, -113.45, -113.35, -113.25, -113.15, -113.05],\n      dtype=float32)lat(lat)float6431.05 31.15 31.25 ... 42.85 42.95units :degrees_northlong_name :Latitudearray([31.05, 31.15, 31.25, 31.35, 31.45, 31.55, 31.65, 31.75, 31.85, 31.95,\n       32.05, 32.15, 32.25, 32.35, 32.45, 32.55, 32.65, 32.75, 32.85, 32.95,\n       33.05, 33.15, 33.25, 33.35, 33.45, 33.55, 33.65, 33.75, 33.85, 33.95,\n       34.05, 34.15, 34.25, 34.35, 34.45, 34.55, 34.65, 34.75, 34.85, 34.95,\n       35.05, 35.15, 35.25, 35.35, 35.45, 35.55, 35.65, 35.75, 35.85, 35.95,\n       36.05, 36.15, 36.25, 36.35, 36.45, 36.55, 36.65, 36.75, 36.85, 36.95,\n       37.05, 37.15, 37.25, 37.35, 37.45, 37.55, 37.65, 37.75, 37.85, 37.95,\n       38.05, 38.15, 38.25, 38.35, 38.45, 38.55, 38.65, 38.75, 38.85, 38.95,\n       39.05, 39.15, 39.25, 39.35, 39.45, 39.55, 39.65, 39.75, 39.85, 39.95,\n       40.05, 40.15, 40.25, 40.35, 40.45, 40.55, 40.65, 40.75, 40.85, 40.95,\n       41.05, 41.15, 41.25, 41.35, 41.45, 41.55, 41.65, 41.75, 41.85, 41.95,\n       42.05, 42.15, 42.25, 42.35, 42.45, 42.55, 42.65, 42.75, 42.85, 42.95])time()datetime64[ns]2015-02-25standard_name :timelong_name :timebounds :time_bndsarray('2015-02-25T00:00:00.000000000', dtype='datetime64[ns]')Data variables: (10)precipitation(lon, lat)float32dask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\nprecipitation_cnt\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprecipitation_cnt_cond\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation\n\n\n(lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nDaily mean High Quality precipitation rate from all available microwave sources. Formerly HQprecipitation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly MWprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nMWprecipitation_cnt_cond\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly MWprecipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError\n\n\n(lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nRoot-mean-square error estimate for combined microwave-IR daily precipitation rate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n56.25 kiB\n56.25 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\nprobabilityLiquidPrecipitation\n\n\n(lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(120, 120), meta=np.ndarray&gt;\n\n\n\n\nunits :\n\npercent\n\nlong_name :\n\nProbability of liquid precipitation\n\ndescription :\n\nProbability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation. Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n14.06 kiB\n14.06 kiB\n\n\nShape\n(120, 120)\n(120, 120)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(nv)\n\n\ndatetime64[ns]\n\n\ndask.array&lt;chunksize=(2,), meta=np.ndarray&gt;\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n16 B\n16 B\n\n\nShape\n(2,)\n(2,)\n\n\nDask graph\n1 chunks in 6 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n\n\n\n\nIndexes: (2)lonPandasIndexPandasIndex(Float64Index([-124.94999694824219,  -124.8499984741211,             -124.75,\n               -124.6500015258789, -124.55000305175781, -124.44999694824219,\n               -124.3499984741211,             -124.25,  -124.1500015258789,\n              -124.05000305175781,\n              ...\n              -113.94999694824219,  -113.8499984741211,             -113.75,\n               -113.6500015258789, -113.55000305175781, -113.44999694824219,\n               -113.3499984741211,             -113.25,  -113.1500015258789,\n              -113.05000305175781],\n             dtype='float64', name='lon', length=120))latPandasIndexPandasIndex(Float64Index([             31.05,  31.15000000000001, 31.250000000000004,\n              31.350000000000012, 31.450000000000006,              31.55,\n               31.65000000000001, 31.750000000000004, 31.850000000000012,\n              31.950000000000006,\n              ...\n                           42.05,  42.14999999999999, 42.250000000000014,\n               42.35000000000001,              42.45,              42.55,\n               42.64999999999999, 42.750000000000014,  42.85000000000001,\n                           42.95],\n             dtype='float64', name='lat', length=120))Attributes: (9)BeginDate :2015-02-25BeginTime :00:00:00.000ZEndDate :2015-02-25EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2015-02-25T00:00:00.000Z;\nStopGranuleDateTime=2015-02-25T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20150225-S000000-E002959.0000.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S003000-E005959.0030.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S010000-E012959.0060.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S013000-E015959.0090.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S020000-E022959.0120.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S023000-E025959.0150.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S030000-E032959.0180.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S033000-E035959.0210.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S040000-E042959.0240.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S043000-E045959.0270.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S050000-E052959.0300.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S053000-E055959.0330.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S060000-E062959.0360.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S063000-E065959.0390.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S070000-E072959.0420.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S073000-E075959.0450.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S080000-E082959.0480.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S083000-E085959.0510.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S090000-E092959.0540.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S093000-E095959.0570.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S100000-E102959.0600.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S103000-E105959.0630.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S110000-E112959.0660.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S113000-E115959.0690.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S120000-E122959.0720.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S123000-E125959.0750.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S130000-E132959.0780.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S133000-E135959.0810.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S140000-E142959.0840.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S143000-E145959.0870.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S150000-E152959.0900.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S153000-E155959.0930.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S160000-E162959.0960.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S163000-E165959.0990.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S170000-E172959.1020.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S173000-E175959.1050.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S180000-E182959.1080.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S183000-E185959.1110.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S190000-E192959.1140.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S193000-E195959.1170.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S200000-E202959.1200.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S203000-E205959.1230.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S210000-E212959.1260.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S213000-E215959.1290.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S220000-E222959.1320.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S223000-E225959.1350.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S230000-E232959.1380.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S233000-E235959.1410.V07B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/07ProductionTime :2023-12-18T14:54:02.047Z\n\n\nNotice the differences?\n\n\nPlotting\nWe will first plot using the methods built-in to the xarray package.\nNote that, as opposed to the “lazy” loading of metadata previously, this will now perform “eager” computation, pulling the required data chunks.\n\nds_subset['precipitation'].plot(figsize=(10,6), x='lon', y='lat');\n\n\n\n\nNow let’s utilize the “Probability of liquid precipitation phase” (probabilityLiquidPrecipitation) variable to split apart the snow precipitation from everything else. From the variable’s description attribute, we can see that “0=missing values; 1=likely solid; 100=likely liquid or no precipitation”.\nMoreover, we’ll utilize precipitation_cnt_cond to filter out data points that had less than 0.01 mm/hr preciptation amounts.\n\nsnow = ds_subset['precipitation'].where(\n    (ds_subset.precipitation_cnt_cond&gt;0) & (ds_subset.probabilityLiquidPrecipitation == 1)\n)\n\nprcp = ds_subset['precipitation'].where(\n    (ds_subset.precipitation_cnt_cond&gt;0) & (ds_subset.probabilityLiquidPrecipitation != 1)\n)\n\nIn the following plotting commands, we utilize cartopy and matplotlib to generate a more customized figure.\ncartopy is used to set the map projection (to PlateCarree) and to add U.S. state boundary lines to the figure. matplotlib’s pcolormesh is used to generate the color plot, with colors determined by the third argument’s value.\n\n# create the plot\nproj = ccrs.PlateCarree()\nfig, ax = plt.subplots(figsize=(8,5), dpi=130, facecolor=\"w\", subplot_kw=dict(projection=proj))\n\nsnowax = plt.pcolormesh(prcp.lon, prcp.lat, snow.squeeze(), vmax=53, cmap='cool')\nprcpax = plt.pcolormesh(prcp.lon, prcp.lat, prcp.squeeze(), vmax=53, cmap='RdYlGn')\n\nplt.colorbar(snowax, ax=ax, label=\"snow (mm/day)\")\nplt.colorbar(prcpax, ax=ax, label=\"rainfall (mm/day)\")\nax.add_feature(cfeature.STATES)\nax.set_extent([-125, -113.0, 31.0, 43.0], crs=proj)\nax.set_title(f'Precipitation {date_start}')\n\nplt.show()\n\n\n\n\nNotice the enhancements?\nAlso, note that you can explore these (and other) data before generating your own customized plots, by using NASA Worldview. Here’s a link to an example map on Worldview for these IMERG data.\nEND of Notebook.",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 2"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#overview",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#overview",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Overview",
    "text": "Overview\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less-experienced users of Python.\n\nThe exercise demonstrates the following techniques:\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nBuilding an ERDDAP data-request URL\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\nDatasets used:\n\nChlorophyll-a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nA loggerhead turtle telemetry track that has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. The track dataset is stored in the data/ folder of this module.",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#import-the-required-python-modules",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#import-the-required-python-modules",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules\n\nimport pandas as pd \nimport numpy as np \nimport warnings\nfrom urllib.parse import quote\nfrom datetime import datetime\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings('ignore')",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#load-the-track-data-into-a-pandas-data-frame",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#load-the-track-data-into-a-pandas-data-frame",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Load the track data into a Pandas data frame",
    "text": "Load the track data into a Pandas data frame\nBelow, the track data will load using the Pandas “read_csv” method. * The use the “.head()” method to view the column names and the first few rows of data. * Use the “.dtypes” to show the data type of each column. Note that numerical values are in the the mean_lon (float), mean_lat (float) year (integer), month (integer), and day (integer) columns. * Numerical values latitude and longitude values are good for plotting the track data on a map. * However, later on we will need to create string versions of the mean_lon and mean_lat columns and to create a date string from year, month, and day columns for use in the ERDDAP data request URL. * The latitude and longitude ranges are displayed below. These values will be helpful to set spatial boundaries when we plot the data onto maps.\n\nds = pd.read_csv('../data/25317_05_subsampled.dat')\nprint(ds.head(2))\nprint(' ')\nprint('Data types for each column')\nprint(ds.dtypes)\nprint(' ')\nprint('Spatial corrdinate ranges')\nprint('latitude range', round(ds.mean_lat.min(), 2), round(ds.mean_lat.max(), 2))\nprint('longitude range', round(ds.mean_lon.min(), 2), round(ds.mean_lon.max(), 2))\n\n     mean_lon   mean_lat  year  month  day\n0  176.619433  32.678728  2005      5    4\n1  175.860895  35.057734  2005      6   23\n \nData types for each column\nmean_lon    float64\nmean_lat    float64\nyear          int64\nmonth         int64\nday           int64\ndtype: object\n \nSpatial corrdinate ranges\nlatitude range 23.72 41.77\nlongitude range 175.86 248.57",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n#ax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\nax1 = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120, 260, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(125, 255, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20, 60, 10), crs=ccrs.PlateCarree())\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# bring the lon and lat data into a numpy array \nx, y = ds.mean_lon.to_numpy(), ds.mean_lat.to_numpy()\n\nax1 = plt.plot(x, y, transform=ccrs.PlateCarree(), color='k')\n# start point in green star\nax1 = plt.plot(x[0], y[0],\n               marker='*',\n               color='g',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\n# end point in red X\nax1 = plt.plot(x[-1], y[-1],\n               marker='X',\n               color='r',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\nplt.title('Animal Track for Turtle #25317', fontsize=20)\n\nplt.show()",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#prepare-track-data-for-use-in-the-erddap-data-request-url",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#prepare-track-data-for-use-in-the-erddap-data-request-url",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Prepare track data for use in the ERDDAP data-request URL",
    "text": "Prepare track data for use in the ERDDAP data-request URL\nTo build the ERDDAP data-request URLs, we will need: * Dates as strings in a format that ERDDAP can understand, i.e. YYYY-mm-dd.\n* The latitude and longitude values need to be converted to strings (characters) not the numerical values found in the mean_lon and mean_lat columns.\n\nCreate a formatted date column and change the columns data type\nLet’s do that in two steps:\n\nReload the “25317_05_subsampled.dat”. This time we will use the “parse_dates” option to create a Pandas date object column (year_month_day) from the ‘year’, ‘month’, and ‘day’ columns.\n\n\ndf = pd.read_csv('../data/25317_05_subsampled.dat',\n                 parse_dates=[['year', 'month', 'day']]\n                 )\n\nprint('The new year_month_day column contains the Pandas date objects')\ndf.head(2)\n\nThe new year_month_day column contains the Pandas date objects\n\n\n\n\n\n\n\n\n\nyear_month_day\nmean_lon\nmean_lat\n\n\n\n\n0\n2005-05-04\n176.619433\n32.678728\n\n\n1\n2005-06-23\n175.860895\n35.057734\n\n\n\n\n\n\n\n\nUse the year_month_day column to create a column called “date_str” containing string versions of the date with the format “YYYY-mm-dd”.\n\n\n\nDelete the year_month_day column to keep the data frame smaller\n\n\ndf['date_str'] = df['year_month_day'].dt.strftime('%Y-%m-%d')\n\n\n# Clean up the data frame a little by deleting the year_month_day column\ndel df['year_month_day']\nprint(df.head(2))\n\nprint(' ')\nprint('The time range is:', df.date_str.min(), df.date_str.max())\n\n     mean_lon   mean_lat    date_str\n0  176.619433  32.678728  2005-05-04\n1  175.860895  35.057734  2005-06-23\n \nThe time range is: 2005-05-04 2008-08-16\n\n\n\n\nCreate string versions of the latitude and longitude data\nCreate two new columns (mean_lon_str and mean_lat_str) the have the latitude and longitude coordinates as string data types rather than numerical (float) data types found in columns mean_lon and mean_lat.\n* The two new columns are mean_lon_str and mean_lat_str\n\ndf[['mean_lon_str', 'mean_lat_str']] = df[['mean_lon', \n                                           'mean_lat'\n                                          ]].to_numpy(dtype=str)\n\nprint(df.head(2))\nprint(' ')\nprint('Data types for each column')\nprint(df.dtypes)\n\n     mean_lon   mean_lat    date_str      mean_lon_str      mean_lat_str\n0  176.619433  32.678728  2005-05-04  176.619432886108  32.6787283689241\n1  175.860895  35.057734  2005-06-23  175.860895212552   35.057734124614\n \nData types for each column\nmean_lon        float64\nmean_lat        float64\ndate_str         object\nmean_lon_str     object\nmean_lat_str     object\ndtype: object",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Extract data from a satellite dataset corresponding to points on the track",
    "text": "Extract data from a satellite dataset corresponding to points on the track\nWe are going to download data from an ERDDAP server using the following steps: * Select a dataset * Loop though the track data using the string versions of data, latitude and longitude to build an ERDDAP data-request URL for each row of the track data frame. * Use the ERDDAP data-request URL to download satellite data into Pandas * Add the downloaded data to you track data frame.\n\nSelect a dataset\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nIdeally we would use a daily dataset, selecting the day correspond the the track data date. However, chlorophyll measurements can have lots of missing data, primarily due to cloud cover. To reduce data gaps and improve the likelihood of data for our matchups, we can use a dataset that combines data monthly averages.\nLet’s use data from the monthly version of the OC-CCI datasets.\nThe ERDDAP URLs to the monthly version is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-03-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n\n\nRefresher on building the ERDDAP data-request URL\nTo refresh your memory from the ERDDAP Tutorial, a full ERDDAP data-request URL looks like the following: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a[(2023-03-01)][(89.9792):(-89.9792)][(0.02083):(359.9792)]\np { text-align: justify;\nWe can deconstruct the URL into its component parts:\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nERDDAP base URL\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/\nWeb location of ERDDAP server\n\n\nDataset ID\naesa-cci-chla-monthly-v6-0\nUnique dataset ID\n\n\nDownload file\n.csv\nData file to download (CSV is this case)\n\n\nQuery indicator\n?\nMark start of data query\n\n\nVariable\nchlor_a\nERDDAP variable to download\n\n\nTime range\n[(2023-02-15):1:(2023-03-01)]\nTemporal date range to download\n\n\nLatitude range\n[(89.9792):(-89.9792)]\nLatitude range to download\n\n\nLongitude range\n[(0.02083):(359.9792)]\nLongitude range to download\n\n\n\n}\nWe need to construct these components parts for each row of the track data frame and join them together to form the ERDDAP data-request URL.\n\n\nBuilding the ERDDAP data-request URL and downloading satellite data\n\n# create a data frame to hold the downloaded satellite data\ncol_names = [\"iso_date\", \"matched_lat\", \"matched_lon\", \"matched_chla\"]\n\n# create tot dataframe with the column names\ntot = pd.DataFrame(columns=col_names)\n\n# create variables for the unchanging parts of the ERDDAP data-request URL. \nbase_url = 'https://oceanwatch.pifsc.noaa.gov/erddap/griddap/'\ndataset_id = \"esa-cci-chla-monthly-v6-0\"\nfile_type = '.csv'\nquery_start = '?'\nerddap_variable = 'chlor_a'\n\n# create the start of the ERDDAP data-request URL by joining URL components\nstart_url = ''.join([base_url,\n                     dataset_id,\n                     file_type,\n                     query_start,\n                     erddap_variable\n                     ])\n\n# Finish each URL and download\nfor i in range(0, len(df)):\n    # for each row in the track data frame, create the query part of the ERDDAP data-request URL.\n    query_url = ''.join([\n                         '[(' + df['date_str'][i] + '):1:(' + df['date_str'][i] + ')]',\n                         '[(' + df['mean_lat_str'][i] + '):1:(' + df['mean_lat_str'][i] + ')]', \n                         '[(' + df['mean_lon_str'][i] + '):1:(' + df['mean_lon_str'][i] + ')]'\n                         ])\n    encoded_query = quote(query_url, safe='')\n\n    # join the start and query parts of the url\n    url = start_url + encoded_query\n    print(i+1, 'of', len(df), url)\n\n    # download the data as a CSV file directly into Pandas\n    new = pd.read_csv(url, skiprows=1)\n    new.columns = col_names\n    \n    # load into the holding data frame\n    tot = pd.concat([tot, new], ignore_index=True)\n    \n\n1 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-05-04%29%3A1%3A%282005-05-04%29%5D%5B%2832.6787283689241%29%3A1%3A%2832.6787283689241%29%5D%5B%28176.619432886108%29%3A1%3A%28176.619432886108%29%5D\n2 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-06-23%29%3A1%3A%282005-06-23%29%5D%5B%2835.057734124614%29%3A1%3A%2835.057734124614%29%5D%5B%28175.860895212552%29%3A1%3A%28175.860895212552%29%5D\n3 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-08-12%29%3A1%3A%282005-08-12%29%5D%5B%2840.4057593651645%29%3A1%3A%2840.4057593651645%29%5D%5B%28180.592617770427%29%3A1%3A%28180.592617770427%29%5D\n4 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-10-01%29%3A1%3A%282005-10-01%29%5D%5B%2841.6848032419466%29%3A1%3A%2841.6848032419466%29%5D%5B%28183.510212411605%29%3A1%3A%28183.510212411605%29%5D\n5 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-11-20%29%3A1%3A%282005-11-20%29%5D%5B%2837.3662285175569%29%3A1%3A%2837.3662285175569%29%5D%5B%28186.999746586372%29%3A1%3A%28186.999746586372%29%5D\n6 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-01-09%29%3A1%3A%282006-01-09%29%5D%5B%2832.1379277609952%29%3A1%3A%2832.1379277609952%29%5D%5B%28193.315150592714%29%3A1%3A%28193.315150592714%29%5D\n7 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-02-28%29%3A1%3A%282006-02-28%29%5D%5B%2832.1112577913518%29%3A1%3A%2832.1112577913518%29%5D%5B%28199.01578005525%29%3A1%3A%28199.01578005525%29%5D\n8 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-04-19%29%3A1%3A%282006-04-19%29%5D%5B%2834.9122377945573%29%3A1%3A%2834.9122377945573%29%5D%5B%28196.367856222399%29%3A1%3A%28196.367856222399%29%5D\n9 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-06-08%29%3A1%3A%282006-06-08%29%5D%5B%2834.6966077152962%29%3A1%3A%2834.6966077152962%29%5D%5B%28194.311561551928%29%3A1%3A%28194.311561551928%29%5D\n10 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-07-28%29%3A1%3A%282006-07-28%29%5D%5B%2837.0917501942058%29%3A1%3A%2837.0917501942058%29%5D%5B%28192.85445935735%29%3A1%3A%28192.85445935735%29%5D\n11 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-09-16%29%3A1%3A%282006-09-16%29%5D%5B%2841.7693290372383%29%3A1%3A%2841.7693290372383%29%5D%5B%28194.078757811627%29%3A1%3A%28194.078757811627%29%5D\n12 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-11-05%29%3A1%3A%282006-11-05%29%5D%5B%2838.2279593047231%29%3A1%3A%2838.2279593047231%29%5D%5B%28192.044436165313%29%3A1%3A%28192.044436165313%29%5D\n13 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-12-25%29%3A1%3A%282006-12-25%29%5D%5B%2834.7385780752043%29%3A1%3A%2834.7385780752043%29%5D%5B%28191.760026290605%29%3A1%3A%28191.760026290605%29%5D\n14 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-02-13%29%3A1%3A%282007-02-13%29%5D%5B%2831.7396435280445%29%3A1%3A%2831.7396435280445%29%5D%5B%28195.063134981283%29%3A1%3A%28195.063134981283%29%5D\n15 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-04-04%29%3A1%3A%282007-04-04%29%5D%5B%2834.3432418597437%29%3A1%3A%2834.3432418597437%29%5D%5B%28199.306553405532%29%3A1%3A%28199.306553405532%29%5D\n16 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-05-24%29%3A1%3A%282007-05-24%29%5D%5B%2835.1277116865649%29%3A1%3A%2835.1277116865649%29%5D%5B%28205.605040455239%29%3A1%3A%28205.605040455239%29%5D\n17 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-07-13%29%3A1%3A%282007-07-13%29%5D%5B%2838.460826483342%29%3A1%3A%2838.460826483342%29%5D%5B%28210.280467921659%29%3A1%3A%28210.280467921659%29%5D\n18 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-09-01%29%3A1%3A%282007-09-01%29%5D%5B%2839.3374947731784%29%3A1%3A%2839.3374947731784%29%5D%5B%28215.722452964025%29%3A1%3A%28215.722452964025%29%5D\n19 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-10-21%29%3A1%3A%282007-10-21%29%5D%5B%2835.8679284198372%29%3A1%3A%2835.8679284198372%29%5D%5B%28223.007301112593%29%3A1%3A%28223.007301112593%29%5D\n20 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-12-10%29%3A1%3A%282007-12-10%29%5D%5B%2830.1854023141461%29%3A1%3A%2830.1854023141461%29%5D%5B%28225.638647308816%29%3A1%3A%28225.638647308816%29%5D\n21 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-01-29%29%3A1%3A%282008-01-29%29%5D%5B%2828.328588352337%29%3A1%3A%2828.328588352337%29%5D%5B%28232.406424355302%29%3A1%3A%28232.406424355302%29%5D\n22 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-03-19%29%3A1%3A%282008-03-19%29%5D%5B%2825.9810780813157%29%3A1%3A%2825.9810780813157%29%5D%5B%28239.552975360004%29%3A1%3A%28239.552975360004%29%5D\n23 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-05-08%29%3A1%3A%282008-05-08%29%5D%5B%2824.8366188324699%29%3A1%3A%2824.8366188324699%29%5D%5B%28245.871574770029%29%3A1%3A%28245.871574770029%29%5D\n24 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-06-27%29%3A1%3A%282008-06-27%29%5D%5B%2823.7241735345355%29%3A1%3A%2823.7241735345355%29%5D%5B%28248.571044756%29%3A1%3A%28248.571044756%29%5D\n25 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-08-16%29%3A1%3A%282008-08-16%29%5D%5B%2826.7817714626367%29%3A1%3A%2826.7817714626367%29%5D%5B%28245.7579071789%29%3A1%3A%28245.7579071789%29%5D\n\n\n\ntot.head(2)\n\n\n\n\n\n\n\n\niso_date\nmatched_lat\nmatched_lon\nmatched_chla\n\n\n\n\n0\n2005-05-01T00:00:00Z\n32.6875\n176.604167\n0.293616\n\n\n1\n2005-07-01T00:00:00Z\n35.0625\n175.854167\n0.114716\n\n\n\n\n\n\n\n\n\nConsolidate the downloaded satellite data into the track data frame\n\n\ndf[['matched_lat', 'matched_lon', 'matched_chla']] = tot[['matched_lat',\n                                                          'matched_lon',\n                                                          'matched_chla'\n                                                          ]]\ndf.head(2)\n\n\n\n\n\n\n\n\nmean_lon\nmean_lat\ndate_str\nmean_lon_str\nmean_lat_str\nmatched_lat\nmatched_lon\nmatched_chla\n\n\n\n\n0\n176.619433\n32.678728\n2005-05-04\n176.619432886108\n32.6787283689241\n32.6875\n176.604167\n0.293616\n\n\n1\n175.860895\n35.057734\n2005-06-23\n175.860895212552\n35.057734124614\n35.0625\n175.854167\n0.114716\n\n\n\n\n\n\n\n\n\nSave your work\n\ndf.to_csv('chl_matchup_turtle25327.csv', index=False, encoding='utf-8')",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-chlorophyll-matchup-data-onto-a-map",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-chlorophyll-matchup-data-onto-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot chlorophyll matchup data onto a map",
    "text": "Plot chlorophyll matchup data onto a map\n\nFirst plot a histogram of the chlorophyll data\n\nprint('Range:', df.matched_chla.min(), df.matched_chla.max())\n_ = df.matched_chla.hist(bins=40)\n\nRange: 0.05568646 0.7134876\n\n\n\n\n\nThe range of chlorophyll values can be large, with lots of very low values, and a few very high values. This could skew a linear color bar so the most values lower values have the same color. * For this reason we often plot the log or log10 of chlorophyll\n\n\nPlot a histogram of the log of the chlorophyll data\n\nprint('Range:', np.log(df.matched_chla.min()), np.log(df.matched_chla.max()))\n_ = np.log(df.matched_chla).hist(bins=40)\n\nRange: -2.8880182495708433 -0.33759022133329325\n\n\n\n\n\n\nThe range of log chlorophyll is about -2.9 to -0.3 but most of the values are between -2.5 and -0.8.\nKnowing the distribution of values can also help to set the color bar range for our map.\n\n\n\nMap the chlorophyll data\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n\n# set the projection\nax1 = plt.axes(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120,255, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(120,255,20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20,50,10), crs=ccrs.PlateCarree())\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# build and plot coordinates onto map\nx,y = list(df.mean_lon),list(df.mean_lat)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=np.log(df.matched_chla),\n                  cmap=plt.get_cmap('jet')\n                  )\nax1=plt.plot(x[0],y[0],marker='*', transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(-2.5, 0, 0.5)\ncbar=plt.colorbar(ticks=levs2, shrink=0.75, aspect=10)\ncbar.set_label(\"Chl a (mg/m^3)\", size=15, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.around(np.exp(levs2), 2), size=10)\n\nplt.title(\"Chlorophyll Matchup to Animal Track #25317\", size=15)\nplt.show()",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#on-your-own",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#on-your-own",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "On your own!",
    "text": "On your own!\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html\n* This dataset is a different ERDDAP, so remember the change the base URL. * Set the new dataset ID and variable name.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/\n* This dataset will likely be on a different ERDDAP, so remember the change the base URL. * Set the new dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html",
    "crumbs": [
      "Tutorials",
      "Tutorials in Python",
      "Tutorial 4"
    ]
  },
  {
    "objectID": "tutorials/r/1-earthdatalogin.html",
    "href": "tutorials/r/1-earthdatalogin.html",
    "title": "Intro to earthdatalogin",
    "section": "",
    "text": "This is the “Data Cubes with STAC” vignette from earthdataaccess package.\nHigh-resolution satellites generate many snapshot images each with a limited field of view or spatial extent. In order to see a larger area in space, and/or observe changes across space and time, we need to assemble these many snapshots into a mosaic or “data cube” that we can analyze as a cohesive whole.\nEARTHDATA STAC CATALOGS",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/r/1-earthdatalogin.html#install-earthdatalogin",
    "href": "tutorials/r/1-earthdatalogin.html#install-earthdatalogin",
    "title": "Intro to earthdatalogin",
    "section": "Install earthdatalogin",
    "text": "Install earthdatalogin\nInstall earthdatalogin and update terra\n\ninstall.packages(\"earthdatalogin\")\ninstall.packages(\"terra\")",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/r/1-earthdatalogin.html#basic-use",
    "href": "tutorials/r/1-earthdatalogin.html#basic-use",
    "title": "Intro to earthdatalogin",
    "section": "Basic Use",
    "text": "Basic Use\nFirst let’s get NASA Earth Data Login (EDL) authentication out of the way. For cloud data from almost any other STAC catalog (NOAA, USGS, Planetary Computer, etc), authentication is either unnecessary or already provided by the STAC API, but NASA EDL is special.\n\nlibrary(earthdatalogin)\n# Authenticate\nedl_netrc()\n\nGet data.\n\nlibrary(terra)\n\nterra 1.7.71\n\nurl &lt;- \"https://data.lpdaac.earthdatacloud.nasa.gov/lp-prod-protected/HLSL30.020/HLS.L30.T56JKT.2023246T235950.v2.0/HLS.L30.T56JKT.2023246T235950.v2.0.SAA.tif\"\nras &lt;- terra::rast(url, vsi=TRUE)\n\nThis is a boring and weird example. The plot is correct.\n\nplot(ras)",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/r/1-earthdatalogin.html#searching-and-subsetting",
    "href": "tutorials/r/1-earthdatalogin.html#searching-and-subsetting",
    "title": "Intro to earthdatalogin",
    "section": "Searching and Subsetting",
    "text": "Searching and Subsetting\nThe packages we want\n\nlibrary(rstac)\nlibrary(gdalcubes)\n\n\nAttaching package: 'gdalcubes'\n\n\nThe following objects are masked from 'package:terra':\n\n    animate, crop, size\n\ngdalcubes_options(parallel = TRUE) \n\n\nEDL Authentication\nAs usual, we can handle this with edl_netrc(). Because the gdalcubes package doesn’t respect global environmental variables, we use a helper utility to export those into its configuration as well.\n\nlibrary(earthdatalogin)\nedl_netrc()\nwith_gdalcubes()\n\n\n\nSearch via STAC\nWe will now use the rstac package to search one or more NASA collections for data that falls into our desired bounding box of space and time. NASA has a CMR option for searching that is more stable but this example is using STAC which is a more universal option.\n\nbbox &lt;- c(xmin=-123, ymin=37.25, xmax=-122.0, ymax=38.25) \nstart &lt;- \"2021-12-01\"\nend &lt;- \"2022-01-31\"\n\n# Find all assets from the desired catalog:\nitems &lt;- stac(\"https://cmr.earthdata.nasa.gov/stac/LPCLOUD\") |&gt; \n  stac_search(collections = \"HLSL30.v2.0\",\n              bbox = bbox,\n              datetime = paste(start,end, sep = \"/\")) |&gt;\n  post_request() |&gt;\n  items_fetch() |&gt;\n  items_filter(filter_fn = \\(x) {x[[\"eo:cloud_cover\"]] &lt; 20})\n\n\n  |                                                                            \n  |======================================================================| 100%\n\n\nWarning: In version 0.9.2, rstac changed how filter function is evaluated. In future versions, the `filter_fn` parameter will be evaluated against each feature in items instead of `properties` field.\nSee ?items_filter for more details on how to change your function.\n\n\nNote that 98 features have matched our search criteria! Each feature represents a ‘snapshot’ image taken by the satellite as it passes by (this is a harmonized product so actually there’s quite a lot of post-processing.) Each feature thus shares the same bounding box, projection, and timestamp, but may consist of many different ‘assets’, different files representing the different spectral bands on the satellite camera instrument. Each feature can potentially include quite extensive metadata about the feature, including details of instrument itself or from post-processing, such as cloud cover. Unfortunately, Earth Data’s STAC metadata tends to be quite sparse.\n\n\nBuilding a Data Cube\n\n# Desired data cube shape & resolution\nv = cube_view(srs = \"EPSG:4326\",\n              extent = list(t0 = as.character(start), \n                            t1 = as.character(end),\n                            left = bbox[1], right = bbox[3],\n                            top = bbox[4], bottom = bbox[2]),\n              nx = 512, ny = 512, dt = \"P1M\")\n\nRGB bands + cloud cover mask\n\ncol &lt;- stac_image_collection(items$features, \n                             asset_names = c(\"B02\", \"B03\", \"B04\", \"Fmask\"))\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'B02' does not include eo:bands metadata and will be considered\nas a single band source\n\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'B03' does not include eo:bands metadata and will be considered\nas a single band source\n\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'B04' does not include eo:bands metadata and will be considered\nas a single band source\n\n\nWarning in stac_image_collection(items$features, asset_names = c(\"B02\", : STAC\nasset with name 'Fmask' does not include eo:bands metadata and will be\nconsidered as a single band source\n\n\nUse a cloud mask. See HLS User Guide.\n\ncloud_mask &lt;- image_mask(\"Fmask\", values=1)\n\n\n\nPlot\nThis takes awhile. So far we have not downloaded anything. We have been working with metadata about the files. Now we do the work which involves server-side subsetting and some operations. We download on the part that we need.\n\nraster_cube(col, v, mask=cloud_mask) |&gt;\n  select_bands(c(\"B02\",\"B03\", \"B04\")) |&gt;\n  plot(rgb=3:1)",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 1"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html",
    "title": "Extract data within a boundary",
    "section": "",
    "text": "history | Updated August 2023",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan, frequency measurements, spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of boundaries include marine protected areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces.",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary.",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server for a non-rectangular region using the rerddapXtracto package\nVisualizing data on a map\nPlotting a time-series of mean SST",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthlyly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based gap-free sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#install-packages-and-load-libraries",
    "title": "Extract data within a boundary",
    "section": "Install packages and load libraries",
    "text": "Install packages and load libraries\n\npkges = installed.packages()[,\"Package\"]\n# Function to check if pkgs are installed, install missing pkgs, and load\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n# create list of required packages\nlist.of.packages &lt;- c(\"ncdf4\", \"rerddap\",\"plotdap\", \"parsedate\", \n                      \"sp\", \"ggplot2\", \"RColorBrewer\", \"sf\", \n                      \"reshape2\", \"maps\", \"mapdata\", \n                      \"jsonlite\", \"rerddapXtracto\")\n\n# Run install and load function\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}\n\n\nThe downloaded binary packages are in\n    /var/folders/w4/4s0hrwdd2gd8k4kp6s1z8zn40000gn/T//RtmpWGowQ9/downloaded_packages\n\nThe downloaded binary packages are in\n    /var/folders/w4/4s0hrwdd2gd8k4kp6s1z8zn40000gn/T//RtmpWGowQ9/downloaded_packages\n\nThe downloaded binary packages are in\n    /var/folders/w4/4s0hrwdd2gd8k4kp6s1z8zn40000gn/T//RtmpWGowQ9/downloaded_packages\n\n# create list of installed packages\npkges = installed.packages()[,\"Package\"]",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "title": "Extract data within a boundary",
    "section": "Load boundary coordinates",
    "text": "Load boundary coordinates\nThe shapefile for the Longhurst marine provinces includes a list of regions. For this exercise, we will only use the boundary of one province, the Gulf Stream region (“GFST”).\n\n# Set directory path\ndir_path &lt;- '../resources/longhurst_v4_2010/'\n\n# Import shape files (Longhurst coordinates)\nshapes &lt;- read_sf(dsn = dir_path, layer = \"Longhurst_world_v4_2010\")\n\n# Example List of all the province names\nshapes$ProvCode\n\n [1] \"BPLR\" \"ARCT\" \"SARC\" \"NADR\" \"GFST\" \"NASW\" \"NATR\" \"WTRA\" \"ETRA\" \"SATL\"\n[11] \"NECS\" \"CNRY\" \"GUIN\" \"GUIA\" \"NWCS\" \"MEDI\" \"CARB\" \"NASE\" \"BRAZ\" \"FKLD\"\n[21] \"BENG\" \"MONS\" \"ISSG\" \"EAFR\" \"REDS\" \"ARAB\" \"INDE\" \"INDW\" \"AUSW\" \"BERS\"\n[31] \"PSAE\" \"PSAW\" \"KURO\" \"NPPF\" \"NPSW\" \"TASM\" \"SPSG\" \"NPTG\" \"PNEC\" \"PEQD\"\n[41] \"WARM\" \"ARCH\" \"ALSK\" \"CCAL\" \"CAMR\" \"CHIL\" \"CHIN\" \"SUND\" \"AUSE\" \"NEWZ\"\n[51] \"SSTC\" \"SANT\" \"ANTA\" \"APLR\"\n\n# Get boundary coordinates for Gulf Stream region (GFST)\nGFST &lt;- shapes[shapes$ProvCode == \"GFST\",]\n\nxcoord &lt;- st_coordinates(GFST)[,1]\nycoord &lt;- st_coordinates(GFST)[,2]",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#select-the-satellite-dataset",
    "title": "Extract data within a boundary",
    "section": "Select the satellite dataset",
    "text": "Select the satellite dataset\nWe will load the sea surface temperature data from the geo-polar blended SST satellite data product hosted on the CoastWatch ERDDAP. The dataset ID for this data product is nesdisBLENDEDsstDNDaily.\nWe will use the info function from the rerddap package to first obtain information about the dataset of interest, then we will import the data.\n\n# Set ERDDAP URL\nerd_url = \"http://coastwatch.pfeg.noaa.gov/erddap/\"\n\n# Obtain data info using the erddap url and dataset ID\ndataInfo &lt;- rerddap::info('NOAA_DHW_monthly',url=erd_url)  \n\n# Examine the metadata dataset info\ndataInfo\n\n&lt;ERDDAP info&gt; NOAA_DHW_monthly \n Base URL: http://coastwatch.pfeg.noaa.gov/erddap \n Dataset Type: griddap \n Dimensions (range):  \n     time: (1985-01-16T00:00:00Z, 2024-03-16T00:00:00Z) \n     latitude: (-89.975, 89.975) \n     longitude: (-179.975, 179.975) \n Variables:  \n     mask: \n         Units: pixel_classification \n     sea_surface_temperature: \n         Units: degree_C \n     sea_surface_temperature_anomaly: \n         Units: degree_C",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#set-the-options-for-the-polygon-data-extract",
    "title": "Extract data within a boundary",
    "section": "Set the options for the polygon data extract",
    "text": "Set the options for the polygon data extract\nUsing the rxtractogon function, we will import the satellite data from erddap. The rxtractogon function takes the variable(s) of interest and the coordinates as input.\n\nFor the coordinates: determine the range of x, y, z, and time.\ntime coordinate: select the entire year of 2020\n\n\n# set the parameter to extract\nparameter &lt;- 'sea_surface_temperature'\n# set the time range\ntcoord &lt;- c(\"2020-01-16\", \"2020-12-16\")\n\n# We already extracted the xcoord (longitude) and ycoord (latitude) from the shapefiles \n# The dummy code below is just a placeholder indicating it is necessary to define what the longitude and latitude vectors are that make up the boundary of the polygon.\nxcoord &lt;- xcoord\nycoord &lt;- ycoord",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#extract-data-and-mask-it-using-rxtractogon",
    "title": "Extract data within a boundary",
    "section": "Extract data and mask it using rxtractogon",
    "text": "Extract data and mask it using rxtractogon\n\nthe rxtractogon function automatically extracts data from the satellite dataset and masks out any data outside the polygon boundary.\n\nList the data\n\n\n## Request the data\nsatdata &lt;- rxtractogon(dataInfo, parameter=parameter, xcoord=xcoord, ycoord=ycoord,tcoord=tcoord)\n\n## List the returned data\nstr(satdata)\n\nList of 6\n $ sea_surface_temperature: num [1:601, 1:202, 1:12] NA NA NA NA NA NA NA NA NA NA ...\n $ datasetname            : chr \"NOAA_DHW_monthly\"\n $ longitude              : num [1:601(1d)] -73.5 -73.5 -73.4 -73.4 -73.3 ...\n $ latitude               : num [1:202(1d)] 33.5 33.5 33.6 33.6 33.7 ...\n $ altitude               : logi NA\n $ time                   : POSIXlt[1:12], format: \"2020-01-16 00:00:00\" \"2020-02-16 00:00:00\" ...\n - attr(*, \"class\")= chr [1:2] \"list\" \"rxtracto3D\"\n - attr(*, \"base_url\")= chr \"http://coastwatch.pfeg.noaa.gov/erddap/\"\n - attr(*, \"datasetid\")= chr \"NOAA_DHW_monthly\"\n\n\n\nPlot the data\n\nUse the plotBBox function in the rerddapXtracto package to quickly plot the data\n\n\nplotBBox(satdata, plotColor = 'thermal',maxpixels=1000000)\n\n\n\n\n\n\nPlot the mean seasonal temperature for the province\n\nsst_mean=apply(satdata$sea_surface_temperature,3,mean,na.rm=TRUE)\n\n\nplot(satdata$time,sst_mean,main='Gulf Stream Province Monthly Mean Temperature 2020',ylab='SSt (ºC)',xlab='',type='b')",
    "crumbs": [
      "Tutorials",
      "Tutorials in R",
      "Tutorial 3"
    ]
  }
]