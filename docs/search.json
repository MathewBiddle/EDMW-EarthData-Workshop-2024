[
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#objective",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#objective",
    "title": "Matchup satellite data to track locations",
    "section": "Objective",
    "text": "Objective\nThis tutorial will demonstrate how to extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like those produced by an animal telemetry tag, and ship track, or a glider track.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Matchup satellite data to track locations",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nImporting track data in csv file to data frame\nPlotting the latitude/longitude points onto a map\nUsing rerddapXtraco function to extract satellite data from an ERDDAP data server along a track\nPlotting the satellite data onto a map",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#datasets-used",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#datasets-used",
    "title": "Matchup satellite data to track locations",
    "section": "Datasets used",
    "text": "Datasets used\nChlorophyll a concentration, the European Space Agency’s Ocean Colour Climate Change Initiative (OC-CCI) Monthly dataset v6.0\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nLoggerhead turtle telemetry track data\nThe turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. This dataset has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The track data are stored in the data folder in this project folder.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#install-required-packages-and-load-libraries",
    "title": "Matchup satellite data to track locations",
    "section": "Install required packages and load libraries",
    "text": "Install required packages and load libraries\n\n# Function to check if pkgs are installed, and install any missing pkgs\npkgTest &lt;- function(x)\n{\n  if (!require(x,character.only = TRUE))\n  {\n    install.packages(x,dep=TRUE,repos='http://cran.us.r-project.org')\n    if(!require(x,character.only = TRUE)) stop(x, \" :Package not found\")\n  }\n}\n\n\n# Create list of required packages\nlist.of.packages &lt;- c(\"rerddap\", \"plotdap\", \"parsedate\", \"ggplot2\", \"rerddapXtracto\",\n                       \"date\", \"maps\", \"mapdata\", \"RColorBrewer\",\"viridis\")\n\n# Create list of installed packages\npkges = installed.packages()[,\"Package\"]\n\n# Install and load all required pkgs\nfor (pk in list.of.packages) {\n  pkgTest(pk)\n}",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#import-the-track-data-into-a-data-frame",
    "title": "Matchup satellite data to track locations",
    "section": "Import the track data into a data frame",
    "text": "Import the track data into a data frame\n\n# Import csv file into a data frame\nturtle_df &lt;- read.csv(\"../data/25317_05_subsampled.dat\")\n# Show 3 rows from the data frame\nhead(turtle_df,3)\n\n  mean_lon mean_lat year month day\n1 176.6194 32.67873 2005     5   4\n2 175.8609 35.05773 2005     6  23\n3 180.5926 40.40576 2005     8  12",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to track locations",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\n# Download world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Map turtle tracks\nggplot(turtle_df, aes(mean_lon,mean_lat)) +\n  geom_path(group=1)+\n  geom_point(aes(x=mean_lon,y=mean_lat), pch=1, size=2 )+\n  geom_point(aes(x=mean_lon[1],y=mean_lat[1]),fill=\"green\", shape=24, size=3)+\n  geom_point(aes(x=mean_lon[length(mean_lon)],y=mean_lat[length(mean_lat)]), shape=22, size=3, fill=\"red\")+\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60))+\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with start (green) and end location (red)\")+\n  theme(plot.title=element_text(hjust=0.5), aspect.ratio=1/2)\n\n\n\n\n\n\n\n\nIn this exercise, two different ways of extracting data from ERDDAP data server along a track of xyt points are demonstrated:\n\nUsing the rerddapXtracto package which was written specifically for this task\nBy manually constructing a URL with the data data request\n\n\nExtracting XYT data using the rerddapXtracto package\nWe will use the `rxtracto function of the rerddapXtracto package, which was written to simplify data extraction from ERDDAP servers.\nLet’s use data from the monthly product of the OC-CCI datasets.\nThe ERDDAP URL to the monthly product is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-12-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n\n# Set dataset ID\ndataset &lt;- 'esa-cci-chla-monthly-v6-0'\n\n# Get data information from ERDDAP server\ndataInfo &lt;- rerddap::info(dataset, url= \"https://oceanwatch.pifsc.noaa.gov/erddap\")",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#examine-metadata",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#examine-metadata",
    "title": "Matchup satellite data to track locations",
    "section": "Examine metadata",
    "text": "Examine metadata\nrerddap::info returns the metadata of the requested dataset. We can first understand the attributes dataInfo includes then examine each attribute.\n\n# Display the metadata\ndataInfo\n\n&lt;ERDDAP info&gt; esa-cci-chla-monthly-v6-0 \n Base URL: https://oceanwatch.pifsc.noaa.gov/erddap \n Dataset Type: griddap \n Dimensions (range):  \n     time: (1997-09-04T00:00:00Z, 2023-12-01T00:00:00Z) \n     latitude: (-89.97916666666666, 89.97916666666667) \n     longitude: (0.020833333333314386, 359.97916666666663) \n Variables:  \n     chlor_a: \n         Units: mg m-3 \n     chlor_a_log10_bias: \n     chlor_a_log10_rmsd: \n     MERIS_nobs_sum: \n     MODISA_nobs_sum: \n     OLCI_A_nobs_sum: \n     OLCI_B_nobs_sum: \n     SeaWiFS_nobs_sum: \n     total_nobs_sum: \n     VIIRS_nobs_sum: \n\n# Display data attributes\nnames(dataInfo)\n\n[1] \"variables\" \"alldata\"   \"base_url\" \n\n# Examine attribute: variables\ndataInfo$variables\n\n        variable_name data_type actual_range\n1             chlor_a     float             \n2  chlor_a_log10_bias     float             \n3  chlor_a_log10_rmsd     float             \n4      MERIS_nobs_sum     float             \n5     MODISA_nobs_sum     float             \n6     OLCI_A_nobs_sum     float             \n7     OLCI_B_nobs_sum     float             \n8    SeaWiFS_nobs_sum     float             \n9      total_nobs_sum     float             \n10     VIIRS_nobs_sum     float             \n\n# Distribute attributes of dataInfo$alldata\nnames(dataInfo$alldata)\n\n [1] \"NC_GLOBAL\"          \"time\"               \"latitude\"          \n [4] \"longitude\"          \"chlor_a\"            \"MERIS_nobs_sum\"    \n [7] \"MODISA_nobs_sum\"    \"OLCI_A_nobs_sum\"    \"OLCI_B_nobs_sum\"   \n[10] \"SeaWiFS_nobs_sum\"   \"VIIRS_nobs_sum\"     \"chlor_a_log10_bias\"\n[13] \"chlor_a_log10_rmsd\" \"total_nobs_sum\"    \n\n\n\nExtract data using the rxtracto function\nFirst we need to define the bounding box within which to search for coordinates. The rxtracto function allows you to set the size of the box used to collect data around the track points using the xlen and ylen arguments. The values for xlen and ylen are in degrees. For our example, we can use 0.2 degrees for both arguments. Note: You can also submit vectors for xlen and ylen, as long as they are the same length as xcoord, ycoord, and tcoord if you want to set a different search radius around each track point.\n\n# Set the variable we want to extract data from:\nparameter &lt;- 'chlor_a'\n\n# Set xlen, ylen to 0.2 degree\nxlen &lt;- 0.2 \nylen &lt;- 0.2\n\n# Create date column using year, month and day in a format ERDDAP will understand (eg. 2008-12-15)\nturtle_df$date &lt;- as.Date(paste(turtle_df$year, turtle_df$month, turtle_df$day, sep=\"-\"))\n\n# Get variables x, y, t coordinates from turtle track data\nxcoords &lt;- turtle_df$mean_lon\nycoords &lt;- turtle_df$mean_lat\ntcoords &lt;- turtle_df$date\n\n# Extract satellite data using x, y, t coordinates from turtle track data\nchl_track &lt;- rxtracto(dataInfo, \n                  parameter=parameter, \n                  xcoord=xcoords, ycoord=ycoords, \n                  tcoord=tcoords, xlen=xlen, ylen=ylen)",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#check-the-output-of-the-rxtracto-function",
    "title": "Matchup satellite data to track locations",
    "section": "Check the output of the rxtracto function",
    "text": "Check the output of the rxtracto function\n\n# Check all variables extracted using rxtracto\nchl_track\n\n$`mean chlor_a`\n [1] 0.26779765 0.12073122 0.30777924 0.31780368 0.28884829 0.36146353\n [7] 0.22923882 0.11644071 0.09268904 0.05536651 0.18447913 0.22765385\n[13] 0.23869553 0.24669819 0.35838123 0.09624625 0.12024124 0.11400095\n[19] 0.10017463 0.09397742 0.08515869 0.06913812 0.14883095 0.51560753\n[25] 0.65806269\n\n$`stdev chlor_a`\n [1] 0.032191816 0.007231171 0.036716832 0.041052758 0.027952051 0.053364804\n [7] 0.024394244 0.007282479 0.003880810 0.001490017 0.040774493 0.025363286\n[13] 0.014782180 0.013523678 0.036640145 0.004842596 0.004098601 0.003910613\n[19] 0.003537558 0.005928580 0.007001476 0.004942355 0.011980482 0.099209610\n[25] 0.149563991\n\n$n\n [1] 36 36 36 27 36 30 36 36 30 30 30 30 36 30 36 30 36 36 36 30 36 30 36 36 36\n\n$`satellite date`\n [1] \"2005-05-01T00:00:00Z\" \"2005-07-01T00:00:00Z\" \"2005-08-01T00:00:00Z\"\n [4] \"2005-10-01T00:00:00Z\" \"2005-12-01T00:00:00Z\" \"2006-01-01T00:00:00Z\"\n [7] \"2006-03-01T00:00:00Z\" \"2006-05-01T00:00:00Z\" \"2006-06-01T00:00:00Z\"\n[10] \"2006-08-01T00:00:00Z\" \"2006-09-01T00:00:00Z\" \"2006-11-01T00:00:00Z\"\n[13] \"2007-01-01T00:00:00Z\" \"2007-02-01T00:00:00Z\" \"2007-04-01T00:00:00Z\"\n[16] \"2007-06-01T00:00:00Z\" \"2007-07-01T00:00:00Z\" \"2007-09-01T00:00:00Z\"\n[19] \"2007-11-01T00:00:00Z\" \"2007-12-01T00:00:00Z\" \"2008-02-01T00:00:00Z\"\n[22] \"2008-04-01T00:00:00Z\" \"2008-05-01T00:00:00Z\" \"2008-07-01T00:00:00Z\"\n[25] \"2008-08-01T00:00:00Z\"\n\n$`requested lon min`\n [1] 176.5194 175.7609 180.4926 183.4102 186.8997 193.2152 198.9158 196.2679\n [9] 194.2116 192.7545 193.9788 191.9444 191.6600 194.9631 199.2066 205.5050\n[17] 210.1805 215.6225 222.9073 225.5386 232.3064 239.4530 245.7716 248.4710\n[25] 245.6579\n\n$`requested lon max`\n [1] 176.7194 175.9609 180.6926 183.6102 187.0997 193.4152 199.1158 196.4679\n [9] 194.4116 192.9545 194.1788 192.1444 191.8600 195.1631 199.4066 205.7050\n[17] 210.3805 215.8225 223.1073 225.7386 232.5064 239.6530 245.9716 248.6710\n[25] 245.8579\n\n$`requested lat min`\n [1] 32.57873 34.95773 40.30576 41.58480 37.26623 32.03793 32.01126 34.81224\n [9] 34.59661 36.99175 41.66933 38.12796 34.63858 31.63964 34.24324 35.02771\n[17] 38.36083 39.23749 35.76793 30.08540 28.22859 25.88108 24.73662 23.62417\n[25] 26.68177\n\n$`requested lat max`\n [1] 32.77873 35.15773 40.50576 41.78480 37.46623 32.23793 32.21126 35.01224\n [9] 34.79661 37.19175 41.86933 38.32796 34.83858 31.83964 34.44324 35.22771\n[17] 38.56083 39.43749 35.96793 30.28540 28.42859 26.08108 24.93662 23.82417\n[25] 26.88177\n\n$`requested z min`\n [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n\n$`requested z max`\n [1] NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA NA\n\n$`requested date`\n [1] \"2005-05-04\" \"2005-06-23\" \"2005-08-12\" \"2005-10-01\" \"2005-11-20\"\n [6] \"2006-01-09\" \"2006-02-28\" \"2006-04-19\" \"2006-06-08\" \"2006-07-28\"\n[11] \"2006-09-16\" \"2006-11-05\" \"2006-12-25\" \"2007-02-13\" \"2007-04-04\"\n[16] \"2007-05-24\" \"2007-07-13\" \"2007-09-01\" \"2007-10-21\" \"2007-12-10\"\n[21] \"2008-01-29\" \"2008-03-19\" \"2008-05-08\" \"2008-06-27\" \"2008-08-16\"\n\n$`median chlor_a`\n [1] 0.26985641 0.11935977 0.31413330 0.31312889 0.28226255 0.35456662\n [7] 0.22596541 0.11711950 0.09256660 0.05540323 0.18355133 0.22467585\n[13] 0.24202415 0.24848759 0.34953472 0.09518800 0.11983451 0.11379882\n[19] 0.10012896 0.09296544 0.08735247 0.06766215 0.14883141 0.49834299\n[25] 0.67895702\n\n$`mad chlor_a`\n [1] 0.030100095 0.008344179 0.039171724 0.027213317 0.023952735 0.049566912\n [7] 0.022928175 0.009027836 0.003463391 0.001267676 0.035848973 0.026539111\n[13] 0.016244819 0.011793729 0.035606685 0.003954114 0.002984454 0.002953619\n[19] 0.002999692 0.003767908 0.003242842 0.003565519 0.015092995 0.109981245\n[25] 0.133971250\n\nattr(,\"row.names\")\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\" \"11\" \"12\" \"13\" \"14\" \"15\"\n[16] \"16\" \"17\" \"18\" \"19\" \"20\" \"21\" \"22\" \"23\" \"24\" \"25\"\nattr(,\"class\")\n[1] \"list\"          \"rxtractoTrack\"\nattr(,\"base_url\")\n[1] \"https://oceanwatch.pifsc.noaa.gov/erddap/\"\nattr(,\"datasetid\")\n[1] \"esa-cci-chla-monthly-v6-0\"\n\n\nrxtracto computes statistics using all the pixels found in the search radius around each track point.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-plottrack",
    "title": "Matchup satellite data to track locations",
    "section": "Plotting the results using plotTrack",
    "text": "Plotting the results using plotTrack\nWe will use the “plotTrack” function to plot the results. “plotTrack” is a function of the “rerddapXtracto” package designed specifically to plot the results of the “rxtracto” function. It provides an easy way to make a quick plot, however it’s not very customizable.\n\n# Plot tracks with color: algae specifically designed for chlorophyll\nplotTrack(chl_track, xcoords, ycoords, tcoords, size=3, plotColor = 'viridis')",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#animating-the-track",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#animating-the-track",
    "title": "Matchup satellite data to track locations",
    "section": "Animating the track",
    "text": "Animating the track\nOne of the nice features of the “plotTrack” function is that it is very easy to make an animation of the track data. This will take a minute to run. It creates an animated gif that will display in the Rstudio viewer window once the encoding to gif is done.\n\n# Animate tracks\n\nmake180 &lt;- function(lon) {\n    ind &lt;- which(lon &gt; 180)\n    lon[ind] &lt;- lon[ind] - 360\n   return(lon)\n}\n\nplotTrack(chl_track, make180(xcoords), ycoords, tcoords, plotColor = 'viridis',\n                    animate = TRUE, cumulative = TRUE)\n\nNULL",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "href": "tutorials/r/4-matchup-satellite-data-to-track-locations.html#plotting-the-results-using-ggplot",
    "title": "Matchup satellite data to track locations",
    "section": "Plotting the results using ggplot",
    "text": "Plotting the results using ggplot\n\nCreate a data frame with the turtle track and the output of rxtracto\nIf we to do an customization of the plot, its better to plot the dat ausing ggplot. We will first create a data frame that contains longitudes and latitudes from the turtle and associated satellite chlor-a values.\n\n# Create a data frame of coords from turtle and chlor_a values \nnew_df &lt;- as.data.frame(cbind(xcoords, ycoords,  \n                              chl_track$`requested lon min`, \n                              chl_track$`requested lon max`, \n                              chl_track$`requested lat min`, \n                              chl_track$`requested lon max`,  \n                              chl_track$`mean chlor_a`))\n\n# Set variable names\nnames(new_df) &lt;- c(\"Lon\", \"Lat\", \"Matchup_Lon_Lower\", \"Matchup_Lon_Upper\", \"Matchup_Lat_Lower\", \"Matchup_Lat_Upper\",  \"Chlor_a\")\nwrite.csv(new_df, \"matchup_df.csv\")\n\n\n\nPlot using ggplot\n\n# Import world map\nmapWorld &lt;- map_data(\"world\", wrap=c(0,360))\n\n# Draw the track positions with associated chlora values\nggplot(new_df) +\n  geom_point(aes(Lon,Lat,color=log(Chlor_a))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\n\nExtracting XYT data by constructing the URL data requests manually\nFirst we need to set up the ERDDAP URL using the datasets ID and the name of the variable we are interested in. Note that we are requesting the data as .csv\ndata_url = \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_1d_2018_0.csv?chlor_a\"\nIdeally, we would work with daily data since we have one location per day. But chlorophyll data is severely affected by clouds (i.e. lots of missing data), so you might need to use weekly or even monthly data to get sufficient non-missing data. We will start with the monthly chl-a data since it contains fewer gaps.\n\n# Set erddap address\nerddap &lt;- \"https://oceanwatch.pifsc.noaa.gov/erddap/griddap/aqua_chla_monthly_2018_0.csv?chlor_a\"\n\n# Get longitude and latitude from turtle track data\nlon &lt;- turtle_df$mean_lon\nlat &lt;- turtle_df$mean_lat\n\n# Get time from turtle track data and convert into ERDDAP date format\ndates &lt;- mdy.date(turtle_df$month,turtle_df$day,turtle_df$year)\ndates2 &lt;- format(as.Date(dates), \"%Y-%m-%d\")\n\n# Initatilize tot variable where data will be downloaded to\ntot &lt;- rep(NA, 4)\n\n# Loop through each turtle track data\nfor (i in 1:dim(turtle_df)[1]) {\n\n   # Create erddap URL by adding lat, lon, dates of each track point \n   url &lt;-  paste(erddap, \"[(\", dates2[i], \"):1:(\", dates2[i], \")][(\", lat[i], \"):1:(\", lat[i], \")][(\", lon[i], \"):1:(\", lon[i], \")]\", sep = \"\")  \n   \n   # Request and load satelite data from ERDDAP\n   new &lt;- read.csv(url, skip=2, header = FALSE) \n   \n   # Append the data\n   tot &lt;- rbind(tot, new)   \n}\n\n# Delete the first row (default column names)\ntot &lt;- tot[-1, ]\n\n# Rename columns\nnames(tot) &lt;- c(\"chlo_date\", \"matched_lat\", \"matched_lon\", \"matched_chl.m\")\n\n# Create data frame combining turtle track data and the chlo-a data\nchl_track2 &lt;- data.frame(turtle_df, tot)\n\n# Write the data frame to csv file\nwrite.csv(chl_track2, 'turtle-track-chl.m.csv', row.names = FALSE)\n\n\n\nMake a map of the data extracted using the second method\n\n# Draw the track positions with associated chlora values\nggplot(chl_track2) +\n  geom_point(aes(mean_lon,mean_lat,color=log(matched_chl.m))) +\n  geom_polygon(data = mapWorld, aes(x=long, y = lat, group = group)) + \n  coord_fixed(xlim = c(120,260),ylim = c(15,60)) +\n  scale_color_viridis(discrete = FALSE) +\n  labs(x=\"Longitude (deg)\", y=\"Latitude (deg)\", title=\"Turtle Track with chlor-a values\")+\n  theme(plot.title=element_text(hjust=0.5))\n\n\n\n\n\n\n\n\n\n\nPlot histogram of chlorophyll\nHow do the chlorophyll values of the turtle track compare to values in the surrounding environment? Meaning does the turtle seem to have a preference for certain chlorophyll values? To look at this we will plot a histograms of the track chl valuesand those of the surrounding area.\nFirst we will get a 3D block of chl data from the region and of the turtle track over the span of time the turtle was in that area. We will use the ‘xtracto_3d’ function of rerddapXtracto to get the data. This data call will take a few minutes.\n\nchl_grid &lt;- rxtracto_3D(dataInfo, \n                  parameter=parameter, \n                  xcoord=c(min(xcoords),max(xcoords)), \n                  ycoord=c(min(ycoords),max(ycoords)), \n                  tcoord=c(min(tcoords),max(tcoords)))\n\nchl_area &lt;- as.vector(chl_grid$chlor_a) \n\n# remove NA values \nchl_area &lt;- chl_area[!is.na(chl_area)]\n\n# vector or turtle chlorophyll \n\nchl_turtle &lt;- chl_track$`mean chlor_a`\n\nNow we we plot histograms of all the chlorphyll values in the area, and those of the turtle track. Since we subset the turtletrack, and only have 25 points for this subsampopled dataset the turtle histogram isn’t as useful as it would be with a larger dataset.\n\nggplot(as.data.frame(chl_area)) + \n      geom_histogram(aes(x=chl_area,y=after_stat(density),color = \"darkgray\",fill='Area'),color='black', bins=50) + \n      geom_histogram(data=as.data.frame(chl_turtle), aes(x=chl_turtle,y=after_stat(density),color='green', fill='Turtle'),color='black',bins=50, alpha=.4) + \n      scale_x_continuous(limits = c(0,.9), expand = c(0, 0)) + \n      scale_y_continuous(limits = c(0,15), expand = c(0, 0)) +\n      labs(x='Chlorophyll values',y='Density') + \n      theme_bw() + \n      scale_fill_manual(values=c(\"darkgray\",\"green\"),'')\n\n\n\n\n\n\n\n\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html \\* This dataset is a different ERDDAP, so remember to change the base URL. \\* Set the new dataset ID and variable name.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/ \\* This dataset will likely be on a different ERDDAP, so remember to change the base URL. \\* Set the new dataset ID and variable name. \\* Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://coastwatch.pfeg.noaa.gov/erddap/griddap/pmlEsaCCI60OceanColorDaily_Lon0360.html",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/2-subset-and-plot.html#load-packages",
    "href": "tutorials/r/2-subset-and-plot.html#load-packages",
    "title": "Subset and Plot",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(earthdatalogin)\nlibrary(gdalcubes)\nlibrary(terra)\n\nterra 1.7.71\n\n\n\nAttaching package: 'terra'\n\n\nThe following objects are masked from 'package:gdalcubes':\n\n    animate, crop, size",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/r/2-subset-and-plot.html#get-a-vector-of-urls-to-our-nc-files",
    "href": "tutorials/r/2-subset-and-plot.html#get-a-vector-of-urls-to-our-nc-files",
    "title": "Subset and Plot",
    "section": "Get a vector of urls to our nc files",
    "text": "Get a vector of urls to our nc files\n\nedl_netrc()\nwith_gdalcubes()\n\n\nshort_name &lt;- 'MUR-JPL-L4-GLOB-v4.1'\nbbox &lt;- c(xmin=-73.5, ymin=33.5, xmax=-43.5, ymax=43.5) \ntbox &lt;- c(\"2020-01-16\", \"2020-12-16\")\n\nresults &lt;- edl_search(\n    short_name = short_name,\n    version = \"4.1\",\n    temporal = tbox,\n    bounding_box = paste(bbox,collapse=\",\")\n)\n\nresults is a vector of urls pointing to our netCDF files in the cloud.\n\nresults[1:3]\n\n[1] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[2] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200117090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[3] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200118090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n\n\nEach netCDF file is ca 670Mb.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/r/2-subset-and-plot.html#crop-and-plot-one-image",
    "href": "tutorials/r/2-subset-and-plot.html#crop-and-plot-one-image",
    "title": "Subset and Plot",
    "section": "Crop and plot one image",
    "text": "Crop and plot one image\nEach MUR SST netCDF file is large so I do not want to download. Instead I will use terra::rast() to do subset the data on the server side.\n\nlibrary(terra)\nras &lt;- terra::rast(results[1], vsi=TRUE)\ne &lt;- ext(c(-75.5, -73.5,  33.5, 35.5 ))\nrc &lt;- crop(ras, e)\nplot(rc[[c(1, 2)]])",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/r/2-subset-and-plot.html#stop-not-worked-below-yet",
    "href": "tutorials/r/2-subset-and-plot.html#stop-not-worked-below-yet",
    "title": "Subset and Plot",
    "section": "STOP NOT WORKED BELOW YET",
    "text": "STOP NOT WORKED BELOW YET\n\nExplore earthdatalogin search response\nresults is a vector of urls to the netCDF files.\n\nresults[1:3]\n\n[1] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[2] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200117090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[3] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200118090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n\n\nNotice it will start with https: or s3:. The former is a slower from of access while the latter allows faster access, like having a cloud bucket attached as a drive to your browser.\n\nlength(results)\n\n[1] 336\n\n\n\nr &lt;- terra::rast(results[1], vsi=TRUE)\n\n\n\nOpen results in a data cube\nBased on: https://boettiger-lab.github.io/nasa-topst-env-justice/tutorials/R/2-earthdata.html\nUnfortunately these netCDF files lack appropriate metadata (projection, extent) that GDAL expects. We can provide this manually using the GDAL VRT mechanism:\n\nvrt &lt;- function(url) {\n  prefix &lt;-  \"vrt://NETCDF:/vsicurl/\"\n  suffix &lt;- \":analysed_sst?a_srs=OGC:CRS84&a_ullr=-180,90,180,-90\"\n  paste0(prefix, url, suffix)\n}\n\n# date associated with each file\nurl_dates &lt;- as.Date(gsub(\".*(\\\\d{8})\\\\d{6}.*\", \"\\\\1\", results), format=\"%Y%m%d\")",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/r/2-subset-and-plot.html#conclusions",
    "href": "tutorials/r/2-subset-and-plot.html#conclusions",
    "title": "Subset and Plot",
    "section": "Conclusions",
    "text": "Conclusions\nSome really cool things just happened here! Not only were we able to seamlessly stream our earthaccess search results into a xarray dataset using the open_mfdataset() (multi-file) method, but earthaccess determined that we were working from within AWS us-west-2 and accessed the data via direct S3 access! We didn’t have to create a session or a filesystem to authenticate and connect to the data. earthaccess did this for us using the auth object we created at the beginning of this tutorial. If we were not working in AWS us-west-2, earthaccess would “automagically” switch to accessing the data via the HTTPS endpoints and would again handle the authentication for us.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/r/2-subset-and-plot.html#resources",
    "href": "tutorials/r/2-subset-and-plot.html#resources",
    "title": "Subset and Plot",
    "section": "Resources",
    "text": "Resources\n\nNASA’s Common Metadata Repository (CMR) API\n\nearthaccess repository\nearthaccess documentation\nEarthdata Search",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html",
    "href": "tutorials/r/05-r-geospatial.html",
    "title": "Geospatial in R - lab 1",
    "section": "",
    "text": "require(sf)\nrequire(mapview)\nrequire(readr)\nrequire(readxl)\nhere::i_am(\"tutorials/r/05-r-geospatial.qmd\")\ndir_data &lt;- here::here(\"tutorials\", \"data\")\nIn this lab, you will learn basic skills of working with points. We will store our points in data frames. All our points data frames will have these columns:\nBut the columns names are often shortened to lon, lat or lng, latd or anything else.\nIn addition they will have other info in other columns."
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#create-a-data-frame-of-points",
    "href": "tutorials/r/05-r-geospatial.html#create-a-data-frame-of-points",
    "title": "Geospatial in R - lab 1",
    "section": "Create a data frame of points",
    "text": "Create a data frame of points\n\nlibrary(mapview)\n  \n# Create example data of points\nlon &lt;- c(85.21, 80.23, 77.28)\nlat = c(25.59, 12.99, 28.56)\nnames = c(\"Patna\", \"Chennai\", \"New Delhi\")\n  \n# Create a data frame with the point data\ndf &lt;- data.frame(lon, lat, names)"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#convert-to-a-spatial-points-data-frame",
    "href": "tutorials/r/05-r-geospatial.html#convert-to-a-spatial-points-data-frame",
    "title": "Geospatial in R - lab 1",
    "section": "Convert to a spatial points data frame",
    "text": "Convert to a spatial points data frame\n\n\n\n\n\n\nCore skill\n\n\n\nConvert data frame with latitude and longitude columns to a geospatial object with a geometry column and coordinate system. We are setting the coordinate system to WGS 84 with crs = 4326.\n\nsf::st_as_sf() function\n\n\n\nThis is a special data frame where the location data is converted to a single point object.\n\ncities3 &lt;- sf::st_as_sf(\n    df, # the data frame\n    coords = c(\"lon\", \"lat\"), # what are the x and y dimension names\n    crs = 4326)\n\nLook at the class of the object\n\nclass(cities3)\n\n[1] \"sf\"         \"data.frame\""
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#plot-the-points",
    "href": "tutorials/r/05-r-geospatial.html#plot-the-points",
    "title": "Geospatial in R - lab 1",
    "section": "Plot the points",
    "text": "Plot the points\n\nplot(cities3)\n\n\n\n\n\n\n\n\nIt plotted but it is not very useful. Let’s use the helper package mapview. That’s more useful.\n\nmapview::mapview(cities3, label = cities3$names)"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#read-in-points-from-files",
    "href": "tutorials/r/05-r-geospatial.html#read-in-points-from-files",
    "title": "Geospatial in R - lab 1",
    "section": "Read in points from files",
    "text": "Read in points from files\n\n\n\n\n\n\nCore skill\n\n\n\nRead in tabular data with latitude, longitude into a data frame.\n\nreadr::read_csv() or readxl::read_excel()"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#from-a-csv-file",
    "href": "tutorials/r/05-r-geospatial.html#from-a-csv-file",
    "title": "Geospatial in R - lab 1",
    "section": "from a csv file",
    "text": "from a csv file\nHere I use a URL to a csv file. However I could use fil &lt;- file.path(\"data\", \"india_tide_guages.csv\") since I have the data file in a directory data in the same folder as my Quarto file (or RMarkdown or R script).\n\nfil &lt;- here::here(\"tutorials\", \"data\", \"india_tide_guages.csv\")\ndf2 &lt;- readr::read_csv(fil, show_col_types = FALSE)\n\nConvert to spatial data frame. Notice, I had to change the latitude and longitude to match the columns names in the dataframe.\n\nsdf &lt;- sf::st_as_sf(\n    df2, \n    coords = c(\"Longitude\", \"Latitude\"), # what are the x and y dimension names\n    crs = 4326)\n\nMap. You can click on the points to get more info.\n\nmapview::mapview(sdf)\n\n\n\n\n\nIf you want state labels, you need to only have the geometry and label columns in the dataframe.\n\nsdf2 &lt;- sdf %&gt;% select(geometry, State)\nmapview::mapview(sdf2, label = sdf2$State)\n\n\nfrom Excel file\n\nfil &lt;- here::here(\"tutorials\", \"data\", \"india_tide_guages.xlsx\")\ndf3 &lt;- readxl::read_excel(fil, sheet = \"Kerala\")\n\nConvert to spatial points.\n\nsdf = sf::st_as_sf(\n    df3, \n    coords = c(\"Longitude\", \"Latitude\"), \n    crs = 4326)\n\n\nmapview::mapview(sdf)"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#using-ggplot2",
    "href": "tutorials/r/05-r-geospatial.html#using-ggplot2",
    "title": "Geospatial in R - lab 1",
    "section": "Using ggplot2",
    "text": "Using ggplot2\nHere is a gallery of some basic plots you can make. There are many ways to make maps with ggplot2. I will use a single approach that is fairly flexible.\n\n\n\n\n\n\nCore skill\n\n\n\nCreate a base world and India map from rnaturalearth. Plot with ggplot2.\n\nne_countries()\nggplot() + geom_sf()\ncoord_sf()\n\n\n\n\nIndia alone\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nindia_sf &lt;- ne_countries(country = \"India\", scale = \"medium\", returnclass = \"sf\")\nbasemap &lt;- ggplot() + \n  geom_sf(data = india_sf, color = \"black\", size = 2, fill=\"green\") +\n  coord_sf(xlim = c(58, 98), ylim = c(6, 30))\nbasemap\n\n\n\n\n\n\n\n\n\nfil &lt;- here::here(\"tutorials\", \"data\", \"india.jpeg\")\nggsave(filename = fil, plot = basemap, device = \"jpeg\")\n\nSaving 7 x 5 in image\n\n\n\n\n\n\n\n\nCore skill\n\n\n\nAdd points to a plot.\n\ngeom_sf(data=points_df)\n\n\n\nAdd points\n\nbasemap + \n  geom_sf(data = cities3, aes(color = names), size = 3) +\n  theme_void()\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one.\n\n\n\n\n\n\n\n\n\n\n\nThe world\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nbasemap &lt;- ggplot() + \n  geom_sf(data = world_sf, color = \"black\", size = 0.2, fill=\"lightblue\")\nbasemap\n\n\n\n\n\n\n\n\nAdd points\n\nbasemap + \n  geom_sf(data = cities3, aes(color = names), size = 1)\n\n\n\n\n\n\n\n\nZoom in\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nbasemap &lt;- ggplot() + \n  geom_sf(data = world_sf, color = \"black\", size = 0.2, fill=\"lightblue\") +\n  coord_sf(xlim = c(58, 98), ylim = c(0, 30))\nbasemap\n\n\n\n\n\n\n\n\nAdd points\n\nbasemap + \n  geom_sf(data = cities3, aes(color = names), size = 2) +\n  coord_sf(xlim = c(58, 98), ylim = c(0, 30))\n\nCoordinate system already present. Adding new coordinate system, which will\nreplace the existing one."
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#change-the-projection",
    "href": "tutorials/r/05-r-geospatial.html#change-the-projection",
    "title": "Geospatial in R - lab 1",
    "section": "Change the projection",
    "text": "Change the projection\n\n\n\n\n\n\nCore skill\n\n\n\nApply a coordinate reference system to a sf object.\n\nst_transform(sf_object, crs=crs)\n\nCommon CRS’s\n\ncrs = 4326 WGS 84\nRobinson crs = \"+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\nGlobe crs = \"+proj=laea +lon_0=77 +lat_0=20 +ellps=WGS84 +no_defs\"\n\n\n\nMake a world in Robinson coord system.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\ncrs &lt;- \"+proj=robin +lon_0=0 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs\" \nworld_crs &lt;- st_transform(world_sf, crs=crs)\nbasemap &lt;- ggplot() +\n  geom_sf(data = world_crs, color = \"black\", size = 0.2, fill=\"lightblue\") +\n  theme_minimal()\nbasemap\n\n\n\n\n\n\n\n\nAdd points.\n\ncities3_robin &lt;- st_transform(cities3, crs=crs)\nbasemap + \n  geom_sf(data = cities3_robin, aes(color = names), size = 2)\n\n\n\n\n\n\n\n\nMake a globe.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\ncrs &lt;- \"+proj=laea +lon_0=77 +lat_0=20 +ellps=WGS84 +no_defs\"\nworld_crs &lt;- sf::st_transform(world_sf, crs)\nbasemap &lt;- ggplot() +\n  geom_sf(data = world_crs, color = \"black\", size = 0.2, fill=\"lightblue\") +\n  theme_minimal()\nbasemap\n\n\n\n\n\n\n\n\nAdd points.\n\ncities3_crs &lt;- st_transform(cities3, crs=crs)\nbasemap + \n  geom_sf(data = cities3_crs, aes(color = names), size = 2)\n\n\n\n\n\n\n\n\nAdd a circle around the globe.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nworld_sf &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\ncrs &lt;- \"+proj=laea +lon_0=77 +lat_0=20 +ellps=WGS84 +no_defs\"\nworld_crs &lt;- sf::st_transform(world_sf, crs)\n\nsphere &lt;- st_graticule(ndiscr = 10000, margin = 10e-6) %&gt;%\n  st_transform(crs = crs) %&gt;%\n  st_convex_hull() %&gt;%\n  summarise(geometry = st_union(geometry))\n\nbasemap &lt;- ggplot()  +\n  geom_sf(data = sphere, fill = \"#D8F4FF\", alpha = 0.7) +\n  geom_sf(data = world_crs, fill=\"grey\") +\n  theme_bw()\nbasemap\n\n\n\n\n\n\n\n\nAdd points and remove legend.\n\n# Add crs\ncities3_crs &lt;- st_transform(cities3, crs=crs)\nbasemap + \n  geom_sf(data = cities3_crs, aes(color = names), size = 1) +\n  theme(legend.position = \"none\")"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#getting-help-from-ai",
    "href": "tutorials/r/05-r-geospatial.html#getting-help-from-ai",
    "title": "Geospatial in R - lab 1",
    "section": "Getting help from AI",
    "text": "Getting help from AI\nUnfortunately, ChatGPT often gets confused with mapping and gives you code that doesn’t fully work. This can be hard for beginners (and experts) to debug.\nTry telling it\n\nUse only the sf, rnaturalearth, and ggplot2 packages\nWork in steps, “Make a sf points object and name it sf_points”, “Using sf_points”, add these points to a map of the world.”"
  },
  {
    "objectID": "tutorials/r/05-r-geospatial.html#your-turn",
    "href": "tutorials/r/05-r-geospatial.html#your-turn",
    "title": "Geospatial in R - lab 1",
    "section": "Your Turn!",
    "text": "Your Turn!\nMake some maps using mapview of your own data, data in the “r-tutorials/data” directory or data you can find on-line.\nTry the layer feature to change the base map."
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan or frequency measurements, or spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of locations with boundaries include Marine Protected Areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server\nVisualizing data on a map\nMasking satellite data using a shape file",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nNOAA Geo-polar Blended Analysis Sea-Surface Temperature, Global, Monthly, 5km, 2019-Present\nThe NOAA geo-polar blended SST is a high resolution satellite-based sea surface temperature (SST) product that combines SST data from US, Japanese and European geostationary infrared imagers, and low-earth orbiting infrared (U.S. and European) SST data, into a single product. We will use the monthly composite. https://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#import-packages",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#import-packages",
    "title": "Extract data within a boundary",
    "section": "Import packages",
    "text": "Import packages\nNote: Make sure you have at least version 0.10.0 of regionmask * To install with conda use “conda install -c conda-forge regionmask=0.10.0 cartopy”\n\nimport matplotlib.pyplot as plt\nimport xarray as xr\nimport geopandas\nimport regionmask\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport warnings\nimport os\nwarnings.filterwarnings('ignore')",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#load-the-longhurst-provinces-shape-files-into-a-geopandas-dataframe",
    "title": "Extract data within a boundary",
    "section": "Load the Longhurst Provinces shape files into a geopandas dataframe",
    "text": "Load the Longhurst Provinces shape files into a geopandas dataframe\n\n#shape_path = '../resources/longhurst_v4_2010/Longhurst_world_v4_2010.shp'\nshape_path = os.path.join('..',\n                          'resources',\n                          'longhurst_v4_2010',\n                          'Longhurst_world_v4_2010.shp'\n                          )\nshapefiles = geopandas.read_file(shape_path)\nshapefiles.head(8)\n\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n0\nBPLR\nPolar - Boreal Polar Province (POLR)\nMULTIPOLYGON (((-161.18426 63.50000, -161.5000...\n\n\n1\nARCT\nPolar - Atlantic Arctic Province\nMULTIPOLYGON (((-21.51305 64.64409, -21.55945 ...\n\n\n2\nSARC\nPolar - Atlantic Subarctic Province\nMULTIPOLYGON (((11.26472 63.96082, 11.09548 63...\n\n\n3\nNADR\nWesterlies - N. Atlantic Drift Province (WWDR)\nPOLYGON ((-11.50000 57.50000, -11.50000 56.500...\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500...\n\n\n5\nNASW\nWesterlies - N. Atlantic Subtropical Gyral Pro...\nPOLYGON ((-39.50000 25.50000, -40.50000 25.500...\n\n\n6\nNATR\nTrades - N. Atlantic Tropical Gyral Province (...\nMULTIPOLYGON (((-72.34673 18.53597, -72.36877 ...\n\n\n7\nWTRA\nTrades - Western Tropical Atlantic Province\nPOLYGON ((-19.50000 -6.50000, -20.50000 -6.500...",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#isolate-the-gulf-stream-province",
    "title": "Extract data within a boundary",
    "section": "Isolate the Gulf Stream Province",
    "text": "Isolate the Gulf Stream Province\nThe Gulf Stream Province can be isolated using its ProvCode (GFST)\n\nProvCode = \"GFST\"\n\n# Locate the row with the ProvCode code\ngulf_stream = shapefiles.loc[shapefiles[\"ProvCode\"] == ProvCode]\ngulf_stream\n\n\n\n\n\n\n\n\n\nProvCode\nProvDescr\ngeometry\n\n\n\n\n4\nGFST\nWesterlies - Gulf Stream Province\nPOLYGON ((-43.50000 43.50000, -43.50000 42.500...",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#find-the-coordinates-of-the-bounding-box",
    "title": "Extract data within a boundary",
    "section": "Find the coordinates of the bounding box",
    "text": "Find the coordinates of the bounding box\n\nThe bounding box is the smallest rectangle that will completely enclose the province.\nWe will use the bounding box coordinates to subset the satellite data\n\n\ngs_bnds = gulf_stream.bounds\ngs_bnds\n\n\n\n\n\n\n\n\n\nminx\nminy\nmaxx\nmaxy\n\n\n\n\n4\n-73.5\n33.5\n-43.5\n43.5",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#open-the-satellite-dataset-into-a-xarray-dataset-object",
    "title": "Extract data within a boundary",
    "section": "Open the satellite dataset into a xarray dataset object",
    "text": "Open the satellite dataset into a xarray dataset object\n\nerddap_url = '/'.join(['https://coastwatch.pfeg.noaa.gov',\n                       'erddap',\n                       'griddap',\n                       'NOAA_DHW_monthly'\n                       ])\n\nds = xr.open_dataset(erddap_url)\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                          (time: 464, latitude: 3600, longitude: 7200)\nCoordinates:\n  * time                             (time) datetime64[ns] 1985-01-16 ... 202...\n  * latitude                         (latitude) float32 89.97 89.93 ... -89.97\n  * longitude                        (longitude) float32 -180.0 -179.9 ... 180.0\nData variables:\n    sea_surface_temperature          (time, latitude, longitude) float32 ...\n    mask                             (time, latitude, longitude) float32 ...\n    sea_surface_temperature_anomaly  (time, latitude, longitude) float32 ...\nAttributes: (12/66)\n    _NCProperties:                    version=2,netcdf=4.8.1,hdf5=1.12.2\n    acknowledgement:                  NOAA Coral Reef Watch program\n    cdm_data_type:                    Grid\n    comment:                          This is a product of NOAA Coral Reef Wa...\n    contributor_name:                 NOAA Coral Reef Watch program\n    contributor_role:                 Collecting source data and deriving pro...\n    ...                               ...\n    time_coverage_duration:           P1M\n    time_coverage_end:                2023-08-16T00:00:00Z\n    time_coverage_resolution:         P1M\n    time_coverage_start:              1985-01-16T00:00:00Z\n    title:                            SST and SST Anomaly, NOAA Global Coral ...\n    Westernmost_Easting:              -179.975xarray.DatasetDimensions:time: 464latitude: 3600longitude: 7200Coordinates: (3)time(time)datetime64[ns]1985-01-16 ... 2023-08-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['1985-01-16T00:00:00.000000000', '1985-02-16T00:00:00.000000000',\n       '1985-03-16T00:00:00.000000000', ..., '2023-06-16T00:00:00.000000000',\n       '2023-07-16T00:00:00.000000000', '2023-08-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3289.97 89.93 89.88 ... -89.92 -89.97_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([ 89.975   ,  89.92501 ,  89.87501 , ..., -89.875   , -89.924995,\n       -89.975   ], dtype=float32)longitude(longitude)float32-180.0 -179.9 ... 179.9 180.0_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-179.975  , -179.925  , -179.875  , ...,  179.875  ,  179.92499,\n        179.975  ], dtype=float32)Data variables: (3)sea_surface_temperature(time, latitude, longitude)float32...colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0[12026880000 values with dtype=float32]mask(time, latitude, longitude)float32...colorBarMaximum :5.0colorBarMinimum :0.0comment :A 2D array, in the same size as the data array in the X and Y directions, the classifies land, ice pixels, and water (data) pixelscoverage_content_type :thematicClassificationflag_meanings :valid-water land missing iceflag_values :[0 1 2 4]ioos_category :Qualitylong_name :Pixel characteristics flag arrayunits :pixel_classification[12026880000 values with dtype=float32]sea_surface_temperature_anomaly(time, latitude, longitude)float32...colorBarMaximum :3.0colorBarMinimum :-3.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :sea surface temperature anomalystandard_name :surface_temperature_anomalyunits :degree_Cvalid_max :15.0valid_min :-15.0[12026880000 values with dtype=float32]Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['1985-01-16 00:00:00', '1985-02-16 00:00:00',\n               '1985-03-16 00:00:00', '1985-04-16 00:00:00',\n               '1985-05-15 23:00:00', '1985-06-15 23:00:00',\n               '1985-07-15 23:00:00', '1985-08-15 23:00:00',\n               '1985-09-15 23:00:00', '1985-10-15 23:00:00',\n               ...\n               '2022-11-16 00:00:00', '2022-12-16 00:00:00',\n               '2023-01-16 00:00:00', '2023-02-16 00:00:00',\n               '2023-03-16 00:00:00', '2023-04-16 00:00:00',\n               '2023-05-16 00:00:00', '2023-06-16 00:00:00',\n               '2023-07-16 00:00:00', '2023-08-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', length=464, freq=None))latitudePandasIndexPandasIndex(Index([  89.9749984741211,  89.92501068115234,  89.87500762939453,\n        89.82500457763672,   89.7750015258789,   89.7249984741211,\n        89.67501068115234,  89.62500762939453,  89.57500457763672,\n         89.5250015258789,\n       ...\n        -89.5250015258789, -89.57499694824219,            -89.625,\n       -89.67499542236328,  -89.7249984741211,  -89.7750015258789,\n       -89.82499694824219,            -89.875, -89.92499542236328,\n        -89.9749984741211],\n      dtype='float32', name='latitude', length=3600))longitudePandasIndexPandasIndex(Index([-179.97500610351562,  -179.9250030517578,            -179.875,\n       -179.82501220703125, -179.77500915527344, -179.72500610351562,\n        -179.6750030517578,            -179.625, -179.57501220703125,\n       -179.52500915527344,\n       ...\n        179.52499389648438,  179.57501220703125,             179.625,\n        179.67498779296875,  179.72500610351562,  179.77499389648438,\n        179.82501220703125,             179.875,  179.92498779296875,\n        179.97500610351562],\n      dtype='float32', name='longitude', length=7200))Attributes: (66)_NCProperties :version=2,netcdf=4.8.1,hdf5=1.12.2acknowledgement :NOAA Coral Reef Watch programcdm_data_type :Gridcomment :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite Version 3.1, derived from CoralTemp v1.0.contributor_name :NOAA Coral Reef Watch programcontributor_role :Collecting source data and deriving products; performing quality control of products; disseminating, storing, and submitting data to archive.Conventions :CF-1.6, ACDD-1.3, COARDScreator_email :coralreefwatch@noaa.govcreator_institution :NOAA/NESDIS/STAR Coral Reef Watch programcreator_name :NOAA Coral Reef Watch programcreator_type :groupcreator_url :https://coralreefwatch.noaa.govdate_created :2018-03-01T12:00:00Zdate_issued :2019-01-19T20:32:23Zdate_metadata_modified :2018-09-01T12:00:00Zdate_modified :2018-03-01T12:00:00ZEasternmost_Easting :179.975geospatial_bounds :POLYGON((-90.0 180.0, 90.0 180.0, 90.0 -180.0, -90.0 -180.0, -90.0 180.0))geospatial_bounds_crs :EPSG:4326geospatial_lat_max :89.975geospatial_lat_min :-89.975geospatial_lat_units :degrees_northgeospatial_lon_max :179.975geospatial_lon_min :-179.975geospatial_lon_units :degrees_eastgrid_mapping_epsg_code :EPSG:32663grid_mapping_inverse_flattening :298.2572grid_mapping_name :latitude_longitudegrid_mapping_semi_major_axis :6378137.0history :Tue Jul 27 10:37:54 2021: ncrename -d lon,longitude -d lat,latitude -v lon,longitude -v lat,latitude -v sea surface temperature anomaly,sea_surface_temperature_anomaly /cwdata/coralreef/work/temp.nc\nMonthly data files for mean sea surface temperature (SST) and sea surface temperature anomaly (SST anomaly) were downloaded from ftp.star.nesdis.noaa.gov/pub/sod/mecb/crw/data/5km/v3.1/nc/v1.0/monthly. Monthly files were created that contain both SST and SST anomaly data, and a mask of earth surface classifications.\n2023-09-06T18:39:14Z (local files)\n2023-09-06T18:39:14Z http://coastwatch.pfeg.noaa.gov/erddap/griddap/NOAA_DHW_monthly.dasid :Satellite_Global_5km_CoralTemp_SST_SSTA_Monthly_Mean_CompositeinfoUrl :https://coralreefwatch.noaa.gov/product/5km/index.phpinstitution :NOAA/NESDIS/STAR Coral Reef Watch programinstrument :ATSR-1, ATSR-2, AATSR, AVHRR, AVHRR-2, AVHRR-3, VIIRS, GOES Imager, MTSAT Imager, MTSAT 2 Imager, AHI, ABI, SEVIRI, buoy - moored buoy, buoy - drifting buoy, buoy - TAO buoy, surface seawater intakeinstrument_vocabulary :NOAA NODC Ocean Archive System Instrumentskeywords :5km, analysed, anomaly, array, characteristics, coral, crw, data, earth, Earth Science &gt; Land Surface &gt; Land Temperature &gt; Land Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Sea Surface Temperature Anomaly, Earth Science &gt; Oceans &gt; Ocean Temperature &gt; Water Temperature, Earth Science &gt; Spectral/Engineering &gt; Infrared Wavelengths &gt; Thermal Infrared, engineering, environmental, flag, global, information, infrared, land, latitude, longitude, mask, mean, month, monthly, national, nesdis, noaa, ocean, oceans, pixel, program, quality, reef, satellite, science, sea, sea_surface_temperature, sea_surface_temperature_anomaly, seawater, service, spectral, spectral/engineering, sst, star, surface, surface_temperature_anomaly, temperature, thermal, time, v.3.1, watch, water, wavelengthskeywords_vocabulary :GCMD Science Keywordslicense :The data produced by Coral Reef Watch are available for use without restriction, but Coral Reef Watch relies on the ethics and integrity of the user to ensure that the source of the data and products is appropriately cited and credited. When using these data and products, credit and courtesy should be given to NOAA Coral Reef Watch. Please include the appropriate DOI associated with this dataset in the citation. For more information, visit the NOAA Coral Reef Watch website: https://coralreefwatch.noaa.gov. Recommendations for citing and providing credit are provided at https://coralreefwatch.noaa.gov/satellite/docs/recommendations_crw_citation.php. Users are referred to the footer section of the Coral Reef Watch website (https://coralreefwatch.noaa.gov/index.php) for disclaimers, policies, notices pertaining to the use of the data.metadata_link :https://coralreefwatch.noaa.gov/product/5km/index.phpnaming_authority :gov.noaa.coralreefwatchNCO :\"4.6.3\"Northernmost_Northing :89.975platform :Ships, drifting buoys, moored buoys, TOGA-TAO buoy arrays, GOES-8 satellite, GOES-9 satellite, GOES-10 satellite, GOES-11 satellite, GOES-12 satellite, GOES-13 satellite, GOES-14 satellite, GOES-15 satellite, GOES-16 satellite, MTSAT-1R satellite, MTSAT-2 satellite, Himawari-8 satellite, Meteosat-8 satellite, Meteosat-9 satellite, Meteoset-10 satellite, Meteosat-11 satellite, Suomi NPP, MetOp-A satellite, MetOp-B satellite, NOAA-9 satellite, NOAA-11 satellite, NOAA-12 satellite, NOAA-14 satellite, NOAA-15 satellite, NOAA-16 satellite, NOAA-17 satellite, NOAA-18 satellite, NOAA-19 satellite.platform_vocabulary :NOAA NODC Ocean Archive System Platformsprocessing_level :Derived from L4 satellite sea surface temperature analysisproduct_version :3.1program :NOAA Coral Reef Watch programproject :NOAA Coral Reef Watch programpublisher_email :erd.data at noaa.govpublisher_institution :NOAA/NESDIS/STAR Coral Reef Watch programpublisher_name :NOAA NMFS SWFSC ERD, CoastWatch West Coast Nodepublisher_type :institutionpublisher_url :https://coralreefwatch.noaa.gov, https://coastwatch.pfeg.noaa.gov/references :https://coralreefwatch.noaa.gov/product/5km/index.php and https://coralreefwatch.noaa.gov/satellite/coraltemp.phpsource :Coral Reef Watch CoralTemp v1.0sourceUrl :(local files)Southernmost_Northing :-89.975spatial_resolution :0.05 degreestandard_name_vocabulary :CF Standard Name Table v27summary :This is a product of NOAA Coral Reef Watch Global 5km Satellite Coral Bleaching Heat Stress Monitoring Product Suite, derived from CoralTemp v1.0.time_coverage_duration :P1Mtime_coverage_end :2023-08-16T00:00:00Ztime_coverage_resolution :P1Mtime_coverage_start :1985-01-16T00:00:00Ztitle :SST and SST Anomaly, NOAA Global Coral Bleaching Monitoring, 5km, V.3.1, Monthly, 1985-PresentWesternmost_Easting :-179.975",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#subset-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Subset the satellite data",
    "text": "Subset the satellite data\n\nUse the bounding box coordinates for the latitude and longitude slices\nSelect the entire year of 2020\n\n\n# This dataset has latitude in descending order. \n# Therefore use maxy first and miny last to slice latitude\nds_subset = ds['sea_surface_temperature'].sel(time=slice(\"2020-01-16\", \"2020-12-16\"),\n                                              latitude=slice(gs_bnds.maxy.item(), \n                                                             gs_bnds.miny.item()),\n                                              longitude=slice(gs_bnds.minx.item(), \n                                                              gs_bnds.maxx.item())\n                                            )\nds_subset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'sea_surface_temperature' (time: 12, latitude: 200,\n                                             longitude: 600)&gt;\n[1440000 values with dtype=float32]\nCoordinates:\n  * time       (time) datetime64[ns] 2020-01-16 2020-02-16 ... 2020-12-16\n  * latitude   (latitude) float32 43.47 43.43 43.38 43.33 ... 33.62 33.58 33.53\n  * longitude  (longitude) float32 -73.47 -73.42 -73.38 ... -43.62 -43.57 -43.53\nAttributes:\n    colorBarMaximum:        32.0\n    colorBarMinimum:        0.0\n    coverage_content_type:  physicalMeasurement\n    ioos_category:          Temperature\n    long_name:              analysed sea surface temperature\n    standard_name:          sea_surface_temperature\n    units:                  degree_C\n    valid_max:              50.0\n    valid_min:              -2.0xarray.DataArray'sea_surface_temperature'time: 12latitude: 200longitude: 600...[1440000 values with dtype=float32]Coordinates: (3)time(time)datetime64[ns]2020-01-16 ... 2020-12-16_CoordinateAxisType :Timeactual_range :[4.746816e+08 1.692144e+09]axis :Tcoverage_content_type :coordinateioos_category :Timelong_name :reference time of the last day of the composite temporal coveragestandard_name :timetime_origin :01-JAN-1970 00:00:00array(['2020-01-16T00:00:00.000000000', '2020-02-16T00:00:00.000000000',\n       '2020-03-15T23:00:00.000000000', '2020-04-15T23:00:00.000000000',\n       '2020-05-15T23:00:00.000000000', '2020-06-15T23:00:00.000000000',\n       '2020-07-15T23:00:00.000000000', '2020-08-15T23:00:00.000000000',\n       '2020-09-15T23:00:00.000000000', '2020-10-15T23:00:00.000000000',\n       '2020-11-16T00:00:00.000000000', '2020-12-16T00:00:00.000000000'],\n      dtype='datetime64[ns]')latitude(latitude)float3243.47 43.43 43.38 ... 33.58 33.53_CoordinateAxisType :Latactual_range :[-89.975  89.975]axis :Ycomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Latitudestandard_name :latitudeunits :degrees_northvalid_max :89.975valid_min :-89.975array([43.475   , 43.42501 , 43.375008, 43.325005, 43.275   , 43.225   ,\n       43.17501 , 43.125008, 43.075005, 43.025   , 42.975   , 42.92501 ,\n       42.875008, 42.825005, 42.775   , 42.725   , 42.67501 , 42.625008,\n       42.575005, 42.525   , 42.475   , 42.42501 , 42.375008, 42.325005,\n       42.275   , 42.225   , 42.17501 , 42.125008, 42.075005, 42.025   ,\n       41.975   , 41.92501 , 41.875008, 41.825005, 41.775   , 41.725   ,\n       41.67501 , 41.625008, 41.575005, 41.525   , 41.475   , 41.42501 ,\n       41.375008, 41.325005, 41.275   , 41.225   , 41.17501 , 41.125008,\n       41.075005, 41.025   , 40.975   , 40.92501 , 40.875008, 40.825005,\n       40.775   , 40.725   , 40.67501 , 40.625008, 40.575005, 40.525   ,\n       40.475   , 40.42501 , 40.375008, 40.325005, 40.275   , 40.225   ,\n       40.17501 , 40.125008, 40.075005, 40.025   , 39.975   , 39.92501 ,\n       39.875008, 39.825005, 39.775   , 39.725   , 39.67501 , 39.625008,\n       39.575005, 39.525   , 39.475   , 39.42501 , 39.375008, 39.325005,\n       39.275   , 39.225   , 39.17501 , 39.125008, 39.075005, 39.025   ,\n       38.975   , 38.92501 , 38.875008, 38.825005, 38.775   , 38.725   ,\n       38.67501 , 38.625008, 38.575005, 38.525   , 38.475   , 38.42501 ,\n       38.375008, 38.325005, 38.275   , 38.225   , 38.17501 , 38.125008,\n       38.075005, 38.025   , 37.975006, 37.925003, 37.875   , 37.825005,\n       37.775   , 37.725006, 37.675003, 37.625   , 37.575005, 37.525   ,\n       37.475006, 37.425003, 37.375   , 37.325005, 37.275   , 37.225006,\n       37.175003, 37.125   , 37.075005, 37.025   , 36.975006, 36.925003,\n       36.875   , 36.825005, 36.775   , 36.725006, 36.675003, 36.625   ,\n       36.575005, 36.525   , 36.475006, 36.425003, 36.375   , 36.325005,\n       36.275   , 36.225006, 36.175003, 36.125   , 36.075005, 36.025   ,\n       35.975006, 35.925003, 35.875   , 35.825005, 35.775   , 35.725006,\n       35.675003, 35.625   , 35.575005, 35.525   , 35.475006, 35.425003,\n       35.375   , 35.325005, 35.275   , 35.225006, 35.175003, 35.125   ,\n       35.075005, 35.025   , 34.975006, 34.925003, 34.875   , 34.825005,\n       34.775   , 34.725006, 34.675003, 34.625   , 34.575005, 34.525   ,\n       34.475006, 34.425003, 34.375   , 34.325005, 34.275   , 34.225006,\n       34.175003, 34.125   , 34.075005, 34.025   , 33.975006, 33.925003,\n       33.875   , 33.825005, 33.775   , 33.725006, 33.675003, 33.625   ,\n       33.575005, 33.525   ], dtype=float32)longitude(longitude)float32-73.47 -73.42 ... -43.57 -43.53_CoordinateAxisType :Lonactual_range :[-179.975  179.975]axis :Xcomment :equirectangular projection and grid centerscoverage_content_type :coordinateioos_category :Locationlong_name :Longitudestandard_name :longitudeunits :degrees_eastvalid_max :179.975valid_min :-179.975array([-73.475   , -73.424995, -73.375   , ..., -43.624992, -43.57499 ,\n       -43.525   ], dtype=float32)Indexes: (3)timePandasIndexPandasIndex(DatetimeIndex(['2020-01-16 00:00:00', '2020-02-16 00:00:00',\n               '2020-03-15 23:00:00', '2020-04-15 23:00:00',\n               '2020-05-15 23:00:00', '2020-06-15 23:00:00',\n               '2020-07-15 23:00:00', '2020-08-15 23:00:00',\n               '2020-09-15 23:00:00', '2020-10-15 23:00:00',\n               '2020-11-16 00:00:00', '2020-12-16 00:00:00'],\n              dtype='datetime64[ns]', name='time', freq=None))latitudePandasIndexPandasIndex(Index([43.474998474121094, 43.425010681152344,  43.37500762939453,\n        43.32500457763672, 43.275001525878906, 43.224998474121094,\n       43.175010681152344,  43.12500762939453,  43.07500457763672,\n       43.025001525878906,\n       ...\n       33.975006103515625,  33.92500305175781,             33.875,\n        33.82500457763672, 33.775001525878906, 33.725006103515625,\n        33.67500305175781,             33.625,  33.57500457763672,\n       33.525001525878906],\n      dtype='float32', name='latitude', length=200))longitudePandasIndexPandasIndex(Index([  -73.4749984741211,  -73.42499542236328,             -73.375,\n        -73.32499694824219,  -73.27499389648438,   -73.2249984741211,\n        -73.17499542236328,             -73.125,  -73.07499694824219,\n        -73.02499389648438,\n       ...\n       -43.974998474121094,  -43.92499542236328,  -43.87499237060547,\n       -43.824989318847656, -43.775001525878906, -43.724998474121094,\n        -43.67499542236328,  -43.62499237060547, -43.574989318847656,\n       -43.525001525878906],\n      dtype='float32', name='longitude', length=600))Attributes: (9)colorBarMaximum :32.0colorBarMinimum :0.0coverage_content_type :physicalMeasurementioos_category :Temperaturelong_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :degree_Cvalid_max :50.0valid_min :-2.0",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-unmasked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the unmasked data on a map",
    "text": "Visualize the unmasked data on a map\nThe map shows the full extent of the bounding box\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nds_subset[0].plot.pcolormesh(ax=ax1, transform=ccrs.PlateCarree(), cmap='jet')\n\nplt.title('Satellite Data Before Masking')\n\nText(0.5, 1.0, 'Satellite Data Before Masking')",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#create-the-region-from-the-shape-file",
    "title": "Extract data within a boundary",
    "section": "Create the region from the shape file",
    "text": "Create the region from the shape file\nThe plot shows the shape of the region and its placement along the US East Coast.\n\nregion = regionmask.from_geopandas(gulf_stream)\nregion.plot()",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#mask-the-satellite-data",
    "title": "Extract data within a boundary",
    "section": "Mask the satellite data",
    "text": "Mask the satellite data\n\n# Create the mask\nmask = region.mask(ds_subset.longitude, ds_subset.latitude)\n\n# Apply mask the the satellite data\nmasked_ds = ds_subset.where(mask == region.numbers[0])",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#visualize-the-masked-data-on-a-map",
    "title": "Extract data within a boundary",
    "section": "Visualize the masked data on a map",
    "text": "Visualize the masked data on a map\nThese data have been trimmed to contain only values within the Gulf Stream Province\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\nax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([260, 350, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\nmasked_ds[0].plot.pcolormesh(ax=ax1,\n                             transform=ccrs.PlateCarree(),\n                             cmap='jet')\n\nplt.title('Satellite Data After Masking for Longhurst GFST')\n\n\nText(0.5, 1.0, 'Satellite Data After Masking for Longhurst GFST')",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#plot-the-mean-seasonal-temperature-for-the-province",
    "title": "Extract data within a boundary",
    "section": "Plot the mean seasonal temperature for the province",
    "text": "Plot the mean seasonal temperature for the province\n\ngulf_stream_mean = masked_ds.mean(dim=['latitude', 'longitude'])\n\n\ngulf_stream_mean\n\nplt.figure(figsize=(10, 5)) \n# Plot the SeaWiFS data\nplt.plot_date(gulf_stream_mean.time,\n              gulf_stream_mean, \n              'o', markersize=8, \n              label='gulf stream', c='black', \n              linestyle='-', linewidth=2) \n\nplt.title('Gulf Stream Province Monthly Mean Temperature 2020')\nplt.ylabel('SST(degrees C)') \nplt.legend()",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/3-extract-satellite-data-within-boundary.html#references",
    "href": "tutorials/python/3-extract-satellite-data-within-boundary.html#references",
    "title": "Extract data within a boundary",
    "section": "References",
    "text": "References\nThe several CoastWatch Node websites have data catalog containing documentation and links to all the datasets available:\n* https://oceanwatch.pifsc.noaa.gov/doc.html\n* https://coastwatch.pfeg.noaa.gov/data.html\n* https://polarwatch.noaa.gov/catalog/\nSources for marine shape files * https://www.marineregions.org/downloads.php",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#summary",
    "href": "tutorials/python/1-earthaccess.html#summary",
    "title": "Earthdata Search and Discovery",
    "section": "Summary",
    "text": "Summary\nIn this example we will use the earthaccess library to search for data collections from NASA Earthdata. earthaccess is a Python library that simplifies data discovery and access to NASA Earth science data by providing an abstraction layer for NASA’s Common Metadata Repository (CMR) API Search API. The library makes searching for data more approachable by using a simpler notation instead of low level HTTP queries. earthaccess takes the trouble out of Earthdata Login authentication, makes search easier, and provides a stream-line way to download or stream search results into an xarray object.\nFor more on earthaccess visit the earthaccess GitHub page and/or the earthaccess documentation site. Be aware that earthaccess is under active development.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Search"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#prerequisites",
    "href": "tutorials/python/1-earthaccess.html#prerequisites",
    "title": "Earthdata Search and Discovery",
    "section": "Prerequisites",
    "text": "Prerequisites\nAn Earthdata Login account is required to access data from NASA Earthdata. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Search"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#get-started",
    "href": "tutorials/python/1-earthaccess.html#get-started",
    "title": "Earthdata Search and Discovery",
    "section": "Get Started",
    "text": "Get Started\n\nImport Required Packages\n\nimport earthaccess \nfrom pprint import pprint\nimport xarray as xr\nimport geopandas as gpd\n\n\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\n\n\nSearch for data\nThere are multiple keywords we can use to discovery data from collections. The table below contains the short_name, concept_id, and doi for some collections we are interested in for other exercises. Each of these can be used to search for data or information related to the collection we are interested in.\n\n\n\n\n\n\n\n\nShortname\nCollection Concept ID\nDOI\n\n\n\n\nMUR-JPL-L4-GLOB-v4.1\nC1996881146-POCLOUD\n10.5067/GHGMR-4FJ04\n\n\nAVHRR_OI-NCEI-L4-GLOB-v2.1\nC2036881712-POCLOUD\n10.5067/GHAAO-4BC21\n\n\n\nHow can we find the shortname, concept_id, and doi for collections not in the table above?. Let’s take a quick detour.\nhttps://search.earthdata.nasa.gov/search\n\nSearch by collection\n\ncollection_id = 'C1996881146-POCLOUD'\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    count = 10    # Restricting to 10 records returned\n)\n\nGranules found: 8002\n\n\nIn this example we used the concept_id parameter to search from our desired collection. However, there are multiple ways to specify the collection(s) we are interested in. Alternative parameters include:\n\ndoi - request collection by digital object identifier (e.g., doi = ‘10.5067/GHGMR-4FJ04’)\n\nshort_name - request collection by CMR shortname (e.g., short_name = ‘MUR-JPL-L4-GLOB-v4.1’)\n\nNOTE: Each Earthdata collection has a unique concept_id and doi. This is not the case with short_name. A shortname can be associated with multiple versions of a collection. If multiple versions of a collection are publicaly available, using the short_name parameter with return all versions available. It is advised to use the version parameter in conjunction with the short_name parameter with searching.\nWe can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the temporal parameter to request a date range and the bounding_box parameter to request granules that intersect with a bounding box.\nFor our bounding box, we need the xmin, ymin, xmax, ymax and we will assign this to bbox. We will assign our start date and end date to a variable named date_range\n\ndate_range = (\"2020-01-16\", \"2020-12-16\")\n# (xmin=-73.5, ymin=33.5, xmax=-43.5, ymax=43.5)\nbbox = (-73.5, 33.5, -43.5, 43.5)\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 336\n\n\n\nThe short_name and concept_id search parameters can be used to request one or multiple collections per request, but the doi parameter can only request a single collection.\n&gt; concept_ids = [‘C2723754864-GES_DISC’, ‘C1646609808-NSIDC_ECS’]\n\nUse the cloud_hosted search parameter only to search for data assets available from NASA’s Earthdata Cloud.\nThere are even more search parameters that can be passed to help refine our search, however those parameters do have to be populated in the CMR record to be leveraged. A non exhaustive list of examples are below:\n\nday_night_flag = 'day'\n\ncloud_cover = (0, 10)\n\n\n\n# col_ids = ['C2723754864-GES_DISC', 'C1646609808-NSIDC_ECS', 'C2531308461-NSIDC_ECS', 'C2537927247-NSIDC_ECS']    # Specify a list of collections to pass to the search\n\n# results = earthaccess.search_data(\n#     concept_id = col_ids,\n#     #cloud_hosted = True,\n#     temporal = date_range,\n#     bounding_box = bbox,\n# )\n\n\n\n\nWorking with earthaccess returns\nFollowing the search for data, you’ll likely take one of two pathways with those results. You may choose to download the assets that have been returned to you or you may choose to continue working with the search results within the Python environment.\n\nDownload earthaccess results\nIn some cases you may want to download your assets. earthaccess makes downloading the data from the search results very easy using the earthaccess.download() function. The MUR SST files are very large so we won’t run this code.\ndownloaded_files = earthaccess.download( results[0:9], local_path=‘../data’, )\nearthaccess does a lot of heavy lifting for us. It identifies the downloadable links, passes our Earthdata Login credentials, and saves the files with the proper names.\n\n\nWork in the cloud\nWe do not have to download the data to work with it or at least not until we need to compute with it or plot it. Let’s look at a smaller dataset.\n\nresults = earthaccess.search_data(\n    short_name = \"AVHRR_OI-NCEI-L4-GLOB-v2.1\",\n    version = \"2.1\",\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 337\n\n\n\ntype(results[0])\n\nearthaccess.results.DataGranule\n\n\n\nresults[0]\n\n\n    \n            \n            \n    \n      \n        \n          \n            Data: 20200115120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc\n            Size: 0.99 MB\n            Cloud Hosted: True\n          \n          \n            \n          \n        \n      \n    \n    \n\n\nThe data_links() methods gets us the url to the data. The data_links() method can also be used to get the s3 URI when we want to perform direct s3 access of the data in the cloud. To get the s3 URI, pass access = 'direct' to the method. Note, for NASA data, you need to be in AWS us-west-2 for direct access to work.\n\nresults[0].data_links()\n\n['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20200115120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc']\n\n\nWe can pass or read the data url into libraries like xarray, rioxarray, or gdal, but earthaccess has a built-in module for easily reading these data links in. We use earthaccess’s open() method make a connection the cloud resource so we can work with the files. To get the first file, we use results[0:1].\n\nfileset = earthaccess.open(results[0:1])\n\nOpening 1 granules, approx size: 0.0 GB\n\n\n\n\n\n\n\n\n\n\n\n\nds = xr.open_dataset(fileset[0])\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 17MB\nDimensions:           (lat: 720, lon: 1440, time: 1, nv: 2)\nCoordinates:\n  * lat               (lat) float32 3kB -89.88 -89.62 -89.38 ... 89.62 89.88\n  * lon               (lon) float32 6kB -179.9 -179.6 -179.4 ... 179.6 179.9\n  * time              (time) datetime64[ns] 8B 2020-01-15\nDimensions without coordinates: nv\nData variables:\n    lat_bnds          (lat, nv) float32 6kB ...\n    lon_bnds          (lon, nv) float32 12kB ...\n    analysed_sst      (time, lat, lon) float32 4MB ...\n    analysis_error    (time, lat, lon) float32 4MB ...\n    mask              (time, lat, lon) float32 4MB ...\n    sea_ice_fraction  (time, lat, lon) float32 4MB ...\nAttributes: (12/47)\n    Conventions:                CF-1.6, ACDD-1.3\n    title:                      NOAA/NCEI 1/4 Degree Daily Optimum Interpolat...\n    id:                         NCEI-L4LRblend-GLOB-AVHRR_OI\n    references:                 Reynolds, et al.(2009) What is New in Version...\n    institution:                NOAA/NESDIS/NCEI\n    creator_name:               NCEI Products and Services\n    ...                         ...\n    Metadata_Link.:             http://doi.org/10.7289/V5SQ8XB5\n    keywords:                   Oceans&gt;Ocean Temperature&gt;Sea Surface Temperature\n    keywords_vocabulary:        NASA Global Change Master Directory (GCMD) Sc...\n    standard_name_vocabulary:   CF Standard Name Table v29\n    processing_level:           L4\n    cdm_data_type:              Gridxarray.DatasetDimensions:lat: 720lon: 1440time: 1nv: 2Coordinates: (3)lat(lat)float32-89.88 -89.62 ... 89.62 89.88long_name :latitudestandard_name :latitudeaxis :Yunits :degrees_northvalid_min :-90.0valid_max :90.0bounds :lat_bndscomment :Uniform grid with centers from -89.875 to 89.875 by 0.25 degreesarray([-89.875, -89.625, -89.375, ...,  89.375,  89.625,  89.875],\n      dtype=float32)lon(lon)float32-179.9 -179.6 ... 179.6 179.9long_name :longitudestandard_name :longitudeaxis :Xunits :degrees_eastvalid_min :-180.0valid_max :180.0bounds :lon_bndscomment :Uniform grid with centers from -179.875 to 179.875 by 0.25 degreesarray([-179.875, -179.625, -179.375, ...,  179.375,  179.625,  179.875],\n      dtype=float32)time(time)datetime64[ns]2020-01-15long_name :reference time of sst fieldstandard_name :timeaxis :Tcomment :Nominal time because observations are from different sources and are made at different times of the day.array(['2020-01-15T00:00:00.000000000'], dtype='datetime64[ns]')Data variables: (6)lat_bnds(lat, nv)float32...units :degrees_northcomment :This variable defines the latitude values at the north and south bounds of every 0.25-degree pixel.[1440 values with dtype=float32]lon_bnds(lon, nv)float32...units :degrees_eastcomment :This variable defines the longitude values at the west and east bounds of every 0.25-degree pixel.[2880 values with dtype=float32]analysed_sst(time, lat, lon)float32...long_name :analysed sea surface temperaturestandard_name :sea_surface_temperatureunits :kelvinvalid_min :-300valid_max :4500source :UNKNOWN,ICOADS SHIPS,ICOADS BUOYS,ICOADS argos,MMAB_50KM-NCEP-ICEcomment :Single-sensor Pathfinder 5.0/5.1 AVHRR SSTs used until 2005; two AVHRRs at a time are used 2007 onward. Sea ice and in-situ data used also are near real time quality for recent period. SST (bulk) is at ambiguous depth because multiple types of observations are used.[1036800 values with dtype=float32]analysis_error(time, lat, lon)float32...long_name :estimated error standard deviation of analysed_sstunits :kelvinvalid_min :0valid_max :32767comment :Sum of bias, sampling and random errors.[1036800 values with dtype=float32]mask(time, lat, lon)float32...long_name :sea/land field composite maskvalid_min :1valid_max :31flag_masks :[ 1  2  4  8 16]flag_meanings :water land optional_lake_surface sea_ice optional_river_surfacesource :RWReynolds_landmask_V1.0comment :Several masks distinguishing between water, land and ice.[1036800 values with dtype=float32]sea_ice_fraction(time, lat, lon)float32...long_name :sea ice area fractionstandard_name :sea_ice_area_fractionunits :1valid_min :0valid_max :100source :MMAB_50KM-NCEP-ICEcomment :7-day median filtered. Switch from 25 km NASA team ice (http://nsidc.org/data/nsidc-0051.html) to 50 km NCEP ice (http://polar.ncep.noaa.gov/seaice) after 2004 results in artificial increase in ice coverage.[1036800 values with dtype=float32]Indexes: (3)latPandasIndexPandasIndex(Index([-89.875, -89.625, -89.375, -89.125, -88.875, -88.625, -88.375, -88.125,\n       -87.875, -87.625,\n       ...\n        87.625,  87.875,  88.125,  88.375,  88.625,  88.875,  89.125,  89.375,\n        89.625,  89.875],\n      dtype='float32', name='lat', length=720))lonPandasIndexPandasIndex(Index([-179.875, -179.625, -179.375, -179.125, -178.875, -178.625, -178.375,\n       -178.125, -177.875, -177.625,\n       ...\n        177.625,  177.875,  178.125,  178.375,  178.625,  178.875,  179.125,\n        179.375,  179.625,  179.875],\n      dtype='float32', name='lon', length=1440))timePandasIndexPandasIndex(DatetimeIndex(['2020-01-15'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (47)Conventions :CF-1.6, ACDD-1.3title :NOAA/NCEI 1/4 Degree Daily Optimum Interpolation Sea Surface Temperature (OISST) Analysis, Version 2 - Finalid :NCEI-L4LRblend-GLOB-AVHRR_OIreferences :Reynolds, et al.(2009) What is New in Version 2. Available at http://www.ncdc.noaa.gov/sites/default/files/attachments/Reynolds2009_oisst_daily_v02r00_version2-features.pdf;Daily 1/4 Degree Optimum Interpolation Sea Surface Temperature (OISST) - Climate Algorithm Theoretical Basis Document, NOAA Climate Data Record Program CDRP-ATBD-0303 Rev. 2 (2013). Available at http://www1.ncdc.noaa.gov/pub/data/sds/cdr/CDRs/Sea_Surface_Temperature_Optimum_Interpolation/AlgorithmDescription.pdf.institution :NOAA/NESDIS/NCEIcreator_name :NCEI Products and Servicescreator_email :ncei.orders@noaa.govcreator_url :http://www.ncdc.noaa.gov/oisstgds_version_id :v2.0r5netcdf_version_id :4.3.2date_created :20200211T000000Zproduct_version :Version 2.0history :2015-10-28: Modified format and attributes with NCO to match the GDS 2.0 rev 5 specification.spatial_resolution :0.25 degreestart_time :20200115T000000Zstop_time :20200116T000000Zwesternmost_longitude :-179.875easternmost_longitude :179.875southernmost_latitude :-89.875northernmost_latitude :89.875file_quality_level :3source :UNKNOWN,ICOADS SHIPS,ICOADS BUOYS,ICOADS argos,MMAB_50KM-NCEP-ICEcomment :The daily OISST version 2.0 data contained in this file are the same as those in the equivalent GDS 1.0 file.summary :NOAAs 1/4-degree Daily Optimum Interpolation Sea Surface Temperature (OISST) (sometimes referred to as Reynolds SST, which however also refers to earlier products at different resolution), currently available as version 2, is created by interpolating and extrapolating SST observations from different sources, resulting in a smoothed complete field. The sources of data are satellite (AVHRR) and in situ platforms (i.e., ships and buoys), and the specific datasets employed may change over time. At the marginal ice zone, sea ice concentrations are used to generate proxy SSTs.  A preliminary version of this file is produced in near-real time (1-day latency), and then replaced with a final version after 2 weeks. Note that this is the AVHRR-ONLY DOISST, available from Oct 1981, but there is a companion DOISST product that includes microwave satellite data, available from June 2002.acknowledgement :This project was supported in part by a grant from the NOAA Climate Data Record (CDR) Program. Cite this dataset when used as a source. The recommended citation and DOI depends on the data center from which the files were acquired. For data accessed from NOAA in near real-time or from the GHRSST LTSRF, cite as: Richard W. Reynolds, Viva F. Banzon, and NOAA CDR Program (2008): NOAA Optimum Interpolation 1/4 Degree Daily Sea Surface Temperature (OISST) Analysis, Version 2. [indicate subset used]. NOAA National Centers for Environmental Information. http://doi.org/doi:10.7289/V5SQ8XB5 [access date]. For data accessed from the NASA PO.DAAC, cite as: Richard W. Reynolds, Viva F. Banzon, and NOAA CDR Program (2008): NOAA Optimum Interpolation 1/4 Degree Daily Sea Surface Temperature (OISST) Analysis, Version 2. [indicate subset used]. PO.DAAC, CA, USA. http://doi.org/10.5067/GHAAO-4BC01 [access date].license :No constraints on data access or use.project :Group for High Resolution Sea Surface Temperaturepublisher_name :NCEI Products and Servicespublisher_email :ncei.orders@noaa.govpublisher_url :http://www.ncdc.noaa.gov/oisstnaming_authority :org.ghrssttime_coverage_start :20200115T000000Ztime_coverage_end :20200116T000000Zplatform :sensor :uuid :15459239-4bd8-4e2c-801a-9c515da7af42geospatial_lat_units :degrees_northgeospatial_lat_resolution :0.25geospatial_lon_units :degrees_eastgeospatial_lon_resolution :0.25Metadata_Conventions :ACDD-1.3Metadata_Link. :http://doi.org/10.7289/V5SQ8XB5keywords :Oceans&gt;Ocean Temperature&gt;Sea Surface Temperaturekeywords_vocabulary :NASA Global Change Master Directory (GCMD) Science Keywords, Version 8.1standard_name_vocabulary :CF Standard Name Table v29processing_level :L4cdm_data_type :Grid\n\n\n\nds['analysed_sst'].plot()",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Search"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#conclusion",
    "href": "tutorials/python/1-earthaccess.html#conclusion",
    "title": "Earthdata Search and Discovery",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes tutorial 1. You have worked with remote-sensing data in the cloud and plotted a single file.\nNext we will learn to subset the data so we can work with bigger datasets in the cloud without downloading the whole dataset.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Search"
    ]
  },
  {
    "objectID": "tutorials/python/1-earthaccess.html#resources",
    "href": "tutorials/python/1-earthaccess.html#resources",
    "title": "Earthdata Search and Discovery",
    "section": "Resources",
    "text": "Resources\n\nNASA’s Common Metadata Repository (CMR) API\n\nearthaccess repository\nearthaccess documentation\nEarthdata Search",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Search"
    ]
  },
  {
    "objectID": "team.html#organizers-and-instructors",
    "href": "team.html#organizers-and-instructors",
    "title": "Our Team",
    "section": "Organizers and Instructors",
    "text": "Organizers and Instructors\n\n\nEli Holmes\n\n\nNOAA Fisheries\nwebpage • GitHub • ORCID\n\n\nSunny Hospital\n\nNOAA CoastWatch PolarWatch\nGitHub\n\n\nMatt Grossi\n\n\nEmily Markowitz\n\nNOAA Fisheries\nwebpage • GitHub • NOAA • ORCID\n\n\n\n\nMore\n\n\nMore\n\n\nMore\n\n\nMore",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Our Team"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "Set-up",
    "section": "",
    "text": "To work on the JupyterHub for the workshop:",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "setup.html#github-username-required-to-get-on-hub",
    "href": "setup.html#github-username-required-to-get-on-hub",
    "title": "Set-up",
    "section": "GitHub username (required to get on hub)",
    "text": "GitHub username (required to get on hub)\n\nCreate a GitHub account (if you don’t already have one) at https://github.com. Advice for choosing a GitHub username: this is a professional username that you will use in work settings. GitHub accounts are not anonymous; this is for sharing work. Using your real name is common.\nWrite down your username and password; you will need to log in during the course!\nHere is a video showing the whole process",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "setup.html#get-on-the-jupyterhub-if-you-want-to-follow-along",
    "href": "setup.html#get-on-the-jupyterhub-if-you-want-to-follow-along",
    "title": "Set-up",
    "section": "Get on the JupyterHub (if you want to follow along)",
    "text": "Get on the JupyterHub (if you want to follow along)\nOnce you have submitted your GitHub username and have been accepted as a member of the DaskHub team on the nmfs-opensci organization, you can log-into the JupyterHub.\nhttps://dhub.opensci.live/\n\nChoose the default Py-R base geospatial image. Watch a video of the login process and basic JupyterHub orientation.\nhome directory is yours and no one else can see it. To share files, you can connect to a GitHub repository or use the shared directory. Everyone can read and write to this directory. Please don’t delete content that is not your own.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "setup.html#earthdata-login-account-optional",
    "href": "setup.html#earthdata-login-account-optional",
    "title": "Set-up",
    "section": "Earthdata Login account (optional)",
    "text": "Earthdata Login account (optional)\nWe will be using a public user account, but if you do a lot of work with NASA Earthdata, you should get a login account.\n\nCreate an Earthdata Login account (if you don’t already have one) at https://urs.earthdata.nasa.gov\nWrite down your username and password; you will need it.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "setup.html#set-up-authentication-to-github",
    "href": "setup.html#set-up-authentication-to-github",
    "title": "Set-up",
    "section": "Set up authentication to GitHub",
    "text": "Set up authentication to GitHub\nYou need to tell GitHub who you are so you can push your local changes up to GitHub. There are a few ways to do this. I am going to show you a way that works on any computer, including a virtual computer like the JupyterHub.\n\nStep 1: Generate a Personal Access Token\nWe are going to generate a classic token.\n\nGo to https://github.com/settings/tokens\nClick Generate new token &gt; Generate new token (classic)\nWhen the pop-up shows up, fill in a description, click the “repo” checkbox, and then scroll to bottom to click “Generate”.\nFor scope, select “repo”.\nSAVE the token. You need it for the next step.\n\n\n\nStep 2: Tell Git who your are\n\nOpen a terminal. In Jupyter Lab, you will see a box labelled “Terminal” on the Launcher window. In RStudio, you will see a tab (usually in lower left) with the label “Terminal”\nPaste these 3 lines of code into the terminal\n\ngit config --global user.email \"&lt;your email&gt;\"\ngit config --global user.name \"&lt;your name&gt;\"\ngit config --global pull.rebase false\ngit config --global credential.helper store\nReplace \"&lt;your email&gt;\" with something like jane.doe@noaa.gov. Replace \"&lt;your name&gt;\" with something like \"Jane Doe\". Notice the quotes.\n\n\nStep 3: Trigger git to ask for your password\nThere are a few ways to do this.\n\nClone a repo, make a change, and then commit and push the change\nClone a private repo\n\nOption b is easiest if you are new to Git and GitHub.\n\nOpen a terminal window\nMake sure you are in the home directory by typing cd ~\nClone a repo and create an RStudio project. File &gt; New Project &gt; Version Control &gt; Git. Paste in this URL https://github.com/nmfs-opensci/github_setup_check and make sure it is creating the repo at ~ (home directory).\nYou will be asked for your GitHub username and password. For the password, enter the PERSONAL ACCESS TOKEN from Step 1.\n\nWatch a video of these 4 steps\nFull instructions with other ways to do this from R",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Set-up"
    ]
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "Overview",
    "section": "",
    "text": "The the era of big data in the earth sciences is here and learning how to effectively use oceanographic remote-sensing data, both in the cloud and on your computer, is a core skill for modern fisheries science and management. Learning how to access cloud-based data, visualize these data, use these data in models, and use the tools of modern reproducible and collaborative science is the main goal of this course. Through the course, participants will gain experience with assessing remote-sensing data in the cloud, R and RStudio, Python and Jupyter notebooks, and collaborating with Git and GitHub.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#aims-and-objectives",
    "href": "overview.html#aims-and-objectives",
    "title": "Overview",
    "section": "Aims and Objectives",
    "text": "Aims and Objectives\n\nLearn how to discover and use oceanographic remote-sensing data for species distribution modeling and other fisheries applications\nFamiliarize participants with using remote-sensing data and geospatial tools in R and Python code.\nObtain hands-on experience in using remote-sensing data and other earth data in science workflows by working together on a group project.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#what-is-a-hackweek",
    "href": "overview.html#what-is-a-hackweek",
    "title": "Overview",
    "section": "What is a hackweek?",
    "text": "What is a hackweek?\nA hackweek is a participant-driven workshop that blends data science education, community building, and project work over a short period of time (one to two weeks). The events are highly immersive and allow participants to work directly with data science professionals to co-shape projects and educational outcomes. Hackweeks help individuals and teams engage more effectively in open and reproducible science. - eScience Institute, University of Washington, Seattle USA\nThe hackweek model has become a vital tool in the data science community, fostering idea exchange through modern data analysis workflow training. Unlike traditional academic events, hackweeks offer intensive, interactive learning, including tutorials on cutting-edge methods, peer-based learning, and collaborative on-site projects. Unlike hackathons, which emphasize software development, hackweeks prioritize education and open-ended projects, benefiting fields needing both expertise and efficient computational workflows for idea exchange and discovery. The hackweek model is now widely used in many fields: Astrohackweek, Neurohackweek, Geohackweek, OceanHackWeek, ICESat-2 Hackweek, SnowEx Hackweek, NASA Cloud Hackathon. The NOAA HackDays content and format is modeled off the University of Washington eScience Hackweek model.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "overview.html#code-of-conduct",
    "href": "overview.html#code-of-conduct",
    "title": "Overview",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nThe NOAA HackDays events are a safe learning space and all participants are required to abide by our Code of Conduct.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Overview"
    ]
  },
  {
    "objectID": "content/index.html",
    "href": "content/index.html",
    "title": "Week 1 Tutorials",
    "section": "",
    "text": "During week 1, participants will gain experience with the platforms used in collaborative science: GitHub and RMarkdown."
  },
  {
    "objectID": "content/index.html#prerequisites",
    "href": "content/index.html#prerequisites",
    "title": "Week 1 Tutorials",
    "section": "Prerequisites",
    "text": "Prerequisites\nPlease follow the set up prerequisites"
  },
  {
    "objectID": "content/index.html#content",
    "href": "content/index.html#content",
    "title": "Week 1 Tutorials",
    "section": "Content",
    "text": "Content\n\nThe R language and RStudio\nIntro to RStudio\nIntroduction to Git and GitHub"
  },
  {
    "objectID": "content/02-local-setup.html",
    "href": "content/02-local-setup.html",
    "title": "Setting up on your computer",
    "section": "",
    "text": "Here are instructions for installing on your own computer.\nInstall the development version of earthdatalogin and update terra.\n\ndevtools::install_github(\"boettiger-lab/earthdatalogin\")\ninstall.packages(\"terra\")\ninstall.packages(\"rstac\")\ninstall.packages(\"gdalcubes\")\ninstall.packages(\"here\")\n\nlibrary(\"earthdatalogin\")\nlibrary(\"terra\")\nlibrary(\"rstac\")\nlibrary(\"gdalcubes\")\nlibrary(\"here\")\n\nYou will need GDAL installed. See these instructions if you do not have it installed: https://developers.planet.com/docs/integrations/qgis/install-qgis-gdal/\nYou may need to install terra and sf from source to get them to use the latest GDAL installation.\n\ninstall.packages(\"terra\", type = \"source\")\ninstall.packages(\"sf\", type = \"source\")\nsf_extSoftVersion()\n\nThe environment we are using today is the py-rocket-geospatial image. This is part of work on a Data Science Docker Stack for NOAA Fisheries.\n\nR Version Metadata\n\nsessionInfo()\n\nR version 4.4.0 (2024-04-24)\nPlatform: x86_64-pc-linux-gnu\nRunning under: Ubuntu 22.04.4 LTS\n\nMatrix products: default\nBLAS:   /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 \nLAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/libopenblasp-r0.3.20.so;  LAPACK version 3.10.0\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\ntime zone: Etc/UTC\ntzcode source: system (glibc)\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.4.0    fastmap_1.1.1     cli_3.6.2        \n [5] tools_4.4.0       htmltools_0.5.8.1 rstudioapi_0.16.0 yaml_2.3.8       \n [9] rmarkdown_2.26    knitr_1.46        jsonlite_1.8.8    xfun_0.43        \n[13] digest_0.6.35     rlang_1.1.3       evaluate_0.23",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Local set-up"
    ]
  },
  {
    "objectID": "content/02-git-jupyter.html#summary",
    "href": "content/02-git-jupyter.html#summary",
    "title": "Git - Jupyter Lab",
    "section": "Summary",
    "text": "Summary\nIn this tutorial, we will provide a brief introduction to:\n\nCommand line (terminal/shell)\nNavigating around folders in Jupyter Lab\nVersion Control (code management using git)\nSetting up Git in Jupyter Lab\nThe Git GUI in Jupyter Lab\nBasic Git commands",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-JupyterLab"
    ]
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-jupyter-lab",
    "href": "content/02-git-jupyter.html#introduction-jupyter-lab",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Jupyter Lab",
    "text": "Introduction :: Jupyter Lab\nWhen you start the JupyterHub, you will be in Jupyter Lab. From there you can click on the RStudio box and open RStudio. However for this tutorial, we will stay in Juptyer Lab.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-JupyterLab"
    ]
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-terminalshell",
    "href": "content/02-git-jupyter.html#introduction-terminalshell",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Terminal/Shell",
    "text": "Introduction :: Terminal/Shell\nLog into the JupyterHub. If you do not see this\n\nThen go to File &gt; New Launcher\nClick on the “Terminal” box to open a new terminal window.\n\nShell or Terminal Basics\n\nWhat is Terminal or Shell?\nNavigating Files and Directories\nWorking with Files and Directories\nOptional: Detailed self-paced lesson on running scripts from the shell: Shell Lesson from Software Carpentry\n\nYou will need only basic navigation skills for this course: cd, ls and cat\n\npwd where am I\ncd nameofdir move into a directory\ncd .. move up a directory\nls list the files in the current directory\nls -a list the files including hidden files\nls -l list the files with more info\ncat filename print out the contents of a file\n\n\n\nLet’s try\nls\nls -a\ncd shared\nls\ncd shell-tutorial\ncat lesson1.sh\ncd ..\ncd ..\n\n\nClose the terminal\nJust click on the X in the terminal tab",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-JupyterLab"
    ]
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-file-navigation",
    "href": "content/02-git-jupyter.html#introduction-file-navigation",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: File Navigation",
    "text": "Introduction :: File Navigation\nIn the far left, you will see a line of icons. The top one is a folder and allows us to move around our file system.\n\nClick on shared. Now you can see the files in the shared directory.\nClick on shell-tutorial. Then click on lesson1.sh. The file opens. You won’t be able to save changes here because you don’t have write permission on this drive.\nClick on the folder icon that looks like this. Click on the actual folder image. \nNow it should look like this folder /\nThis shows me doing this\n\nCreate a new folder.\n\nNext to the blue rectange with a +, is a grey folder with a +. Click that to create a new folder, called lesson-scripts.\nThen click on lesson-scripts to enter the folder\n\n\nCreate a new file\n\nCreate with File &gt; New &gt; Text file\nThe file will open and you can edit it.\nSave with File &gt; Save Text\nDelete the file by right-clicking on it and clicking “Delete”",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-JupyterLab"
    ]
  },
  {
    "objectID": "content/02-git-jupyter.html#introduction-version-control-git",
    "href": "content/02-git-jupyter.html#introduction-version-control-git",
    "title": "Git - Jupyter Lab",
    "section": "Introduction :: Version Control (Git)",
    "text": "Introduction :: Version Control (Git)\n\nWhat is version control, git, github, and how to set it up?\nVersion control is managing and tracking changes to your documents (program source code, images, websites, data files, etc.). git is a popular tool used for version control of software code. github.com is popular platform that provides remote server hosting for git repositories. A repository is a collection of various files that you are tracking for changes and versions. Currently GitHub is the most popular platform for file sharing code and code packages.\nThis section is a step-by-step guide to set up git on our JupyterHub. We will also configure git to use your github.com account for managing your repositories hosted on github.com. There are 5 main steps.\n\n\nStep 1: Create a GitHub account\nTo complete the setup, you will need an account on github.com. If you don’t have an account, please visit github.com, create an account (free) and come back to this guide for setting up git.\n\n\nStep 2: Clone a repository\nWe have created a demo repository for you to clone:\nhttps://github.com/nmfs-opensci/Git-Lesson\n\nStart your JupyterHub\nClick on the Git icon\n\n\n\nClick “Clone a Repository”\nWhere it says “Enter the URI of the remote Git repository”, paste in the URL https://github.com/nmfs-opensci/EDMW-EarthData-Workshop-2024\nThe folder appears and you can enter the folder and edit and create files.\n\n\nYour task: Create a file with your name and save to the Git-Lesson folder",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-JupyterLab"
    ]
  },
  {
    "objectID": "content/02-git-jupyter.html#step-3",
    "href": "content/02-git-jupyter.html#step-3",
    "title": "Git - Jupyter Lab",
    "section": "Step 3:",
    "text": "Step 3:\nConfigure git with your name and email address.\n``` bash\ngit config --global user.name \"Makhan Virdi\"\ngit config --global user.email \"Makhan.Virdi@gmail.com\"\n```\n\n**Note:** This name and email could be different from your github.com credentials. Remember `git` is a program that keeps track of your changes locally (on the JupyterHub or your own computer) and github.com is a platform to host your repositories. However, since your changes are tracked by `git`, the email/name used in git configuration will show up next to your contributions on github.com when you `push` your repository to github.com (`git push` is discussed in a later step).\n\nConfigure git to store your github credentials to avoid having to enter your github username and token each time you push changes to your repository(in Step 5, we will describe how to use github token instead of a password)\ngit config --global credential.helper store\nCopy link for the demo repository from your github account. Click the green “Code” button and copy the link as shown.\n\nClone the repository using git clone command in the terminal\nTo clone a repository from github, copy the link for the repository (previous step) and use git clone:\ngit clone https://github.com/YOUR-GITHUB-USERNAME/check_github_setup\nNote: Replace YOUR-GITHUB-USERNAME here with your github.com username. For example, it is virdi for my github.com account as seen in this image.\n\nUse ls (list files) to verify the existence of the repository that you just cloned\n\nChange directory to the cloned repository using cd check_github_setup and check the current directory using pwd command (present working directory)\n\nCheck status of your git repository to confirm git set up using git status\n\nYou are all set with using git on your 2i2c JupyterHub! But the collaborative power of git through github needs some additional setup.\nIn the next step, we will create a new file in this repository, track changes to this file, and link it with your github.com account.\n\n\nStep 4. Creating new file and tracking changes\n\nIn the left panel on your 2i2c JupyterHub, click on the “directory” icon and then double click on “check_github_setup” directory.\n\n\nOnce you are in the check_github_setup directory, create a new file using the text editor in your 2i2c JupyterHub (File &gt;&gt; New &gt;&gt; Text File).\n\nName the file lastname.txt. For example, virdi.txt for me (use your last name). Add some content to this file (for example, I added this to my virdi.txt file: my last name is virdi).\n\nNow you should have a new file (lastname.txt) in the git repository directory check_github_setup\nCheck if git can see that you have added a new file using git status. Git reports that you have a new file that is not tracked by git yet, and suggests adding that file to the git tracking system.\n\nAs seen in this image, git suggests adding that file so it can be tracked for changes. You can add file to git for tracking changes using git add. Then, you can commit changes to this file’s content using git commit as shown in the image.\ngit add virdi.txt\ngit status\ngit commit -m \"adding a new file\"\ngit status\n\nAs seen in the image above, git is suggesting to push the change that you just committed to the remote server at github.com (so that your collaborators can also see what changes you made).\nNote: DO NOT execute push yet. Before we push to github.com, let’s configure git further and store our github.com credentials to avoid entering the credentials every time we invoke git push. For doing so, we need to create a token on github.com to be used in place of your github.com password.\n\n\n\nStep 5. Create access token on github.com\n\nGo to your github account and create a new “personal access token”: https://github.com/settings/tokens/new\n\n\n\nGenerate Personal Access Token on github.com\n\n\nEnter a description in “Note” field as seen above, select “repo” checkbox, and scroll to the bottom and click the green button “Generate Token”. Once generated, copy the token (or save it in a text file for reference).\nIMPORTANT: You will see this token only once, so be sure to copy this. If you do not copy your token at this stage, you will need to generate a new token.\n\nTo push (transfer) your changes to github, use git push in terminal. It requires you to enter your github credentials. You will be prompted to enter your github username and “password”. When prompted for your “password”, DO NOT use your github password, use the github token that was copied in the previous step.\ngit push\n\nNote: When you paste your token in the terminal window, windows users will press Ctrl+V and mac os users will press Cmd+V. If it does not work, try generating another token and use the copy icon next to the token to copy the token. Then, paste using your computer’s keyboard shortcut for paste.\nNow your password is stored in ~/.git-credentials and you will not be prompted again unless the Github token expires. You can check the presence of this git-credentials file using Terminal. Here the ~ character represents your home directory (/home/jovyan/).\nls -la ~\nThe output looks like this:\ndrwxr-xr-x 13 jovyan jovyan 6144 Oct 22 17:35 .\ndrwxr-xr-x  1 root   root   4096 Oct  4 16:21 ..\n-rw-------  1 jovyan jovyan 1754 Oct 29 18:30 .bash_history\ndrwxr-xr-x  4 jovyan jovyan 6144 Oct 29 16:38 .config\n-rw-------  1 jovyan jovyan   66 Oct 22 17:35 .git-credentials\n-rw-r--r--  1 jovyan jovyan   84 Oct 22 17:14 .gitconfig\ndrwxr-xr-x 10 jovyan jovyan 6144 Oct 21 16:19 2021-Cloud-Hackathon\nYou can also verify your git configuration\n(notebook) jovyan@jupyter-virdi:~$ git config -l\nThe output should have credential.helper = store:\nuser.email        = Makhan.Virdi@gmail.com\nuser.name         = Makhan Virdi\ncredential.helper = store\n\nNow we are all set to collaborate with github on the JupyterHub during the Cloud Hackathon!\n\n\nSummary: Git Commands\n\nCommonly used git commands (modified from source)\n\n\nGit Command\nDescription\n\n\n\n\ngit status\nShows the current state of the repository: the current working branch, files in the staging area, etc.\n\n\ngit add\nAdds a new, previously untracked file to version control and marks already tracked files to be committed with the next commit\n\n\ngit commit\nSaves the current state of the repository and creates an entry in the log\n\n\ngit log\nShows the history for the repository\n\n\ngit diff\nShows content differences between commits, branches, individual files and more\n\n\ngit clone\nCopies a repository to your local environment, including all the history\n\n\ngit pull\nGets the latest changes of a previously cloned repository\n\n\ngit push\nPushes your local changes to the remote repository, sharing them with others\n\n\n\n\n\nGit: More Details\nLesson: For a more detailed self-paced lesson on git, visit Git Lesson from Software Carpentry\nCheatsheet: Frequently used git commands\nDangit, Git!?!: If you are stuck after a git mishap, there are ready-made solutions to common problems at Dangit, Git!?!\n\n\nCloning our repository using the git Jupyter lab extension.\nIf we’re already familiar with git commands and feel more confortable using a GUI our Jupyterhub deployment comes with a git extension. This plugin allows us to operate with git using a simple user interface.\nFor example we can clone our repository using the extension.\n\n\n\ngit extension",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-JupyterLab"
    ]
  },
  {
    "objectID": "content/01-welcome.html",
    "href": "content/01-welcome.html",
    "title": "Welcome",
    "section": "",
    "text": "Introduction to working with earth data in the cloud and NASA Earth Data\nOrientation on our JupyterHub\nTutorial 1: Searching for resources in NASA Earth Data\nTutorial 2: Points and shapefiles\nTutorial 3: Subsetting your earth data with in a region (shapefile)\nTutorial 4: Getting values at points (along a track or transect)",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Welcome"
    ]
  },
  {
    "objectID": "content/01-intro-to-cloud.html",
    "href": "content/01-intro-to-cloud.html",
    "title": "Intro the Cloud",
    "section": "",
    "text": "Lecture on NASA earth data in the cloud by Michele Thornton (NASA Openscapes) Video",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Geoscience cloud tools"
    ]
  },
  {
    "objectID": "coc.html",
    "href": "coc.html",
    "title": "Code of Conduct",
    "section": "",
    "text": "We are dedicated to providing a harassment-free learning experience for everyone regardless of gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age or religion. We do not tolerate harassment of participants in any form. Sexual language and imagery is not appropriate either in-person or virtual form, including the Discussion boards and Slack workspace. Participants (including event volunteers and organizers) violating these rules may be sanctioned or expelled from the event at the discretion of the organizers.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#definition-of-harassment",
    "href": "coc.html#definition-of-harassment",
    "title": "Code of Conduct",
    "section": "Definition of Harassment",
    "text": "Definition of Harassment\nHarassment includes, but is not limited to:\n\nVerbal comments that reinforce social structures of domination related to gender, gender identity and expression, sexual orientation, disability, physical appearance, body size, race, age, religion.\nSexual images in public spaces\nDeliberate intimidation, stalking, or following\nHarassing photography or recording\nSustained disruption of talks or other events\nInappropriate physical contact\nUnwelcome sexual attention\nAdvocating for, or encouraging, any of the above behavior",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#expectations",
    "href": "coc.html#expectations",
    "title": "Code of Conduct",
    "section": "Expectations",
    "text": "Expectations\nParticipants asked to stop any harassing behavior are expected to comply immediately. If a participant engages in harassing behavior, the organizers retain the right to take any actions to keep the event a welcoming environment for all participants. This includes warning the offender or expulsion from the event.\nThe organizers may take action to redress anything designed to, or with the clear impact of, disrupting the event or making the environment hostile for any participants. We expect participants to follow these rules at all the event venues and event-related social activities.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "coc.html#reporting-a-violation",
    "href": "coc.html#reporting-a-violation",
    "title": "Code of Conduct",
    "section": "Reporting a violation",
    "text": "Reporting a violation\nHarassment and other code of conduct violations reduce the value of the event for everyone. If someone makes you or anyone else feel unsafe or unwelcome, please report it as soon as possible.\nIf you feel comfortable contacting someone associated with our event, you may speak with one of the event organizers in person or contact an organizer on a private Slack channel.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Code of Conduct"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#log-into-the-jupyterhub",
    "href": "content/01-intro-to-jupyterhub.html#log-into-the-jupyterhub",
    "title": "Intro to JupyterHubs",
    "section": "Log into the JupyterHub",
    "text": "Log into the JupyterHub\nGo to https://dhub.opensci.live/. Click “Login to continue”. You will be asked to log in with your GitHub Account, if you are not logged in already.\n\nImage type: Python or R\nNext you select your image type. We will use the default Py-R - base geospatial image.\n\n\nVirtual Machine size\nYou’ll see something similar to this that allows you to choose a large virtual machine if your project needs it. For the tutorials, you will only need the Small Virtual Machine. Please only choose the large machines if you run out of RAM as the larger machines cost us more.\n\n\n\nMachine Profiles\n\n\n\n\nStart up\nAfter we select our server type and click on start, JupyterHub will allocate our instance in the cloud (on Azure). This may take several minutes.\n\n\n\nJupyterhub Spawning",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#open-rstudio",
    "href": "content/01-intro-to-jupyterhub.html#open-rstudio",
    "title": "Intro to JupyterHubs",
    "section": "Open RStudio",
    "text": "Open RStudio\nWhen you are in the Jupyter Lab tab (note the Jupyter Logo), you will see a Launcher page. If you don’t see this, go to File &gt; New Launcher.\n\n\n\nJupyterhub Launcher\n\n\nIf you will be using Python today, you can stay in Jupyter Lab. If you are using R today then read the next steps.\n\nOpen RStudio by clicking on the “RStudio” box in the Launcher tab:\n\n\n\n\nRStudio",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#end-your-session",
    "href": "content/01-intro-to-jupyterhub.html#end-your-session",
    "title": "Intro to JupyterHubs",
    "section": "End your session",
    "text": "End your session\nWhen you are finished working for the day it is important to log out of the Jupyter Hub. When you keep a session active it uses up cloud resources (costs money) and keeps a series of virtual machines deployed.\n\n\n\n\n\n\nCaution\n\n\n\nYou log out from the Jupyter Lab tab not the RStudio tab.\n\n\nFrom the Jupyter Lab tab, do one of two things to stop the server:\n\nLog out File -&gt; Log Out and click “Log Out”!\nor File -&gt; Hub Control Panel -&gt; Stop My Server\n\n\n\n\n\n\n\nTip\n\n\n\nCan’t find the Jupyter Lab tab? Go to https://dhub.opensci.live/hub/home",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#restart-your-server",
    "href": "content/01-intro-to-jupyterhub.html#restart-your-server",
    "title": "Intro to JupyterHubs",
    "section": "Restart your server",
    "text": "Restart your server\nSometimes the server will crash/stop. This can happen if too many people use a lot of memory all at once. If that happens, go to the Jupyter Lab tab and then File -&gt; Hub Control Panel -&gt; Stop My Server and then Start My Server. You shouldn’t lose your work unless you were uploading a file.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#your-files",
    "href": "content/01-intro-to-jupyterhub.html#your-files",
    "title": "Intro to JupyterHubs",
    "section": "Your files",
    "text": "Your files\nWhen you start your server, you will have access to your own virtual drive space. No other users will be able to see or access your files. You can upload files to your virtual drive space and save files here. You can create folders to organize your files. You personal directory is home/jovyan. Everyone has the same home directory but your files are separate and cannot be seen by others.\nThere are a number of different ways to create new files. We will practice this in the RStudio lecture.\n\nWill I lose all of my work?\nLogging out will NOT cause any of your work to be lost or deleted. It simply shuts down some resources. It would be equivalent to turning off your desktop computer at the end of the day.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#shared-files",
    "href": "content/01-intro-to-jupyterhub.html#shared-files",
    "title": "Intro to JupyterHubs",
    "section": "Shared files",
    "text": "Shared files\n\n\n\nShared folder\n\n\nIn the file panel, you will see a folder called shared. These are read-only shared files.\nYou will also see shared-public. This is a read-write folder for you to put files for everyone to see and use. You can create a team folder here for shared data and files. Note, everyone can see and change these so be careful to communicate with your team so multiple people don’t work on the same file at the same time. You can also create folders for each team member and agree not to change other team members files.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#python-users",
    "href": "content/01-intro-to-jupyterhub.html#python-users",
    "title": "Intro to JupyterHubs",
    "section": "**Python users",
    "text": "**Python users\nYou can open a Jupyter Notebook by clicking on the “Python 3” box. In the Launcher tab:\n\n\n\nJupyterhub Launcher\n\n\nJupyter notebooks are a very common way to share Python code and tutorials. Get an overview of Jupyter Lab: Intro to Jupyter Lab Learn about the geosciences tools in Python",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/01-intro-to-jupyterhub.html#faq",
    "href": "content/01-intro-to-jupyterhub.html#faq",
    "title": "Intro to JupyterHubs",
    "section": "FAQ",
    "text": "FAQ\nWhy do we have the same home directory as /home/jovyan? /home/jovyan is the default home directory for ‘jupyter’ based images/dockers. It is the historic home directory for Jupyter deployments.\nCan other users see the files in my /home/jovyan folder? No, other users can not see your credentials.\n\nAcknowledgements\nSome sections of this document have been taken from hackweeks organized by the University of Washington eScience Institute and Openscapes.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Welcome",
      "Jupyter hubs"
    ]
  },
  {
    "objectID": "content/02-earthdata.html#overview",
    "href": "content/02-earthdata.html#overview",
    "title": "Earthdata Login",
    "section": "Overview",
    "text": "Overview",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Earthdata login"
    ]
  },
  {
    "objectID": "content/02-earthdata.html#why-do-i-need-an-earthdata-login",
    "href": "content/02-earthdata.html#why-do-i-need-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "Why do I need an Earthdata login?",
    "text": "Why do I need an Earthdata login?\nWe will be teaching you ways to programmatically access NASA remote-sensing data from within your scripts. You will need to enter your Earthdata username and password in order for this to work.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Earthdata login"
    ]
  },
  {
    "objectID": "content/02-earthdata.html#getting-an-earthdata-login",
    "href": "content/02-earthdata.html#getting-an-earthdata-login",
    "title": "Earthdata Login",
    "section": "Getting an Earthdata login",
    "text": "Getting an Earthdata login\nIf you do not already have an Earthdata login, then navigate to the Earthdata Login page, a username and password, and then record this somewhere for use during the tutorials:",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Earthdata login"
    ]
  },
  {
    "objectID": "content/02-earthdata.html#configure-programmatic-access-to-nasa-servers",
    "href": "content/02-earthdata.html#configure-programmatic-access-to-nasa-servers",
    "title": "Earthdata Login",
    "section": "Configure programmatic access to NASA servers",
    "text": "Configure programmatic access to NASA servers\nIf you use web interfaces to retrieve nasa data such as Earthdata Search you are prompted to login. We will be using software to retrieve data from NASA Servers during the hackweek, so you must store your credentials on the JupyterHub. Run the following commands on the JupyterHub in a terminal replacing your Earthdata login username and password:\necho \"machine urs.earthdata.nasa.gov login EARTHDATA_LOGIN password EARTHDATA_PASSWORD\" &gt; ~/.netrc\nchmod 0600 .netrc",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Earthdata login"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#what-is-git-and-github",
    "href": "content/02-git-rstudio.html#what-is-git-and-github",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "What is Git and GitHub?",
    "text": "What is Git and GitHub?\nGit A program to track your file changes and create a history of those changes. Creates a ‘container’ for a set of files called a repository.\nGitHub A website to host these repositories and allow you to sync local copies (on your computer) to the website. Lots of functionality built on top of this.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#some-basic-git-jargon",
    "href": "content/02-git-rstudio.html#some-basic-git-jargon",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Some basic Git jargon",
    "text": "Some basic Git jargon\n\nRepo Repository. It is your code and the record of your changes. This record and also the status of your repo is a hidden folder called .git . You have a local repo and a remote repo. The remote repo is on GitHub (for in our case) is called origin. The local repo is on the JupyterHub.\nStage Tell Git which changes you want to commit (write to the repo history).\nCommit Write a note about what change the staged files and “commit” that note to the repository record. You are also tagging this state of the repo and you could go back to this state if you wanted.\nPush Push local changes (commits) up to the remote repository on GitHub (origin).\nPull Pull changes on GitHub into the local repository on the JupyterHub.\nGit GUIs A graphical interface for Git (which is command line). Today I will use jupyterlab-git which we have installed on JupyterHub.\nShell A terminal window where we can issue git commands.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#overview",
    "href": "content/02-git-rstudio.html#overview",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Overview",
    "text": "Overview\nToday I will cover the four basic Git/GitHub skills. The goal for today is to first get you comfortable with the basic skills and terminology. We will use what is called a “trunk-based workflow”.\n\nSimple Trunk-based Workflow:\n\nMake local (on your computer) changes to code.\nRecord what those changes were about and commit to the code change record (history).\nPush those changes to your remote repository (aka origin)\n\nWe’ll do this",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#setting-up-git",
    "href": "content/02-git-rstudio.html#setting-up-git",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Setting up Git",
    "text": "Setting up Git\nYou should have gotten this done on Tuesday but if not here are the instructions\nBefore we can work with Git in the JupyterHub, we need to do some set up.\n\nTell Git who you are and to store your credentials (GitHub login info)\n\nShow me\nPaste this into a terminal window:\ngit config --global user.email \"&lt;your email&gt;\"\ngit config --global user.name \"&lt;your name&gt;\"\ngit config --global pull.rebase false\ngit config --global credential.helper store\n\nGet a Personal Access Token from GitHub\n\nCopy the token! You will need it in the next step.\nShow me Note, one change to this video is that you need to specify that you want a classic token.\n\nTrigger Git to ask for your password (that personal access token)\n\nYou can do this by cloning a private repo. In the Terminal, issue this command\ngit clone https://github.com/nmfs-opensci/github_setup_check\nIt will ask for your GitHub username and password. At the password part, paste in the Personal Access Token.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#git-tab",
    "href": "content/02-git-rstudio.html#git-tab",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Git tab",
    "text": "Git tab\nWhen the instructions say to use or open or click the Git tab,",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#the-key-skills",
    "href": "content/02-git-rstudio.html#the-key-skills",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "The Key Skills",
    "text": "The Key Skills\n\nSkill 1: Create a blank repo on GitHub\nSkill 2: Clone your GitHub repo to RStudio\nSkill 3: Make some changes and commit those local changes\nSkill 4: Push the changes to GitHub\nSkill 1b: Copy someone else’s GitHub repository",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#lets-see-it-done",
    "href": "content/02-git-rstudio.html#lets-see-it-done",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Let’s see it done!",
    "text": "Let’s see it done!\n\nSkill 1: Create a blank repo on GitHub\n\nClick the + in the upper left from YOUR GitHub page.\nGive your repo the name Test and make sure it is public.\nClick new and check checkbox to add the Readme file and .gitignore\nCopy the URL of your new repo. It’s in the browser where you normally see a URL.\n\nShow me\n\n\nSkill 2: Clone your repo to the RStudio\nIn RStudio we do this by making a new project.\n\nCopy the URL of your repo. https://www.github.com/yourname/Test\nFile &gt; New Project &gt; Version Control &gt; Git\nPast in the URL of your repo from Step 1\nCheck that it is being created in your Home directory which will be denoted ~ in the JupyterHub.\nClick Create.\n\nShow me\n\n\nSkill 3: Make some changes and commit your changes\nThis writes a note about what changes you have made. It also marks a ‘point’ in time that you can go back to if you need to.\n\nMake some changes to the README.md file in the Test repo.\nClick the Git tab, and stage the change(s) by checking the checkboxes next to the files listed.\nClick the Commit button.\nAdd a commit comment, click commit.\n\nShow me\n\n\nSkill 4: Push changes to GitHub / Pull changes from GitHub\nTo push changes you committed in Skill #3\n\nFrom Git tab, click on the Green up arrow that says Push.\nTo pull changes on GitHub that are not on your local computer:\nMake some changes directly on GitHub (not in RStudio)\nFrom Git tab, click on the down arrow that says Pull.\n\nShow me\n\n\nPair-activity 1\nIn RStudio,\n\nMake a copy of README.md\nRename it to .md\nAdd some text.\nStage and commit the added file.\nPush to GitHub.\n\nTry before watching.\nShow me in RStudio – Show me in the shell – Show me in jupyter-git\n\n\nPair-activity 2\nAll of this activity is in RStudio.\n\nClone this repo https://github.com/nmfs-opensci/git-basics to RStudio and create a new project\nNavigate to the files in your new project, create a filed called to &lt;yourname&gt;.md. Use your actual name so the filename is different from everyone elses.\nStage and then commit that new file.\nPush to GitHub.\nMake some more changes and push to GitHub.\nPull in your partner’s (and everyone elses) changes\n\nShow me in RStudio – Show me in JupyterLab\n\n\nPair-activity 3\nYou can copy your own or other people’s repos1.\n\nIn a browser, go to the GitHub repository https://github.com/RWorkflow-Workshops/Week5\nCopy its URL.\nNavigate to your GitHub page: click your icon in the upper right and then ‘your repositories’\nClick the + in top right and click import repository. Paste in the URL and give your repo a name.\nUse Skill #1 to clone your new repo to RStudio and create a new project",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-git-rstudio.html#footnotes",
    "href": "content/02-git-rstudio.html#footnotes",
    "title": "Basic Git/GitHub Skills Using RStudio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is different from forking. There is no connection to the original repository.↩︎",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "Git-RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#open-rstudio-in-the-jupyterhub",
    "href": "content/02-rstudio.html#open-rstudio-in-the-jupyterhub",
    "title": "RStudio - R",
    "section": "Open RStudio in the JupyterHub",
    "text": "Open RStudio in the JupyterHub\n\nLogin the JupyterHub\nClick on the RStudio button when the Launcher appears \nLook for the browser tab with the RStudio icon",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#basic-navigation",
    "href": "content/02-rstudio.html#basic-navigation",
    "title": "RStudio - R",
    "section": "Basic Navigation",
    "text": "Basic Navigation\n\n\n\nRStudio Panels",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#create-an-rstudio-project",
    "href": "content/02-rstudio.html#create-an-rstudio-project",
    "title": "RStudio - R",
    "section": "Create an RStudio project",
    "text": "Create an RStudio project\n\nOpen RStudio\nIn the file panel, click on the Home icon to make sure you are in your home directory\nFrom the file panel, click “New Project” to create a new project\nIn the pop up, select New Directory and then New Project\nName it sandbox\nClick on the dropdown in the upper right corner to select your sandbox project\nClick on Tools &gt; Project Options &gt; General and change the first 2 options about saving and restoring the workspace to “No”",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#installing-packages",
    "href": "content/02-rstudio.html#installing-packages",
    "title": "RStudio - R",
    "section": "Installing packages",
    "text": "Installing packages\nIn the bottom right panel, select the Packages tab, click install and then start typing the name of the package. Then click Install.\nThe JupyterHub comes with many packages already installed so you shouldn’t have to install many packages.\nWhen you want to use a package, you first need to load it with\nlibrary(hello)\nYou will see this in the tutorials. You might also see something like\nhello::thefunction()\nThis is using thefunction() from the hello package.\n\n\n\n\n\n\nNote\n\n\n\nPython users. In R, you will always call a function like funtion(object) and never like object.function(). The exception is something called ‘piping’ in R, which I have never seen in Python. In this case you pass objects left to right. Like object %&gt;% function(). Piping is very common in modern R but you won’t see it much in R from 10 years ago.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#uploading-and-downloading-files",
    "href": "content/02-rstudio.html#uploading-and-downloading-files",
    "title": "RStudio - R",
    "section": "Uploading and downloading files",
    "text": "Uploading and downloading files\nNote, Upload and download is only for the JupyterHub not on RStudio on your computer.\n\nUploading is easy.\nLook for the Upload button in the Files tab of the bottom right panel.\n\n\nDownload is less intuitive.\n\nClick the checkbox next to the file you want to download. One only.\nClick the “cog” icon in the Files tab of the bottom right panel. Then click Export.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#creating-files",
    "href": "content/02-rstudio.html#creating-files",
    "title": "RStudio - R",
    "section": "Creating files",
    "text": "Creating files\nWhen you start your server, you will have access to your own virtual drive space. No other users will be able to see or access your files. You can upload files to your virtual drive space and save files here. You can create folders to organize your files. You personal directory is home/rstudio. Everyone has the same home directory but your files are separate and cannot be seen by others.\nPython users: If you open a Python image instead of the R image, your home is home/jovyan.\nThere are a number of different ways to create new files. Let’s practice making new files in RStudio.\n\nR Script\n\nOpen RStudio\nIn the upper right, make sure you are in your sandbox project.\nFrom the file panel, click on “New Blank File” and create a new R script.\nPaste\n\nprint(\"Hello World\")\n1+1\nin the script. 7. Click the Source button (upper left of your new script file) to run this code. 8. Try putting your cursor on one line and running that line of code by clicking “Run” 9. Try selecting lines of code and running that by clicking “Run”\n\n\ncsv file\n\nFrom the file panel, click on “New Blank File” and create a Text File.\nThe file will open in the top left corner. Paste in the following:\n\nname, place, value\nA, 1, 2\nB, 10, 20\nC, 100, 200\n\nClick the save icon (above your new file) to save your csv file\n\n\n\nA Rmarkdown document\nNow let’s create some more complicated files using the RStudio template feature.\n\nFrom the upper left, click File -&gt; New File -&gt; RMarkdown\nClick “Ok” at the bottom.\nWhen the file opens, click Knit (icon at top of file).\nIt will ask for a name. Give it one and save.\nYou file will render into html.\n\nReference sheet for writing in RMarkdown or go to Help &gt; Markdown Quick Reference\n\n\nA Rmarkdown presentation\n\nFrom the upper left, click File -&gt; New File -&gt; RMarkdown\nClick “Presentation” on left of the popup and click “Ok” at the bottom.\nWhen the file opens, click Knit (icon at top of file).\nIt will ask for a name. Give it one and save.\nYou file will render into html.\n\n\n\n(advanced) An interactive application\n\nFrom the upper left, click File -&gt; New File -&gt; Shiny Web App\nIn the popup, give the app a name and make sure the app is saved to my-files\nWhen the file opens, Run App (icon at top of file).\n\n\n\nAnd many more\nPlay around with creating other types of documents using templates. Especially if you already use RStudio.",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#more-tips",
    "href": "content/02-rstudio.html#more-tips",
    "title": "RStudio - R",
    "section": "More tips",
    "text": "More tips\nLearn some tips and tricks from these\n\nhttps://colorado.posit.co/rsc/the-unknown/into-the-unknown.html\nhttps://www.dataquest.io/blog/rstudio-tips-tricks-shortcuts/",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "content/02-rstudio.html#plotting-a-netcdf-file",
    "href": "content/02-rstudio.html#plotting-a-netcdf-file",
    "title": "RStudio - R",
    "section": "Plotting a netCDF file",
    "text": "Plotting a netCDF file\n\nhttps://pjbartlein.github.io/REarthSysSci/netCDF.html\nhttps://r-spatial.github.io/sf/articles/sf1.html\n\nwebpage:\nhttps://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg.graph?sst%5B(2023-08-27T12:00:00Z)%5D%5B(0.0)%5D%5B(-7.8):(44.8)%5D%5B(39.7):(92.3)%5D&.draw=surface&.vars=longitude%7Clatitude%7Csst&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\nurl from the dropdown on that page\nurl &lt;- https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg.nc?sst%5B(2023-08-27T12:00:00Z)%5D%5B(0.0)%5D%5B(-7.875):(44.875)%5D%5B(39.625):(92.375)%5D&.draw=surface&.vars=longitude%7Clatitude%7Csst&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\n\nOpen an R script\n\nAdd this code.\n\nlibrary(ggplot2) # package for plotting\nlibrary(sf)\nlibrary(stars)\nlibrary(dplyr)\n\nurl &lt;- \"https://coastwatch.pfeg.noaa.gov/erddap/griddap/ncdcOisst21Agg.nc?sst%5B(2023-08-27T12:00:00Z)%5D%5B(0.0)%5D%5B(-7.875):(44.875)%5D%5B(39.625):(92.375)%5D&.draw=surface&.vars=longitude%7Clatitude%7Csst&.colorBar=%7C%7C%7C%7C%7C&.bgColor=0xffccccff\"\n\nfil &lt;- \"sst.nc\"\nif(!exists(fil)){\n  download.file(url=url, destfile=fil)\n}\n\nstars_object &lt;- raster::raster(fil) %&gt;% st_as_stars()\nggplot() + geom_stars(data = stars_object)",
    "crumbs": [
      "JupyterHub",
      "Welcome",
      "Orientation",
      "RStudio"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "",
    "text": "Welcome to the NOAA Fisheries workshop focused on geospatial analysis using ocean ‘big data’. Today, we are focused on using data from NASA EarthData but the skills you will learn are transferable to other ways that you might get earth data, e.g. NESDIS, NCEI, ERDDAP servers, Copernicus, etc.\nThis session will also introduce to working with JupyterHubs. We will use both Jupyter Lab (Python) and RStudio (R) within our JupyterHub. Go to set-up for the basic orientation and how to get on the JupyterHub.",
    "crumbs": [
      "JupyterHub",
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#topics-for-may-15-2024",
    "href": "index.html#topics-for-may-15-2024",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "Topics for May 15, 2024",
    "text": "Topics for May 15, 2024\n\nIntroduction to working with earth data in the cloud and NASA Earth Data\nOrientation on our JupyterHub\nTutorial 1: Searching for resources in NASA Earth Data\nTutorial 2: Points and shapefiles\nTutorial 3: Subsetting your earth data with in a region (shapefile)\nTutorial 4: Getting values at points (along a track or transect)",
    "crumbs": [
      "JupyterHub",
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#resources",
    "href": "index.html#resources",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "Resources",
    "text": "Resources\n\nCoastWatch GitHub organization for many more training modules for working with satellite data in Python and R\nNASA EarthData Cloudbook for many tutorials on using satellite data in Python and R and NASA Earth Data",
    "crumbs": [
      "JupyterHub",
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#thank-you-for-inspiration-and-content",
    "href": "index.html#thank-you-for-inspiration-and-content",
    "title": "EDMW 2024 - Workshop 3B",
    "section": "Thank you for inspiration and content!",
    "text": "Thank you for inspiration and content!\nThank you to the open science community that has created software, teaching resources, and workflows that we have been able to build off of and be inspired by. These include: NASA Openscapes • OceanHackWeek • SnowEx Hackweek • eScience Institute, University of Washington • ICESat-2 Hackweek • Project Jupyter • Pangeo Project • CryoCloud",
    "crumbs": [
      "JupyterHub",
      "Welcome"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "11-22 September 2023"
  },
  {
    "objectID": "support.html#thank-you-for-inspiration-and-content",
    "href": "support.html#thank-you-for-inspiration-and-content",
    "title": "Acknowledgements",
    "section": "Thank you for inspiration and content!",
    "text": "Thank you for inspiration and content!\nThank you to the open science community that has created software, teaching resources, and workflows that we have been able to build off of and be inspired by. These include: NASA Openscapes • OceanHackWeek • SnowEx Hackweek • eScience Institute, University of Washington • ICESat-2 Hackweek • Project Jupyter • Pangeo Project • CryoCloud"
  },
  {
    "objectID": "tutorials/python/1-earthaccess-cut-items.html#summary",
    "href": "tutorials/python/1-earthaccess-cut-items.html#summary",
    "title": "Earthdata Search and Discovery",
    "section": "Summary",
    "text": "Summary\nIn this example we will use the earthaccess library to search for data collections from NASA Earthdata. earthaccess is a Python library that simplifies data discovery and access to NASA Earth science data by providing an abstraction layer for NASA’s Common Metadata Repository (CMR) API Search API. The library makes searching for data more approachable by using a simpler notation instead of low level HTTP queries. earthaccess takes the trouble out of Earthdata Login authentication, makes search easier, and provides a stream-line way to download or stream search results into an xarray object.\nFor more on earthaccess visit the earthaccess GitHub page and/or the earthaccess documentation site. Be aware that earthaccess is under active development."
  },
  {
    "objectID": "tutorials/python/1-earthaccess-cut-items.html#prerequisites",
    "href": "tutorials/python/1-earthaccess-cut-items.html#prerequisites",
    "title": "Earthdata Search and Discovery",
    "section": "Prerequisites",
    "text": "Prerequisites\nAn Earthdata Login account is required to access data from NASA Earthdata. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up."
  },
  {
    "objectID": "tutorials/python/1-earthaccess-cut-items.html#get-started",
    "href": "tutorials/python/1-earthaccess-cut-items.html#get-started",
    "title": "Earthdata Search and Discovery",
    "section": "Get Started",
    "text": "Get Started\n\nImport Required Packages\n\nimport earthaccess \nfrom pprint import pprint\nimport xarray as xr\nimport geopandas as gpd\n\n\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\n\n\nSearch for data\nThere are multiple keywords we can use to discovery data from collections. The table below contains the short_name, concept_id, and doi for some collections we are interested in for other exercises. Each of these can be used to search for data or information related to the collection we are interested in.\n\n\n\n\n\n\n\n\nShortname\nCollection Concept ID\nDOI\n\n\n\n\nMUR-JPL-L4-GLOB-v4.1\nC1996881146-POCLOUD\n10.5067/GHGMR-4FJ04\n\n\nAVHRR_OI-NCEI-L4-GLOB-v2.1\nC2036881712-POCLOUD\n10.5067/GHAAO-4BC21\n\n\n\nHow can we find the shortname, concept_id, and doi for collections not in the table above?. Let’s take a quick detour.\nhttps://search.earthdata.nasa.gov/search\n\nSearch by collection\n\ncollection_id = 'C1996881146-POCLOUD'\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    count = 10    # Restricting to 10 records returned\n)\n\nGranules found: 8002\n\n\nIn this example we used the concept_id parameter to search from our desired collection. However, there are multiple ways to specify the collection(s) we are interested in. Alternative parameters include:\n\ndoi - request collection by digital object identifier (e.g., doi = ‘10.5067/GHGMR-4FJ04’)\n\nshort_name - request collection by CMR shortname (e.g., short_name = ‘MUR-JPL-L4-GLOB-v4.1’)\n\nNOTE: Each Earthdata collection has a unique concept_id and doi. This is not the case with short_name. A shortname can be associated with multiple versions of a collection. If multiple versions of a collection are publicaly available, using the short_name parameter with return all versions available. It is advised to use the version parameter in conjunction with the short_name parameter with searching.\nWe can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the temporal parameter to request a date range and the bounding_box parameter to request granules that intersect with a bounding box.\nFor our bounding box, we need the xmin, ymin, xmax, ymax and we will assign this to bbox. We will assign our start date and end date to a variable named date_range\n\ndate_range = (\"2020-01-16\", \"2020-12-16\")\n# (xmin=-73.5, ymin=33.5, xmax=-43.5, ymax=43.5)\nbbox = (-73.5, 33.5, -43.5, 43.5)\n\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 336\n\n\n\nThe short_name and concept_id search parameters can be used to request one or multiple collections per request, but the doi parameter can only request a single collection.\n&gt; concept_ids = [‘C2723754864-GES_DISC’, ‘C1646609808-NSIDC_ECS’]\n\nUse the cloud_hosted search parameter only to search for data assets available from NASA’s Earthdata Cloud.\nThere are even more search parameters that can be passed to help refine our search, however those parameters do have to be populated in the CMR record to be leveraged. A non exhaustive list of examples are below:\n\nday_night_flag = 'day'\n\ncloud_cover = (0, 10)\n\n\n\n# col_ids = ['C2723754864-GES_DISC', 'C1646609808-NSIDC_ECS', 'C2531308461-NSIDC_ECS', 'C2537927247-NSIDC_ECS']    # Specify a list of collections to pass to the search\n\n# results = earthaccess.search_data(\n#     concept_id = col_ids,\n#     #cloud_hosted = True,\n#     temporal = date_range,\n#     bounding_box = bbox,\n# )\n\n\n\n\nWorking with earthaccess returns\nFollowing the search for data, you’ll likely take one of two pathways with those results. You may choose to download the assets that have been returned to you or you may choose to continue working with the search results within the Python environment.\n\nDownload earthaccess results\nIn some cases you may want to download your assets. earthaccess makes downloading the data from the search results very easy using the earthaccess.download() function. The MUR SST files are very large so we won’t run this code.\ndownloaded_files = earthaccess.download( results[0:9], local_path=‘../data’, )\nearthaccess does a lot of heavy lifting for us. It identifies the downloadable links, passes our Earthdata Login credentials, and saves the files with the proper names.\n\n\nExplore earthaccess search response\n\nprint(f'The results variable is a {type(results)} of {type(results[0])}')\n\nThe results variable is a &lt;class 'list'&gt; of &lt;class 'earthaccess.results.DataGranule'&gt;\n\n\n\nlen(results)\n\n336\n\n\nWe can explore the first item (earthaccess.results.DataGranule) in our list.\n\nitem = results[0]\ntype(item)\n\nearthaccess.results.DataGranule\n\n\nEach item contains three keys that can be used to explore the item\n\nitem.keys()\n\ndict_keys(['meta', 'umm', 'size'])\n\n\n\nitem['umm']\n\n{'TemporalExtent': {'RangeDateTime': {'EndingDateTime': '2020-01-16T21:00:00.000Z',\n   'BeginningDateTime': '2020-01-15T21:00:00.000Z'}},\n 'MetadataSpecification': {'URL': 'https://cdn.earthdata.nasa.gov/umm/granule/v1.6.5',\n  'Name': 'UMM-G',\n  'Version': '1.6.5'},\n 'GranuleUR': '20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1',\n 'ProviderDates': [{'Type': 'Insert', 'Date': '2021-03-31T16:12:39.303Z'},\n  {'Type': 'Update', 'Date': '2021-03-31T16:12:39.322Z'}],\n 'SpatialExtent': {'HorizontalSpatialDomain': {'Geometry': {'BoundingRectangles': [{'WestBoundingCoordinate': -180,\n      'SouthBoundingCoordinate': -90,\n      'EastBoundingCoordinate': 180,\n      'NorthBoundingCoordinate': 90}]}}},\n 'DataGranule': {'ArchiveAndDistributionInformation': [{'SizeUnit': 'MB',\n    'Size': 673.3220148086548,\n    'Checksum': {'Value': '45a73781f8666f74237ce6ae1d57e2d9',\n     'Algorithm': 'MD5'},\n    'SizeInBytes': 706029305,\n    'Name': '20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc'},\n   {'SizeUnit': 'MB',\n    'Size': 9.059906005859375e-05,\n    'Checksum': {'Value': 'fe7bbdcbf9a580175965c417aed586df',\n     'Algorithm': 'MD5'},\n    'SizeInBytes': 95,\n    'Name': '20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc.md5'}],\n  'DayNightFlag': 'Unspecified',\n  'ProductionDateTime': '2020-01-25T00:42:39.000Z'},\n 'CollectionReference': {'Version': '4.1',\n  'ShortName': 'MUR-JPL-L4-GLOB-v4.1'},\n 'RelatedUrls': [{'URL': 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n   'Type': 'GET DATA VIA DIRECT ACCESS',\n   'Description': 'This link provides direct download access via S3 to the granule.'},\n  {'URL': 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc.md5',\n   'Description': 'Download 20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc.md5',\n   'Type': 'EXTENDED METADATA'},\n  {'URL': 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n   'Description': 'Download 20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n   'Type': 'GET DATA'},\n  {'URL': 'https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-public/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.cmr.json',\n   'Description': 'Download 20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.cmr.json',\n   'Type': 'EXTENDED METADATA'},\n  {'URL': 'https://archive.podaac.earthdata.nasa.gov/s3credentials',\n   'Description': 'api endpoint to retrieve temporary credentials valid for same-region direct s3 access',\n   'Type': 'VIEW RELATED INFORMATION'},\n  {'URL': 'https://opendap.earthdata.nasa.gov/providers/POCLOUD/collections/GHRSST%20Level%204%20MUR%20Global%20Foundation%20Sea%20Surface%20Temperature%20Analysis%20(v4.1)/granules/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1',\n   'Type': 'USE SERVICE API',\n   'Subtype': 'OPENDAP DATA',\n   'Description': 'OPeNDAP request URL'}]}\n\n\n\n\nGet data URLs / S3 URIs\nGet links to data. The data_links() method is used to return the URL(s)/data link(s) for the item. By default the method returns the HTTPS URL to download or access the item.\n\nitem.data_links()\n\n['https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc']\n\n\nThe data_links() method can also be used to get the s3 URI when we want to perform direct s3 access of the data in the cloud. To get the s3 URI, pass access = 'direct' to the method.\n\nitem.data_links(access='direct')\n\n['s3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc']\n\n\nIf we want to extract all of the data links from our search results and add or save them to a list, we can.\n\ndata_link_list = []\n\nfor granule in results:\n    for asset in granule.data_links(access='direct'):\n        data_link_list.append(asset)\n        \n\n\ndata_link_list[0:9]\n\n['s3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200117090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200118090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200119090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200120090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200121090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200122090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200123090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc',\n 's3://podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200124090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc']\n\n\nWe can pass or read these lists of data links into libraries like xarray, rioxarray, or gdal, but earthaccess has a built-in module for easily reading these data links in.\n\n\nOpen results in xarray\nWe use earthaccess’s open() method to make a connection to and open the files from our search result.\n\nfileset = earthaccess.open(results[1:30])\n\nOpening 29 granules, approx size: 19.99 GB\n\n\n\n\n\n\n\n\n\n\n\nThen we pass the fileset object to xarray.\n\nds = xr.open_mfdataset(fileset, chunks = {})\n\nSome really cool things just happened here! Not only were we able to seamlessly stream our earthaccess search results into a xarray dataset using the open_mfdataset() (multi-file) method, but earthaccess whether we were working from within AWS us-west-2 and could use direct S3 access or if not, would use https. We didn’t have to create a session or a filesystem to authenticate and connect to the data. earthaccess did this for us using the auth object we created at the beginning of this tutorial.\nLet’s take a quick lock at our xarray dataset\n\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                    (time: 18, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                        (lon) float32 -179.9 -179.8 ... 179.9 179.9\n  * lat                        (lat) float32 -89.95 -89.85 ... 89.85 89.95\n  * time                       (time) object 2019-11-19 00:00:00 ... 2019-12-...\nDimensions without coordinates: nv\nData variables:\n    precipitationCal           (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt       (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitationCal_cnt_cond  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation            (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    HQprecipitation_cnt_cond   (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt            (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                  (time, nv) object dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes:\n    BeginDate:       2019-11-19\n    BeginTime:       00:00:00.000Z\n    EndDate:         2019-11-19\n    EndTime:         23:59:59.999Z\n    FileHeader:      StartGranuleDateTime=2019-11-19T00:00:00.000Z;\\nStopGran...\n    InputPointer:    3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B....\n    title:           GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 ...\n    DOI:             10.5067/GPM/IMERGDF/DAY/06\n    ProductionTime:  2020-02-27T16:09:48.308Zxarray.DatasetDimensions:time: 18lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.8 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95   , -179.84999, -179.75   , ...,  179.75002,  179.85002,\n        179.95   ], dtype=float32)lat(lat)float32-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95    , -89.85    , -89.75    , ...,  89.75    ,  89.850006,\n        89.95001 ], dtype=float32)time(time)object2019-11-19 00:00:00 ... 2019-12-...standard_name :timebounds :time_bndsarray([cftime.DatetimeJulian(2019, 11, 19, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 20, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 21, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 22, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 23, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 24, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 25, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 26, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 27, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 28, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 29, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 11, 30, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 1, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 2, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 3, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 4, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 5, 0, 0, 0, 0, has_year_zero=False),\n       cftime.DatetimeJulian(2019, 12, 6, 0, 0, 0, 0, has_year_zero=False)],\n      dtype=object)Data variables: (9)precipitationCal(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mmlong_name :Daily accumulated precipitation (combined microwave-IR) estimate\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\nprecipitationCal_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitationCal retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\nprecipitationCal_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly precipitationCal retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\nHQprecipitation\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\nmm\n\nlong_name :\n\nDaily accumulated High Quality precipitation from all available MW sources\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\nHQprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly HQprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\nHQprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly HQprecipitation retrievals for the day where precipitation is greater than 0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\nrandomError\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\nmm\n\nlong_name :\n\nDaily total error of precipitation estimate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n444.95 MiB\n24.72 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n111.24 MiB\n6.18 MiB\n\n\nShape\n(18, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                                                           1800 3600 18\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(time, nv)\n\n\nobject\n\n\ndask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n288 B\n16 B\n\n\nShape\n(18, 2)\n(1, 2)\n\n\nDask graph\n18 chunks in 37 graph layers\n\n\nData type\nobject numpy.ndarray\n\n\n\n\n                          2 18\n\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.84999084472656,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.34999084472656,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.15000915527344,  179.25001525878906,\n                179.3500213623047,   179.4499969482422,   179.5500030517578,\n               179.65000915527344,  179.75001525878906,   179.8500213623047,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([-89.94999694824219,  -89.8499984741211,             -89.75,\n              -89.64999389648438, -89.54999542236328, -89.44999694824219,\n               -89.3499984741211,             -89.25, -89.14999389648438,\n              -89.04999542236328,\n              ...\n               89.05000305175781,  89.15000915527344,              89.25,\n               89.35000610351562,  89.45001220703125,  89.55000305175781,\n               89.65000915527344,              89.75,  89.85000610351562,\n               89.95001220703125],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(CFTimeIndex([2019-11-19 00:00:00, 2019-11-20 00:00:00, 2019-11-21 00:00:00,\n             2019-11-22 00:00:00, 2019-11-23 00:00:00, 2019-11-24 00:00:00,\n             2019-11-25 00:00:00, 2019-11-26 00:00:00, 2019-11-27 00:00:00,\n             2019-11-28 00:00:00, 2019-11-29 00:00:00, 2019-11-30 00:00:00,\n             2019-12-01 00:00:00, 2019-12-02 00:00:00, 2019-12-03 00:00:00,\n             2019-12-04 00:00:00, 2019-12-05 00:00:00, 2019-12-06 00:00:00],\n            dtype='object', length=18, calendar='julian', freq='D'))Attributes: (9)BeginDate :2019-11-19BeginTime :00:00:00.000ZEndDate :2019-11-19EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2019-11-19T00:00:00.000Z;\nStopGranuleDateTime=2019-11-19T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20191119-S000000-E002959.0000.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S003000-E005959.0030.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S010000-E012959.0060.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S013000-E015959.0090.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S020000-E022959.0120.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S023000-E025959.0150.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S030000-E032959.0180.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S033000-E035959.0210.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S040000-E042959.0240.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S043000-E045959.0270.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S050000-E052959.0300.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S053000-E055959.0330.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S060000-E062959.0360.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S063000-E065959.0390.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S070000-E072959.0420.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S073000-E075959.0450.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S080000-E082959.0480.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S083000-E085959.0510.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S090000-E092959.0540.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S093000-E095959.0570.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S100000-E102959.0600.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S103000-E105959.0630.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S110000-E112959.0660.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S113000-E115959.0690.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S120000-E122959.0720.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S123000-E125959.0750.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S130000-E132959.0780.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S133000-E135959.0810.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S140000-E142959.0840.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S143000-E145959.0870.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S150000-E152959.0900.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S153000-E155959.0930.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S160000-E162959.0960.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S163000-E165959.0990.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S170000-E172959.1020.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S173000-E175959.1050.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S180000-E182959.1080.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S183000-E185959.1110.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S190000-E192959.1140.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S193000-E195959.1170.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S200000-E202959.1200.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S203000-E205959.1230.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S210000-E212959.1260.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S213000-E215959.1290.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S220000-E222959.1320.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S223000-E225959.1350.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S230000-E232959.1380.V06B.HDF5;3B-HHR.MS.MRG.3IMERG.20191119-S233000-E235959.1410.V06B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/06ProductionTime :2020-02-27T16:09:48.308Z"
  },
  {
    "objectID": "tutorials/python/1-earthaccess-cut-items.html#resources",
    "href": "tutorials/python/1-earthaccess-cut-items.html#resources",
    "title": "Earthdata Search and Discovery",
    "section": "Resources",
    "text": "Resources\n\nNASA’s Common Metadata Repository (CMR) API\n\nearthaccess repository\nearthaccess documentation\nEarthdata Search"
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#summary",
    "href": "tutorials/python/2-subset-and-plot.html#summary",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Summary",
    "text": "Summary\nIn this examples we will use the xarray and earthaccess to subset data and make figures.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#learning-objectives",
    "href": "tutorials/python/2-subset-and-plot.html#learning-objectives",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Learning Objectives",
    "text": "Learning Objectives\n\nExtract variables, temporal slices, and spatial slices from an xarray dataset\nPlot data and exclude data points via boolean conditions, using xarray, cartopy, and matplotlib\n\n\nImport Required Packages\n\n# Suppress warnings\nimport warnings\nwarnings.simplefilter('ignore')\nwarnings.filterwarnings('ignore')\nfrom pprint import pprint\n\nimport earthaccess\nimport xarray as xr\nxr.set_options(display_expand_attrs=False)\nimport matplotlib.pyplot as plt\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\n%matplotlib inline",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#authenticate-to-nasa-earthdata",
    "href": "tutorials/python/2-subset-and-plot.html#authenticate-to-nasa-earthdata",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Authenticate to NASA Earthdata",
    "text": "Authenticate to NASA Earthdata\nWe will authenticate our Earthaccess session, and then open the results like we did in the Search & Discovery section.\n\n# Bug on dhub settings is setting the home to /home/rstudio\nimport os\nos.environ[\"HOME\"] = \"/home/jovyan\"\n\n\nauth = earthaccess.login()\n# are we authenticated?\nif not auth.authenticated:\n    # ask for credentials and persist them in a .netrc file\n    auth.login(strategy=\"interactive\", persist=True)\n\nEDL_USERNAME and EDL_PASSWORD are not set in the current environment, try setting them or use a different strategy (netrc, interactive)\nYou're now authenticated with NASA Earthdata Login\nUsing token with expiration date: 01/29/2024\nUsing .netrc file for EDL",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/python/2-subset-and-plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "href": "tutorials/python/2-subset-and-plot.html#xarray-subsetting---precipitation-estimates-from-imerg-daily-level-3",
    "title": "Data subsetting and plotting with earthaccess and xarray",
    "section": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3",
    "text": "Xarray Subsetting - Precipitation estimates from IMERG, Daily Level 3\n\nDataset\nWe will use the GPM IMERG Final Precipitation L3 Daily dataset for this tutorial. The IMERG Precipitation Rate provides the rain and snow rates in millimeters per hour (mm/hr). It is estimated by the Integrated Multi-satellitE Retrievals for Global Precipitation Measurement (GPM) (IMERG) algorithm. The IMERG algorithm uses passive-microwave data from the GPM constellation of satellites and infrared data from geosynchronous satellites. IMERG “morphs” observations to earlier or later times using wind from weather-model analyses. The daily IMERG dataset is derived from the half-hourly GPM_3IMERGHH. The derived result represents the final estimate of the daily mean precipitation rate in mm/day.\nLink to data on NASA Earthdata\nThe IMERG data has 0.1 x 0.1 degree latitude-longitude resolution (approximately 11 by 11 km at the Equator). The grid covers the globe, although precipitation cannot always be estimated near the Poles. The dataset and algorithm are described in the data user guide and the Algorithm Theoretical Basis Document (ATBD).\nPlease cite the dataset as: &gt; Huffman, G.J., E.F. Stocker, D.T. Bolvin, E.J. Nelkin, Jackson Tan (2023), GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07, Edited by Andrey Savtchenko, Greenbelt, MD, Goddard Earth Sciences Data and Information Services Center (GES DISC), https://doi.org/10.5067/GPM/IMERGDF/DAY/07\n\ncollection_id = 'C2723754864-GES_DISC'  # GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree V07 (GPM_3IMERGDF)\n# Seems to be a bug in the collection above so I am using older data\n\n# Bounds within which we search for data granules\ndate_start = \"2015-02-25\"\ndate_end = \"2015-02-26\"\ndate_range = (date_start, date_end)\nbbox = (-127.0761, 31.6444, -113.9039, 42.6310)  # min lon, min lat, max lon, max lat\n\n# For reference (e.g., to visualize in https://geojson.io/), here is a GeoJSON representing the above bounding box:\n# {\"type\": \"FeatureCollection\", \"features\": [{\"type\": \"Feature\", \"properties\": {}, \"geometry\": {\"type\": \"LineString\", \"bbox\": [-127.0761, 31.6444, -113.9039, 42.631], \"coordinates\": [[-113.9039, 42.631], [-127.0761,42.631], [-127.0761, 31.6444], [-113.9039, 31.6444], [-113.9039, 42.631]]}}]}\n\nresults = earthaccess.search_data(\n    concept_id = collection_id,\n    cloud_hosted = True,\n    temporal = date_range,\n    bounding_box = bbox,\n)\n\nGranules found: 2\n\n\n\nds = xr.open_mfdataset(earthaccess.open(results))\n\n Opening 2 granules, approx size: 0.05 GB\n\n\n\n\n\n\n\n\n\n\n\nNote that xarray works with “lazy” computation whenever possible. In this case, the metadata are loaded into JupyterHub memory, but the data arrays and their values are not — until there is a need for them.\nLet’s print out all the variable names.\n\nfor v in ds.variables:\n    print(v)\n\nprecipitation\nprecipitation_cnt\nprecipitation_cnt_cond\nMWprecipitation\nMWprecipitation_cnt\nMWprecipitation_cnt_cond\nrandomError\nrandomError_cnt\nprobabilityLiquidPrecipitation\nlon\nlat\ntime\ntime_bnds\n\n\nOf the variables listed above, we are interested in three variables: precipitation, precipitation_cnt_cond, and probabilityLiquidPrecipitation. Let’s print their attributes.\n\nds.variables['precipitation'].attrs\n\n{'units': 'mm/day',\n 'long_name': 'Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.'}\n\n\n\nds.variables['precipitation_cnt_cond'].attrs\n\n{'units': 'count',\n 'long_name': 'Count of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr'}\n\n\n\nds.variables['probabilityLiquidPrecipitation'].attrs\n\n{'units': 'percent',\n 'long_name': 'Probability of liquid precipitation',\n 'description': 'Probability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation.  Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.'}\n\n\n\n\nSubsetting\nIn addition to directly accessing the files archived and distributed by each of the NASA DAACs, many datasets also support services that allow us to customize the data via subsetting, reformatting, reprojection/regridding, and file aggregation. What does subsetting mean? To subset means to extract only the portions of a dataset that are needed for a given purpose.\nThere are three primary types of subsetting that we will walk through: 1. Temporal 2. Spatial 3. Variable\nIn each case, we will be excluding parts of the dataset that are not wanted using xarray. Note that “subsetting” is also called a data “transformation”.\n\nds.time.values\n\narray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')\n\n\nWe start with a subset that represents the U.S. state of California. Notice the dimensions of the Dataset and each variable — time, lon, lat, and ‘nv’ (number of vertices) for the bounds variable.\n\n# Display the full dataset's metadata\nds\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt;\nDimensions:                         (time: 2, lon: 3600, lat: 1800, nv: 2)\nCoordinates:\n  * lon                             (lon) float32 -179.9 -179.9 ... 179.9 179.9\n  * lat                             (lat) float64 -89.95 -89.85 ... 89.85 89.95\n  * time                            (time) datetime64[ns] 2015-02-25 2015-02-26\nDimensions without coordinates: nv\nData variables:\n    precipitation                   (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt               (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    precipitation_cnt_cond          (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation                 (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt             (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    MWprecipitation_cnt_cond        (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError                     (time, lon, lat) float32 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    randomError_cnt                 (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    probabilityLiquidPrecipitation  (time, lon, lat) int8 dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n    time_bnds                       (time, nv) datetime64[ns] dask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\nAttributes: (9)xarray.DatasetDimensions:time: 2lon: 3600lat: 1800nv: 2Coordinates: (3)lon(lon)float32-179.9 -179.9 ... 179.9 179.9units :degrees_eastlong_name :Longitudearray([-179.95, -179.85, -179.75, ...,  179.75,  179.85,  179.95],\n      dtype=float32)lat(lat)float64-89.95 -89.85 ... 89.85 89.95units :degrees_northlong_name :Latitudearray([-89.95, -89.85, -89.75, ...,  89.75,  89.85,  89.95])time(time)datetime64[ns]2015-02-25 2015-02-26standard_name :timelong_name :timebounds :time_bndsarray(['2015-02-25T00:00:00.000000000', '2015-02-26T00:00:00.000000000'],\n      dtype='datetime64[ns]')Data variables: (10)precipitation(time, lon, lat)float32dask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;units :mm/daylong_name :Daily mean precipitation rate (combined microwave-IR) estimate. Formerly precipitationCal.\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly precipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly precipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nMWprecipitation\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nDaily mean High Quality precipitation rate from all available microwave sources. Formerly HQprecipitation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nMWprecipitation_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of all valid half-hourly MWprecipitation retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nMWprecipitation_cnt_cond\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of half-hourly MWprecipitation retrievals for the day where precipitation is at least 0.01 mm/hr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nrandomError\n\n\n(time, lon, lat)\n\n\nfloat32\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\nmm/day\n\nlong_name :\n\nRoot-mean-square error estimate for combined microwave-IR daily precipitation rate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n49.44 MiB\n24.72 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nrandomError_cnt\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\ncount\n\nlong_name :\n\nCount of valid half-hourly randomError retrievals for the day\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\nprobabilityLiquidPrecipitation\n\n\n(time, lon, lat)\n\n\nint8\n\n\ndask.array&lt;chunksize=(1, 3600, 1800), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nunits :\n\npercent\n\nlong_name :\n\nProbability of liquid precipitation\n\ndescription :\n\nProbability of liquid precipitation estimated with a diagnostic parameterization using ancillary data. 0=missing values; 1=likely solid; 100=likely liquid or no precipitation. Screen by positive precipitation or precipitation_cnt_cond to locate meaningful probabilities.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.36 MiB\n6.18 MiB\n\n\nShape\n(2, 3600, 1800)\n(1, 3600, 1800)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\nint8 numpy.ndarray\n\n\n\n\n                           1800 3600 2\n\n\n\n\n\n\n\n\ntime_bnds\n\n\n(time, nv)\n\n\ndatetime64[ns]\n\n\ndask.array&lt;chunksize=(1, 2), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoordinates :\n\ntime nv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n32 B\n16 B\n\n\nShape\n(2, 2)\n(1, 2)\n\n\nDask graph\n2 chunks in 5 graph layers\n\n\nData type\ndatetime64[ns] numpy.ndarray\n\n\n\n\n          2 2\n\n\n\n\n\nIndexes: (3)lonPandasIndexPandasIndex(Float64Index([ -179.9499969482422, -179.85000610351562,             -179.75,\n              -179.64999389648438,  -179.5500030517578,  -179.4499969482422,\n              -179.35000610351562,             -179.25, -179.14999389648438,\n               -179.0500030517578,\n              ...\n                179.0500030517578,  179.14999389648438,              179.25,\n               179.35000610351562,   179.4499969482422,   179.5500030517578,\n               179.64999389648438,              179.75,  179.85000610351562,\n                179.9499969482422],\n             dtype='float64', name='lon', length=3600))latPandasIndexPandasIndex(Float64Index([            -89.95, -89.85000000000001,             -89.75,\n                          -89.65,             -89.55,             -89.45,\n              -89.35000000000001,             -89.25,             -89.15,\n                          -89.05,\n              ...\n                           89.05,  89.15000000000002,  89.25000000000001,\n               89.35000000000001,              89.45,              89.55,\n               89.65000000000002,  89.75000000000001,  89.85000000000001,\n                           89.95],\n             dtype='float64', name='lat', length=1800))timePandasIndexPandasIndex(DatetimeIndex(['2015-02-25', '2015-02-26'], dtype='datetime64[ns]', name='time', freq=None))Attributes: (9)BeginDate :2015-02-25BeginTime :00:00:00.000ZEndDate :2015-02-25EndTime :23:59:59.999ZFileHeader :StartGranuleDateTime=2015-02-25T00:00:00.000Z;\nStopGranuleDateTime=2015-02-25T23:59:59.999ZInputPointer :3B-HHR.MS.MRG.3IMERG.20150225-S000000-E002959.0000.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S003000-E005959.0030.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S010000-E012959.0060.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S013000-E015959.0090.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S020000-E022959.0120.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S023000-E025959.0150.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S030000-E032959.0180.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S033000-E035959.0210.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S040000-E042959.0240.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S043000-E045959.0270.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S050000-E052959.0300.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S053000-E055959.0330.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S060000-E062959.0360.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S063000-E065959.0390.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S070000-E072959.0420.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S073000-E075959.0450.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S080000-E082959.0480.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S083000-E085959.0510.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S090000-E092959.0540.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S093000-E095959.0570.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S100000-E102959.0600.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S103000-E105959.0630.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S110000-E112959.0660.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S113000-E115959.0690.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S120000-E122959.0720.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S123000-E125959.0750.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S130000-E132959.0780.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S133000-E135959.0810.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S140000-E142959.0840.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S143000-E145959.0870.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S150000-E152959.0900.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S153000-E155959.0930.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S160000-E162959.0960.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S163000-E165959.0990.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S170000-E172959.1020.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S173000-E175959.1050.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S180000-E182959.1080.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S183000-E185959.1110.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S190000-E192959.1140.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S193000-E195959.1170.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S200000-E202959.1200.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S203000-E205959.1230.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S210000-E212959.1260.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S213000-E215959.1290.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S220000-E222959.1320.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S223000-E225959.1350.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S230000-E232959.1380.V07B.HDF5;3B-HHR.MS.MRG.3IMERG.20150225-S233000-E235959.1410.V07B.HDF5title :GPM IMERG Final Precipitation L3 1 day 0.1 degree x 0.1 degree (GPM_3IMERGDF)DOI :10.5067/GPM/IMERGDF/DAY/07ProductionTime :2023-12-18T14:54:02.047Z",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Subset"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#overview",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#overview",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Overview",
    "text": "Overview\nIn this exercise you will extract satellite data around a set of points defined by longitude, latitude, and time coordinates, like that produced by an animal telemetry tag, and ship track, or a glider tract.\nPlease note that there may be more efficient ways, more Pythonic ways, to accomplish the tasks in this tutorial. The tutorial was developed to be easier to follow for less-experienced users of Python.\n\nThe exercise demonstrates the following techniques:\n\nLoading data from a tab- or comma-separated file\nPlotting the latitude/longitude points onto a map\nExtracting satellite data along a track\nBuilding an ERDDAP data-request URL\nSaving results as a CSV file\nPlotting the satellite data onto a map\n\n\n\nDatasets used:\n\nChlorophyll-a concentration from the European Space Agency’s Ocean Colour Climate Change Initiative Monthly dataset v6.0\nA loggerhead turtle telemetry track that has been subsampled to reduce the data requests needed for this tutorial from over 1200 to 25. The turtle was raised in captivity in Japan, then tagged and released on 05/04/2005 in the Central Pacific. Its tag transmitted for over 3 years and went all the way to the Southern tip of Baja California. The track dataset is stored in the data/ folder of this module.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#import-the-required-python-modules",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#import-the-required-python-modules",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Import the required Python modules",
    "text": "Import the required Python modules\n\nimport pandas as pd \nimport numpy as np \nimport warnings\nfrom urllib.parse import quote\nfrom datetime import datetime\nimport cartopy.crs as ccrs\nimport cartopy.feature as cfeature\n\nfrom cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\nimport matplotlib.pyplot as plt\n\nwarnings.filterwarnings('ignore')",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#load-the-track-data-into-a-pandas-data-frame",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#load-the-track-data-into-a-pandas-data-frame",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Load the track data into a Pandas data frame",
    "text": "Load the track data into a Pandas data frame\nBelow, the track data will load using the Pandas “read_csv” method. * The use the “.head()” method to view the column names and the first few rows of data. * Use the “.dtypes” to show the data type of each column. Note that numerical values are in the the mean_lon (float), mean_lat (float) year (integer), month (integer), and day (integer) columns. * Numerical values latitude and longitude values are good for plotting the track data on a map. * However, later on we will need to create string versions of the mean_lon and mean_lat columns and to create a date string from year, month, and day columns for use in the ERDDAP data request URL. * The latitude and longitude ranges are displayed below. These values will be helpful to set spatial boundaries when we plot the data onto maps.\n\nds = pd.read_csv('../data/25317_05_subsampled.dat')\nprint(ds.head(2))\nprint(' ')\nprint('Data types for each column')\nprint(ds.dtypes)\nprint(' ')\nprint('Spatial corrdinate ranges')\nprint('latitude range', round(ds.mean_lat.min(), 2), round(ds.mean_lat.max(), 2))\nprint('longitude range', round(ds.mean_lon.min(), 2), round(ds.mean_lon.max(), 2))\n\n     mean_lon   mean_lat  year  month  day\n0  176.619433  32.678728  2005      5    4\n1  175.860895  35.057734  2005      6   23\n \nData types for each column\nmean_lon    float64\nmean_lat    float64\nyear          int64\nmonth         int64\nday           int64\ndtype: object\n \nSpatial corrdinate ranges\nlatitude range 23.72 41.77\nlongitude range 175.86 248.57",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-the-track-on-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot the track on a map",
    "text": "Plot the track on a map\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n#ax1 = plt.subplot(211, projection=ccrs.PlateCarree(central_longitude=180))\n\nax1 = plt.axes(projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120, 260, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(125, 255, 20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20, 60, 10), crs=ccrs.PlateCarree())\n\n# add feature to the map\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# bring the lon and lat data into a numpy array \nx, y = ds.mean_lon.to_numpy(), ds.mean_lat.to_numpy()\n\nax1 = plt.plot(x, y, transform=ccrs.PlateCarree(), color='k')\n# start point in green star\nax1 = plt.plot(x[0], y[0],\n               marker='*',\n               color='g',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\n# end point in red X\nax1 = plt.plot(x[-1], y[-1],\n               marker='X',\n               color='r',\n               transform=ccrs.PlateCarree(),\n               markersize=10)\nplt.title('Animal Track for Turtle #25317', fontsize=20)\n\nplt.show()",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#prepare-track-data-for-use-in-the-erddap-data-request-url",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#prepare-track-data-for-use-in-the-erddap-data-request-url",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Prepare track data for use in the ERDDAP data-request URL",
    "text": "Prepare track data for use in the ERDDAP data-request URL\nTo build the ERDDAP data-request URLs, we will need: * Dates as strings in a format that ERDDAP can understand, i.e. YYYY-mm-dd.\n* The latitude and longitude values need to be converted to strings (characters) not the numerical values found in the mean_lon and mean_lat columns.\n\nCreate a formatted date column and change the columns data type\nLet’s do that in two steps:\n\nReload the “25317_05_subsampled.dat”. This time we will use the “parse_dates” option to create a Pandas date object column (year_month_day) from the ‘year’, ‘month’, and ‘day’ columns.\n\n\ndf = pd.read_csv('../data/25317_05_subsampled.dat',\n                 parse_dates=[['year', 'month', 'day']]\n                 )\n\nprint('The new year_month_day column contains the Pandas date objects')\ndf.head(2)\n\nThe new year_month_day column contains the Pandas date objects\n\n\n\n\n\n\n\n\n\n\nyear_month_day\nmean_lon\nmean_lat\n\n\n\n\n0\n2005-05-04\n176.619433\n32.678728\n\n\n1\n2005-06-23\n175.860895\n35.057734\n\n\n\n\n\n\n\n\n\nUse the year_month_day column to create a column called “date_str” containing string versions of the date with the format “YYYY-mm-dd”.\n\n\n\nDelete the year_month_day column to keep the data frame smaller\n\n\ndf['date_str'] = df['year_month_day'].dt.strftime('%Y-%m-%d')\n\n\n# Clean up the data frame a little by deleting the year_month_day column\ndel df['year_month_day']\nprint(df.head(2))\n\nprint(' ')\nprint('The time range is:', df.date_str.min(), df.date_str.max())\n\n     mean_lon   mean_lat    date_str\n0  176.619433  32.678728  2005-05-04\n1  175.860895  35.057734  2005-06-23\n \nThe time range is: 2005-05-04 2008-08-16\n\n\n\n\nCreate string versions of the latitude and longitude data\nCreate two new columns (mean_lon_str and mean_lat_str) the have the latitude and longitude coordinates as string data types rather than numerical (float) data types found in columns mean_lon and mean_lat.\n* The two new columns are mean_lon_str and mean_lat_str\n\ndf[['mean_lon_str', 'mean_lat_str']] = df[['mean_lon', \n                                           'mean_lat'\n                                          ]].to_numpy(dtype=str)\n\nprint(df.head(2))\nprint(' ')\nprint('Data types for each column')\nprint(df.dtypes)\n\n     mean_lon   mean_lat    date_str      mean_lon_str      mean_lat_str\n0  176.619433  32.678728  2005-05-04  176.619432886108  32.6787283689241\n1  175.860895  35.057734  2005-06-23  175.860895212552   35.057734124614\n \nData types for each column\nmean_lon        float64\nmean_lat        float64\ndate_str         object\nmean_lon_str     object\nmean_lat_str     object\ndtype: object",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#extract-data-from-a-satellite-dataset-corresponding-to-points-on-the-track",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Extract data from a satellite dataset corresponding to points on the track",
    "text": "Extract data from a satellite dataset corresponding to points on the track\nWe are going to download data from an ERDDAP server using the following steps: * Select a dataset * Loop though the track data using the string versions of data, latitude and longitude to build an ERDDAP data-request URL for each row of the track data frame. * Use the ERDDAP data-request URL to download satellite data into Pandas * Add the downloaded data to you track data frame.\n\nSelect a dataset\nWe’ll use the European Space Agency’s OC-CCI product (https://climate.esa.int/en/projects/ocean-colour/) to obtain chlorophyll data. This is a merged product combining data from many ocean color sensors to create a long time series (1997-present).\nIdeally we would use a daily dataset, selecting the day correspond the the track data date. However, chlorophyll measurements can have lots of missing data, primarily due to cloud cover. To reduce data gaps and improve the likelihood of data for our matchups, we can use a dataset that combines data monthly averages.\nLet’s use data from the monthly version of the OC-CCI datasets.\nThe ERDDAP URLs to the monthly version is below:\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0\nA note on dataset selection\nWe have preselected the dataset because we know it will work with this exercise. If you were selecting datasets on your own, you would want to check out the dataset to determine if its spatial and temporal coverages are suitable for your application. Following the link above you will find:\nThe latitude range is -89.97916 to 89.97916 and the longitude range is 0.020833 to 359.97916, which covers the track latitude range of 23.72 to 41.77 and longitude range of 175.86 to 248.57.\nThe time range is 1997-09-04 to 2023-03-01 (at the day of this writing), which covers the track time range of 2005-05-04 to 2008-08-16.\nYou should also note the name of the variable you will be downloading. For this dataset it is “chlor_a”\n\n\nRefresher on building the ERDDAP data-request URL\nTo refresh your memory from the ERDDAP Tutorial, a full ERDDAP data-request URL looks like the following: https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a[(2023-03-01)][(89.9792):(-89.9792)][(0.02083):(359.9792)]\np { text-align: justify;\nWe can deconstruct the URL into its component parts:\n\n\n\n\n\n\n\n\nName\nValue\nDescription\n\n\n\n\nERDDAP base URL\nhttps://oceanwatch.pifsc.noaa.gov/erddap/griddap/\nWeb location of ERDDAP server\n\n\nDataset ID\naesa-cci-chla-monthly-v6-0\nUnique dataset ID\n\n\nDownload file\n.csv\nData file to download (CSV is this case)\n\n\nQuery indicator\n?\nMark start of data query\n\n\nVariable\nchlor_a\nERDDAP variable to download\n\n\nTime range\n[(2023-02-15):1:(2023-03-01)]\nTemporal date range to download\n\n\nLatitude range\n[(89.9792):(-89.9792)]\nLatitude range to download\n\n\nLongitude range\n[(0.02083):(359.9792)]\nLongitude range to download\n\n\n\n}\nWe need to construct these components parts for each row of the track data frame and join them together to form the ERDDAP data-request URL.\n\n\nBuilding the ERDDAP data-request URL and downloading satellite data\n\n# create a data frame to hold the downloaded satellite data\ncol_names = [\"iso_date\", \"matched_lat\", \"matched_lon\", \"matched_chla\"]\n\n# create tot dataframe with the column names\ntot = pd.DataFrame(columns=col_names)\n\n# create variables for the unchanging parts of the ERDDAP data-request URL. \nbase_url = 'https://oceanwatch.pifsc.noaa.gov/erddap/griddap/'\ndataset_id = \"esa-cci-chla-monthly-v6-0\"\nfile_type = '.csv'\nquery_start = '?'\nerddap_variable = 'chlor_a'\n\n# create the start of the ERDDAP data-request URL by joining URL components\nstart_url = ''.join([base_url,\n                     dataset_id,\n                     file_type,\n                     query_start,\n                     erddap_variable\n                     ])\n\n# Finish each URL and download\nfor i in range(0, len(df)):\n    # for each row in the track data frame, create the query part of the ERDDAP data-request URL.\n    query_url = ''.join([\n                         '[(' + df['date_str'][i] + '):1:(' + df['date_str'][i] + ')]',\n                         '[(' + df['mean_lat_str'][i] + '):1:(' + df['mean_lat_str'][i] + ')]', \n                         '[(' + df['mean_lon_str'][i] + '):1:(' + df['mean_lon_str'][i] + ')]'\n                         ])\n    encoded_query = quote(query_url, safe='')\n\n    # join the start and query parts of the url\n    url = start_url + encoded_query\n    print(i+1, 'of', len(df), url)\n\n    # download the data as a CSV file directly into Pandas\n    new = pd.read_csv(url, skiprows=1)\n    new.columns = col_names\n    \n    # load into the holding data frame\n    tot = pd.concat([tot, new], ignore_index=True)\n    \n\n1 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-05-04%29%3A1%3A%282005-05-04%29%5D%5B%2832.6787283689241%29%3A1%3A%2832.6787283689241%29%5D%5B%28176.619432886108%29%3A1%3A%28176.619432886108%29%5D\n2 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-06-23%29%3A1%3A%282005-06-23%29%5D%5B%2835.057734124614%29%3A1%3A%2835.057734124614%29%5D%5B%28175.860895212552%29%3A1%3A%28175.860895212552%29%5D\n3 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-08-12%29%3A1%3A%282005-08-12%29%5D%5B%2840.4057593651645%29%3A1%3A%2840.4057593651645%29%5D%5B%28180.592617770427%29%3A1%3A%28180.592617770427%29%5D\n4 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-10-01%29%3A1%3A%282005-10-01%29%5D%5B%2841.6848032419466%29%3A1%3A%2841.6848032419466%29%5D%5B%28183.510212411605%29%3A1%3A%28183.510212411605%29%5D\n5 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282005-11-20%29%3A1%3A%282005-11-20%29%5D%5B%2837.3662285175569%29%3A1%3A%2837.3662285175569%29%5D%5B%28186.999746586372%29%3A1%3A%28186.999746586372%29%5D\n6 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-01-09%29%3A1%3A%282006-01-09%29%5D%5B%2832.1379277609952%29%3A1%3A%2832.1379277609952%29%5D%5B%28193.315150592714%29%3A1%3A%28193.315150592714%29%5D\n7 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-02-28%29%3A1%3A%282006-02-28%29%5D%5B%2832.1112577913518%29%3A1%3A%2832.1112577913518%29%5D%5B%28199.01578005525%29%3A1%3A%28199.01578005525%29%5D\n8 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-04-19%29%3A1%3A%282006-04-19%29%5D%5B%2834.9122377945573%29%3A1%3A%2834.9122377945573%29%5D%5B%28196.367856222399%29%3A1%3A%28196.367856222399%29%5D\n9 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-06-08%29%3A1%3A%282006-06-08%29%5D%5B%2834.6966077152962%29%3A1%3A%2834.6966077152962%29%5D%5B%28194.311561551928%29%3A1%3A%28194.311561551928%29%5D\n10 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-07-28%29%3A1%3A%282006-07-28%29%5D%5B%2837.0917501942058%29%3A1%3A%2837.0917501942058%29%5D%5B%28192.85445935735%29%3A1%3A%28192.85445935735%29%5D\n11 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-09-16%29%3A1%3A%282006-09-16%29%5D%5B%2841.7693290372383%29%3A1%3A%2841.7693290372383%29%5D%5B%28194.078757811627%29%3A1%3A%28194.078757811627%29%5D\n12 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-11-05%29%3A1%3A%282006-11-05%29%5D%5B%2838.2279593047231%29%3A1%3A%2838.2279593047231%29%5D%5B%28192.044436165313%29%3A1%3A%28192.044436165313%29%5D\n13 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282006-12-25%29%3A1%3A%282006-12-25%29%5D%5B%2834.7385780752043%29%3A1%3A%2834.7385780752043%29%5D%5B%28191.760026290605%29%3A1%3A%28191.760026290605%29%5D\n14 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-02-13%29%3A1%3A%282007-02-13%29%5D%5B%2831.7396435280445%29%3A1%3A%2831.7396435280445%29%5D%5B%28195.063134981283%29%3A1%3A%28195.063134981283%29%5D\n15 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-04-04%29%3A1%3A%282007-04-04%29%5D%5B%2834.3432418597437%29%3A1%3A%2834.3432418597437%29%5D%5B%28199.306553405532%29%3A1%3A%28199.306553405532%29%5D\n16 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-05-24%29%3A1%3A%282007-05-24%29%5D%5B%2835.1277116865649%29%3A1%3A%2835.1277116865649%29%5D%5B%28205.605040455239%29%3A1%3A%28205.605040455239%29%5D\n17 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-07-13%29%3A1%3A%282007-07-13%29%5D%5B%2838.460826483342%29%3A1%3A%2838.460826483342%29%5D%5B%28210.280467921659%29%3A1%3A%28210.280467921659%29%5D\n18 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-09-01%29%3A1%3A%282007-09-01%29%5D%5B%2839.3374947731784%29%3A1%3A%2839.3374947731784%29%5D%5B%28215.722452964025%29%3A1%3A%28215.722452964025%29%5D\n19 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-10-21%29%3A1%3A%282007-10-21%29%5D%5B%2835.8679284198372%29%3A1%3A%2835.8679284198372%29%5D%5B%28223.007301112593%29%3A1%3A%28223.007301112593%29%5D\n20 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282007-12-10%29%3A1%3A%282007-12-10%29%5D%5B%2830.1854023141461%29%3A1%3A%2830.1854023141461%29%5D%5B%28225.638647308816%29%3A1%3A%28225.638647308816%29%5D\n21 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-01-29%29%3A1%3A%282008-01-29%29%5D%5B%2828.328588352337%29%3A1%3A%2828.328588352337%29%5D%5B%28232.406424355302%29%3A1%3A%28232.406424355302%29%5D\n22 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-03-19%29%3A1%3A%282008-03-19%29%5D%5B%2825.9810780813157%29%3A1%3A%2825.9810780813157%29%5D%5B%28239.552975360004%29%3A1%3A%28239.552975360004%29%5D\n23 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-05-08%29%3A1%3A%282008-05-08%29%5D%5B%2824.8366188324699%29%3A1%3A%2824.8366188324699%29%5D%5B%28245.871574770029%29%3A1%3A%28245.871574770029%29%5D\n24 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-06-27%29%3A1%3A%282008-06-27%29%5D%5B%2823.7241735345355%29%3A1%3A%2823.7241735345355%29%5D%5B%28248.571044756%29%3A1%3A%28248.571044756%29%5D\n25 of 25 https://oceanwatch.pifsc.noaa.gov/erddap/griddap/esa-cci-chla-monthly-v6-0.csv?chlor_a%5B%282008-08-16%29%3A1%3A%282008-08-16%29%5D%5B%2826.7817714626367%29%3A1%3A%2826.7817714626367%29%5D%5B%28245.7579071789%29%3A1%3A%28245.7579071789%29%5D\n\n\n\ntot.head(2)\n\n\n\n\n\n\n\n\n\niso_date\nmatched_lat\nmatched_lon\nmatched_chla\n\n\n\n\n0\n2005-05-01T00:00:00Z\n32.6875\n176.604167\n0.293616\n\n\n1\n2005-07-01T00:00:00Z\n35.0625\n175.854167\n0.114716\n\n\n\n\n\n\n\n\n\n\nConsolidate the downloaded satellite data into the track data frame\n\n\ndf[['matched_lat', 'matched_lon', 'matched_chla']] = tot[['matched_lat',\n                                                          'matched_lon',\n                                                          'matched_chla'\n                                                          ]]\ndf.head(2)\n\n\n\n\n\n\n\n\n\nmean_lon\nmean_lat\ndate_str\nmean_lon_str\nmean_lat_str\nmatched_lat\nmatched_lon\nmatched_chla\n\n\n\n\n0\n176.619433\n32.678728\n2005-05-04\n176.619432886108\n32.6787283689241\n32.6875\n176.604167\n0.293616\n\n\n1\n175.860895\n35.057734\n2005-06-23\n175.860895212552\n35.057734124614\n35.0625\n175.854167\n0.114716\n\n\n\n\n\n\n\n\n\n\nSave your work\n\ndf.to_csv('chl_matchup_turtle25327.csv', index=False, encoding='utf-8')",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-chlorophyll-matchup-data-onto-a-map",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#plot-chlorophyll-matchup-data-onto-a-map",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "Plot chlorophyll matchup data onto a map",
    "text": "Plot chlorophyll matchup data onto a map\n\nFirst plot a histogram of the chlorophyll data\n\nprint('Range:', df.matched_chla.min(), df.matched_chla.max())\n_ = df.matched_chla.hist(bins=40)\n\nRange: 0.05568646 0.7134876\n\n\n\n\n\n\n\n\n\nThe range of chlorophyll values can be large, with lots of very low values, and a few very high values. This could skew a linear color bar so the most values lower values have the same color. * For this reason we often plot the log or log10 of chlorophyll\n\n\nPlot a histogram of the log of the chlorophyll data\n\nprint('Range:', np.log(df.matched_chla.min()), np.log(df.matched_chla.max()))\n_ = np.log(df.matched_chla).hist(bins=40)\n\nRange: -2.8880182495708433 -0.33759022133329325\n\n\n\n\n\n\n\n\n\n\nThe range of log chlorophyll is about -2.9 to -0.3 but most of the values are between -2.5 and -0.8.\nKnowing the distribution of values can also help to set the color bar range for our map.\n\n\n\nMap the chlorophyll data\n\nplt.figure(figsize=(14, 10))\n\n# Label axes of a Plate Carree projection with a central longitude of 180:\n\n# set the projection\nax1 = plt.axes(211, projection=ccrs.PlateCarree(central_longitude=180))\n\n# Use the lon and lat ranges to set the extent of the map\n# the 120, 260 lon range will show the whole Pacific\n# the 15, 55 lat range with capture the range of the data\nax1.set_extent([120,255, 15, 55], ccrs.PlateCarree())\n\n# set the tick marks to be slightly inside the map extents\nax1.set_xticks(range(120,255,20), crs=ccrs.PlateCarree())\nax1.set_yticks(range(20,50,10), crs=ccrs.PlateCarree())\n\n# Add geographical features\nax1.add_feature(cfeature.LAND, facecolor='0.6')\nax1.coastlines()\n\n# format the lat and lon axis labels\nlon_formatter = LongitudeFormatter(zero_direction_label=True)\nlat_formatter = LatitudeFormatter()\nax1.xaxis.set_major_formatter(lon_formatter)\nax1.yaxis.set_major_formatter(lat_formatter)\n\n# build and plot coordinates onto map\nx,y = list(df.mean_lon),list(df.mean_lat)\nax1 = plt.scatter(x, y, transform=ccrs.PlateCarree(),\n                  marker='o',\n                  c=np.log(df.matched_chla),\n                  cmap=plt.get_cmap('jet')\n                  )\nax1=plt.plot(x[0],y[0],marker='*', transform=ccrs.PlateCarree(), markersize=10)\nax1=plt.plot(x[-1],y[-1],marker='X', transform=ccrs.PlateCarree(), markersize=10)\n\n\n\n# control color bar values spacing\nlevs2 = np.arange(-2.5, 0, 0.5)\ncbar=plt.colorbar(ticks=levs2, shrink=0.75, aspect=10)\ncbar.set_label(\"Chl a (mg/m^3)\", size=15, labelpad=20)\n\n# set the labels to be exp(levs2) so the label reflect values of chl-a, not log(chl-a)\ncbar.ax.set_yticklabels(np.around(np.exp(levs2), 2), size=10)\n\nplt.title(\"Chlorophyll Matchup to Animal Track #25317\", size=15)\nplt.show()",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#on-your-own",
    "href": "tutorials/python/4-matchup-satellite-data-to-track-locations.html#on-your-own",
    "title": "Matchup satellite data to ship, glider, or animal tracks",
    "section": "On your own!",
    "text": "On your own!\n\nExercise 1:\nRepeat the steps above with a different dataset. For example, extract sea surface temperature data using the following dataset: https://coastwatch.pfeg.noaa.gov/erddap/griddap/nesdisGeoPolarSSTN5NRT_Lon0360.html\n* This dataset is a different ERDDAP, so remember the change the base URL. * Set the new dataset ID and variable name.\n\n\nExercise 2:\nGo to an ERDDAP of your choice, find a dataset of interest, generate the URL, copy it and edit the script above to run a match up on that dataset. To find other ERDDAP servers, you can use this search engine: http://erddap.com/\n* This dataset will likely be on a different ERDDAP, so remember the change the base URL. * Set the new dataset ID and variable name. * Check the metadata to make sure the dataset covers the spatial and temporal range of the track dataset.\n\n\nOptional\nRepeat the steps above with a daily version of the OC-CCI dataset to see how cloud cover can reduce the data you retrieve. https://oceanwatch.pifsc.noaa.gov/erddap/griddap/CRW_sst_v1_0.html",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in Python",
      "Track"
    ]
  },
  {
    "objectID": "tutorials/r/1-earthdatalogin.html#summary",
    "href": "tutorials/r/1-earthdatalogin.html#summary",
    "title": "Earthdata Search and Discovery",
    "section": "Summary",
    "text": "Summary\nIn this example we will use the earthdatalogin R package to search for data collections from NASA Earthdata. earthdatalogin is a R package that simplifies data discovery and access to NASA Earth science data by providing an abstraction layer for NASA’s Common Metadata Repository (CMR) API Search API. The library makes searching for data more approachable by using a simpler notation instead of low level HTTP queries. earthdatalogin takes the trouble out of Earthdata Login authentication, makes search easier, and provides a stream-lined way to download or stream search results into R data objects.\nFor more on earthdatalogin visit the earthdatalogin GitHub page and/or the earthdatalogin documentation site. Be aware that earthdatalogin is under active development.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Search"
    ]
  },
  {
    "objectID": "tutorials/r/1-earthdatalogin.html#prerequisites",
    "href": "tutorials/r/1-earthdatalogin.html#prerequisites",
    "title": "Earthdata Search and Discovery",
    "section": "Prerequisites",
    "text": "Prerequisites\nAn Earthdata Login account is required to access data from NASA Earthdata. Please visit https://urs.earthdata.nasa.gov to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.\n\nImport Required Packages\nNote: See the set-up tab (in left nav bar) for instructions on getting set up on your own computer.\n\n# devtools::install_github(\"boettiger-lab/earthdatalogin\")\n# install.packages(\"rstac\")\n# install.packages(\"gdalcubes\")\n\nlibrary(earthdatalogin)\nlibrary(rstac)\nlibrary(gdalcubes)\nlibrary(here)\n\nhere() starts at /home/jovyan/EDMW-EarthData-Workshop-2024\n\ngdalcubes::gdalcubes_options(parallel = TRUE) \n\n\n\nAuthentication for NASA Earthdata\nWe will start by authenticating using our Earthdata Login credentials. Authentication is not necessarily needed to search for publicly available data collections in Earthdata, but is always needed to download or access data from the NASA Earthdata archives. We can use edl_netrc() from the earthdatalogin package to create a .netrc file that will store our credentials.\nYou will have to register at https://urs.earthdata.nasa.gov/ as a new user.\nThe first time you run authentication use:\n\nearthdatalogin::edl_netrc(\n  username = \"user\", # add your user name\n  password = \"password\" # add you password\n)\n\nThis will save your .netrc file. After this you can run:\n\nearthdatalogin::edl_netrc()\n\nBecause the gdalcubes package, which we need for working with data cubes, doesn’t respect global environmental variables, we use a helper utility to export those into its configuration as well.\n\nearthdatalogin::with_gdalcubes()\n\n\n\nSearch for data\nThere are multiple keywords we can use to discovery data from collections. The table below contains the short_name, concept_id, and doi for some collections we are interested in for the tutorials today. Each of these can be used to search for data or information related to the collection we are interested in.\n\n\n\n\n\n\n\n\nShortname\nCollection Concept ID\nDOI\n\n\n\n\nMUR-JPL-L4-GLOB-v4.1\nC1996881146-POCLOUD\n10.5067/GHGMR-4FJ04\n\n\nAVHRR_OI-NCEI-L4-GLOB-v2.1\nC2036881712-POCLOUD\n10.5067/GHAAO-4BC21\n\n\n\nHow can we find the shortname, concept_id, and doi for collections not in the table above?. Let’s take a quick detour.\nhttps://search.earthdata.nasa.gov/search\nLet’s search for “GHRSST Level 4 MUR Global Foundation Sea Surface Temperature Analysis”.\nLink to the search\n\nIf we hover over the top box, we will see an i with a circle around it. Click that. On this page, you will see the DOI. Now click “View More Info” to get to https://cmr.earthdata.nasa.gov/search/concepts/C1996881146-POCLOUD.html\nOn that page you will see the “short name”. Note the short name was also on the first search page, but was not noted as the short name.\n\nSearch by short name\n\nshort_name &lt;- 'MUR-JPL-L4-GLOB-v4.1'\n\nLet’s set some time bounds.\n\ntbox &lt;- c(\"2020-01-16\", \"2020-12-16\")\n\n\nresults &lt;- earthdatalogin::edl_search(\n    short_name = short_name,\n    version = \"4.1\",\n    temporal = tbox\n)\nresults[1:3]\n\n[1] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[2] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200117090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[3] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200118090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n\n\nIn this example we used the short_name parameter to search from our desired data set. However, there are multiple ways to specify the collection(s) we are interested in. Alternative parameters include:\n\ndoi - request collection by digital object identifier (e.g., doi = ‘10.5067/GHAAO-4BC21’)\n\nNOTE: Each Earthdata collect has a unique concept_id and doi. This is not the case with short_name. A shortname can be associated with multiple versions of a collection. If multiple versions of a collection are publicaly available, using the short_name parameter with return all versions available. It is advised to use the version parameter in conjunction with the short_name parameter with searching.\nWe can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the temporal parameter to request a date range and the bounding_box parameter to request granules that intersect with a bounding box.\n\nbbox &lt;- c(xmin=-73.5, ymin=33.5, xmax=-43.5, ymax=43.5) \nbbox\n\n xmin  ymin  xmax  ymax \n-73.5  33.5 -43.5  43.5 \n\n\n\nresults &lt;- earthdatalogin::edl_search(\n    short_name = short_name,\n    version = \"4.1\",\n    temporal = tbox,\n    bounding_box = paste(bbox,collapse=\",\")\n)\nresults[1:3]\n\n[1] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[2] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200117090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n[3] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200118090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc\"\n\n\n\n\n\nWorking with earthdatalogin returns\nFollowing the search for data, you’ll likely take one of two pathways with those results. You may choose to download the assets that have been returned to you or you may choose to continue working with the search results within the R environment.\n\nDownload earthdatalogin results\nIn some cases you may want to download your assets. earthdatalogin makes downloading the data from the search results is very easy using the edl_download() function. The MUR SST files are 673Gb file so I would prefer not to download. But you could.\n\nearthdatalogin::edl_download(\n    results[1],\n    dest = here::here(\"test.nc\")\n)\n\n\n\nWork in the cloud\nWe do not have to download the data to work with it or at least not until we need to compute with it or plot it. Let’s look at a smaller dataset.\n\noi &lt;- earthdatalogin::edl_search(\n    short_name = \"AVHRR_OI-NCEI-L4-GLOB-v2.1\",\n    version = \"2.1\",\n    temporal = c(\"2020-01-16\", \"2020-01-17\")\n)\noi[1:3]\n\n[1] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20200115120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc\"\n[2] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20200116120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc\"\n[3] \"https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20200117120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc\"\n\n\nLet’s try plotting this. I am going to authenticate again just to make sure my token did not expire.\n\nlibrary(earthdatalogin)\n# Authenticate\nearthdatalogin::edl_netrc()\n\n\nlibrary(terra)\nras &lt;- terra::rast(x = oi[1], vsi=TRUE)\nplot(ras)",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Search"
    ]
  },
  {
    "objectID": "tutorials/r/1-earthdatalogin.html#conclusion",
    "href": "tutorials/r/1-earthdatalogin.html#conclusion",
    "title": "Earthdata Search and Discovery",
    "section": "Conclusion",
    "text": "Conclusion\nThis concludes tutorial 1. You have worked with remote-sensing data in the cloud and plotted it.\nNext we will learn to subset the data so we can work with bigger datasets in the cloud without downloading the whole dataset.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Search"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#background",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#background",
    "title": "Extract data within a boundary",
    "section": "Background",
    "text": "Background\nOne use for satellite observations is to supplement in situ sampling of geographical locations where the timespan, frequency measurements, spatial dimensions or remoteness of the locations, make physical sampling impossible or impractical. One drawback is that satellite data are often rectangular, whereas geographical locations can have irregular boundaries. Examples of boundaries include marine protected areas or marine physical, biological, and ecological divisions like the Longhurst Marine Provinces.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#objectives",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#objectives",
    "title": "Extract data within a boundary",
    "section": "Objectives",
    "text": "Objectives\nIn this tutorial we will learn how to download a timeseries of SST satellite data from an ERDDAP server, and then mask the data to retain only the data within an irregular geographical boundary (polygon). We will then plot a yearly seasonal cycle from within the boundary.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#the-tutorial-demonstrates-the-following-techniques",
    "title": "Extract data within a boundary",
    "section": "The tutorial demonstrates the following techniques",
    "text": "The tutorial demonstrates the following techniques\n\nDownloading data from an ERDDAP data server for a non-rectangular region using the rerddapXtracto package\nVisualizing data on a map\nPlotting a time-series of mean SST",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#datasets-used",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#datasets-used",
    "title": "Extract data within a boundary",
    "section": "Datasets used",
    "text": "Datasets used\nGHRSST Level 4 AVHRR_OI Global Blended Sea Surface Temperature Analysis (GDS2) from NCEI\nThis NOAA blended SST is a moderate resolution satellite-based gap-free sea surface temperature (SST) product. We will use the daily data. https://cmr.earthdata.nasa.gov/search/concepts/C2036881712-POCLOUD.html\nLonghurst Marine Provinces\nThe dataset represents the division of the world oceans into provinces as defined by Longhurst (1995; 1998; 2006). This division has been based on the prevailing role of physical forcing as a regulator of phytoplankton distribution. The Longhurst Marine Provinces dataset is available online (https://www.marineregions.org/downloads.php) and within the shapes folder associated with this repository. For this tutorial we will use the Gulf Stream province (ProvCode: GFST)\n\n\n\n../images/longhurst.png",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#load-packages",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#load-packages",
    "title": "Extract data within a boundary",
    "section": "Load packages",
    "text": "Load packages\n\nlibrary(sf)\nlibrary(rerddapXtracto)",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#load-boundary-coordinates",
    "title": "Extract data within a boundary",
    "section": "Load boundary coordinates",
    "text": "Load boundary coordinates\nThe shapefile for the Longhurst marine provinces includes a list of regions. For this exercise, we will only use the boundary of one province, the Gulf Stream region (“GFST”).\n\n# Set directory path\ndir_path &lt;- '../resources/longhurst_v4_2010/'\n\n# Import shape files (Longhurst coordinates)\nshapes &lt;- read_sf(dsn = dir_path, layer = \"Longhurst_world_v4_2010\")\n\n# Example List of all the province names\nshapes$ProvCode\n\n [1] \"BPLR\" \"ARCT\" \"SARC\" \"NADR\" \"GFST\" \"NASW\" \"NATR\" \"WTRA\" \"ETRA\" \"SATL\"\n[11] \"NECS\" \"CNRY\" \"GUIN\" \"GUIA\" \"NWCS\" \"MEDI\" \"CARB\" \"NASE\" \"BRAZ\" \"FKLD\"\n[21] \"BENG\" \"MONS\" \"ISSG\" \"EAFR\" \"REDS\" \"ARAB\" \"INDE\" \"INDW\" \"AUSW\" \"BERS\"\n[31] \"PSAE\" \"PSAW\" \"KURO\" \"NPPF\" \"NPSW\" \"TASM\" \"SPSG\" \"NPTG\" \"PNEC\" \"PEQD\"\n[41] \"WARM\" \"ARCH\" \"ALSK\" \"CCAL\" \"CAMR\" \"CHIL\" \"CHIN\" \"SUND\" \"AUSE\" \"NEWZ\"\n[51] \"SSTC\" \"SANT\" \"ANTA\" \"APLR\"\n\n# Get boundary coordinates for Gulf Stream region (GFST)\nGFST &lt;- shapes[shapes$ProvCode == \"GFST\",]\n\nxcoord &lt;- st_coordinates(GFST)[,1]\nycoord &lt;- st_coordinates(GFST)[,2]",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#get-a-vector-of-urls-to-our-nc-files",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#get-a-vector-of-urls-to-our-nc-files",
    "title": "Extract data within a boundary",
    "section": "Get a vector of urls to our nc files",
    "text": "Get a vector of urls to our nc files\n\nlibrary(earthdatalogin)\nedl_netrc()\nwith_gdalcubes()\n\n\nshort_name &lt;- 'AVHRR_OI-NCEI-L4-GLOB-v2.1'\nbbox &lt;- c(xmin=min(xcoord), ymin=min(ycoord), xmax=max(xcoord), ymax=max(ycoord)) \ntbox &lt;- c(\"2020-01-16\", \"2020-12-16\")\n\nresults &lt;- edl_search(\n    short_name = short_name,\n    version = \"2.1\",\n    temporal = tbox,\n    bounding_box = paste(bbox,collapse=\",\")\n)\n\nThere are 337 files.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#crop-and-plot-one-image",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#crop-and-plot-one-image",
    "title": "Extract data within a boundary",
    "section": "Crop and plot one image",
    "text": "Crop and plot one image\n\nlibrary(terra)\nras &lt;- terra::rast(results[1], vsi=TRUE)\ne &lt;- ext(c(min(xcoord), max(xcoord),  min(ycoord), max(ycoord) ))\nrc &lt;- crop(ras, e)\n\nThis has the following layers.\n\nnames(rc)\n\n[1] \"analysed_sst\"     \"analysis_error\"   \"mask\"             \"sea_ice_fraction\"\n\n\n\nplot(rc[[\"analysed_sst\"]])",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#apply-a-mask",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#apply-a-mask",
    "title": "Extract data within a boundary",
    "section": "Apply a mask",
    "text": "Apply a mask\nApply mask to a terra raster.\nhttps://rdrr.io/cran/terra/man/mask.html",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#create-a-data-cube",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#create-a-data-cube",
    "title": "Extract data within a boundary",
    "section": "Create a data cube",
    "text": "Create a data cube\nWe will create a data cube so that we can compute daily means over the polygon.",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  },
  {
    "objectID": "tutorials/r/3-extract-satellite-data-within-boundary.html#mask-the-polygon",
    "href": "tutorials/r/3-extract-satellite-data-within-boundary.html#mask-the-polygon",
    "title": "Extract data within a boundary",
    "section": "Mask the polygon",
    "text": "Mask the polygon\n\nPlot the data\n\n\nPlot the mean seasonal temperature for the province\nNot sure how to do this part.\n\nsst_mean=apply(satdata$sea_surface_temperature,3,mean,na.rm=TRUE)\n\n\nplot(satdata$time,sst_mean,main='Gulf Stream Province Monthly Mean Temperature 2020',ylab='SSt (ºC)',xlab='',type='b')",
    "crumbs": [
      "JupyterHub",
      "Tutorials",
      "Tutorials in R",
      "Mask"
    ]
  }
]