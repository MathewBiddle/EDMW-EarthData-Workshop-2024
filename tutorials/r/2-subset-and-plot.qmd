---
title: Subset and Plot
---

::: {.callout-note title="Learning Objectives"}

1. How to plot a subset of a data file
2. How to create a data cube
3. How to subset and aggregate a data cube
:::

## Load packages

```{r}
library(earthdatalogin)
library(gdalcubes)
library(terra)
```

## Get a vector of urls to our nc files

```{r}
edl_netrc()
with_gdalcubes()
```

```{r}
short_name <- 'MUR-JPL-L4-GLOB-v4.1'
bbox <- c(xmin=-73.5, ymin=33.5, xmax=-43.5, ymax=43.5) 
tbox <- c("2020-01-16", "2020-12-16")

results <- edl_search(
    short_name = short_name,
    version = "4.1",
    temporal = tbox,
    bounding_box = paste(bbox,collapse=",")
)
```

`results` is a vector of urls pointing to our netCDF files in the cloud.
```{r}
results[1:3]
```
Each netCDF file is ca 670Mb.

## Crop and plot one image

Each MUR SST netCDF file is large so I do not want to download. Instead I will use `terra::rast()` to do subset the data on the server side.

```{r}
library(terra)
ras <- terra::rast(results[1], vsi=TRUE)
e <- ext(c(-75.5, -73.5,  33.5, 35.5 ))
rc <- crop(ras, e)
plot(rc[[c(1, 2)]])
```

#### Open results in a data cube

Try with stars
https://r-spatial.github.io/stars/articles/stars2.html


Based on: [2-earthdata](https://boettiger-lab.github.io/nasa-topst-env-justice/tutorials/R/2-earthdata.html)

Unfortunately these netCDF files lack appropriate metadata (projection, extent) that GDAL expects. We can provide this manually using the GDAL VRT mechanism:
```{r}
vrt <- function(url) {
  prefix <-  "vrt://NETCDF:/vsicurl/"
  suffix <- ":analysed_sst?a_srs=OGC:CRS84&a_ullr=-180,90,180,-90"
  paste0(prefix, url, suffix)
}

# date associated with each file
url_dates <- as.Date(gsub(".*(\\d{8})\\d{6}.*", "\\1", results), format="%Y%m%d")
```

```{r}
data_gd <- gdalcubes::stack_cube(vrt(results), datetime_values = url_dates)
summary(data_gd)
```

```{r}
extent = list(left=-75.5, right=-73.5, bottom=bbox[2], top=35.5,
              t0=tbox[1], t1=tbox[2])

data_gd |> 
    gdalcubes::crop(extent) |> 
    aggregate_time(dt="P1M", method="mean")
```

```{r eval=FALSE}
# too slow
data_gd |> 
    slice_time(it=1) |>
    plot(col = viridisLite::viridis(10))
```

## Conclusions

Some really cool things just happened here! Not only were we able to seamlessly stream our `earthaccess` search results into a `xarray` `dataset` using the `open_mfdataset()` (multi-file) method, but `earthaccess` determined that we were working from within AWS us-west-2 and accessed the data via direct S3 access! We didn't have to create a session or a filesystem to authenticate and connect to the data. `earthaccess` did this for us using the `auth` object we created at the beginning of this tutorial. If we were not working in AWS us-west-2, `earthaccess` would "automagically" switch to accessing the data via the HTTPS endpoints and would again handle the authentication for us.


---

## Resources  

- NASAâ€™s [Common Metadata Repository (CMR) API](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html)   
- [`earthaccess` repository](https://github.com/nsidc/earthaccess)
- [`earthaccess` documentation](https://nsidc.github.io/earthaccess/)
- [Earthdata Search](https://search.earthdata.nasa.gov/search)
