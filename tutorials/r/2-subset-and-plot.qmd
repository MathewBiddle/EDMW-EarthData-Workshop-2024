---
title: Subset and Plot
---

::: {.callout-note title="Learning Objectives"}

1. How to crop a single data file
2. How to create a data cube with terra
3. How to crop a data cube to a box
:::

## Load packages

```{r message=FALSE}
library(earthdatalogin)
library(lubridate)
library(terra)
```

## Get a vector of urls to our nc files

Authenticate.
```{r}
earthdatalogin::edl_netrc() 
```

Get the urls.
```{r}
short_name <- 'MUR-JPL-L4-GLOB-v4.1'
bbox <- c(xmin=-73.5, ymin=33.5, xmax=-43.5, ymax=43.5) 
tbox <- c("2020-01-16", "2020-12-16")

results <- edl_search(
    short_name = short_name,
    version = "4.1",
    temporal = tbox,
    bounding_box = paste(bbox,collapse=",")
)
length(results)
```

`results` is a vector of urls pointing to our netCDF files in the cloud.
Each netCDF file is ca 670Mb.

```{r}
results[1:3]
```

## Crop and plot one netCDF file

Each MUR SST netCDF file is large so I do not want to download. Instead I will use `terra::rast()` to do subset the data on the server side. `vsi = TRUE` is letting it know that these are files in the cloud and to use GDAL functionality for that type of resource.

```{r}
ras <- terra::rast(results[1], vsi=TRUE)
```

::: {.callout-note title="Troubleshooting"}

If you get the following error:

> Warning: Opening a /vsi file with the netCDF driver requires Linux userfaultfd to be available. Or you may set the GDAL_SKIP=netCDF configuration option to force the use of the HDF5 driver. (GDAL error 1)Error: [rast] file does not exist: /vsicurl/https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/MUR-JPL-L4-GLOB-v4.1/20200116090000-JPL-L4_GHRSST-SSTfnd-MUR-GLOB-v02.0-fv04.1.nc

[insert solve]

:::

Crop to a small region.

```{r}
e <- terra::ext(c(-75.5, -73.5,  33.5, 35.5 ))
rc <- terra::crop(ras, e)
rc
```

Plot.
```{r}
plot(rc[[c(1, 2)]])
```


## Crop and plot multiple netCDF files

We can send multiple urls to terra. 

```{r}
ras_all <- terra::rast(results[c(1:4)], vsi = TRUE)
```

Crop to a small extent. The numbers are lons and lats.
```{r}
e <- terra::ext(c(-75.5, -73.5,  33.5, 35.5 ))
rc_all <- terra::crop(ras_all, e)
rc_sst <- rc_all["analysed_sst",]
```

Convert Kelvin to Celcius.

```{r}
rc_sst <- rc_sst - 273.15
```

Now plot. We will set the range so it is the same across plots and clean up the titles to be just day without time.
```{r}
titles <- terra::time(rc_sst) |> lubridate::date() |> as.character()
plot(
  rc_sst, 
  range = c(16, 26),
  main = titles
)
```

## Reading in a Zarr file

https://www.r-bloggers.com/2022/09/reading-zarr-files-with-r-package-stars/

```{r eval=FALSE}
library(stars)
## Loading required package: abind
## Loading required package: sf
## Linking to GEOS 3.10.2, GDAL 3.4.3, PROJ 8.2.0; sf_use_s2() is TRUE
dsn = 'ZARR:"/vsicurl/https://ncsa.osn.xsede.org/Pangeo/pangeo-forge/gpcp-feedstock/gpcp.zarr"'
bounds = c(longitude = "lon_bounds", latitude = "lat_bounds")
r = read_mdim(dsn, bounds = bounds)
r
```

Read one file.

```{r}
url <- "https://mur-sst.s3.us-west-2.amazonaws.com/zarr-v1"
prefixes <- 'ZARR:\"/vsicurl/'
slice <- '\":/analysed_sst:0"'
addr <- paste0(prefixes, url, slice)
y = terra::rast(addr)
```

Read multiple files.

```{r}
vrt <- function(i) {
  prefix <-  'ZARR:\"/vsicurl/'
  url <- "https://mur-sst.s3.us-west-2.amazonaws.com/zarr-v1"
  slice <- paste0('\":/analysed_sst:',i,'"')
  paste0(prefix, url, slice)
}
```

```{r}
y <- terra::rast(vrt(0:2))
y |> terra::crop(e) |> plot()
```

```{r eval=FALSE}
library(gdalcubes)
data_gd <- gdalcubes::stack_cube(vrt(0:2), datetime_values = as.Date(c("2022-01-01", "2022-01-02","2022-01-03")))
#extent = list(left=-75.5, right=-73.5, bottom=33.5, top=35.5, t0="2022-01-01", t1="2022-01-02")
extent = list(left=-75.5, right=-73.5, bottom=33.5, top=35.5)
test <- data_gd |> gdalcubes::crop(extent) |> 
    gdalcubes::aggregate_time(dt="P2D", method="mean") |> 
    plot(col = viridisLite::viridis(10))
```




## Conclusions

Some really cool things just happened here! You connected to multiple remote-sensing files (netCDF) in the cloud and worked with them without directly downloading them.


## Appendix

Alternatively we might get our bounding box from a shape. Here I get a bounding box around Indonesia. I am going to use a smaller dataset, the OI SST dataset.
```{r}
oi <- earthdatalogin::edl_search(
    short_name = "AVHRR_OI-NCEI-L4-GLOB-v2.1",
    version = "2.1",
    temporal = c("2020-01-16", "2020-01-17")
)
earthdatalogin::edl_netrc()
io_ras <- terra::rast(x = oi[1], vsi=TRUE)
```

Get the shape, then bounding box, then plot.
```{r}
library(tmap)
data(World)
ind_shp <- World$geometry[World$name == "Indonesia"]
ind <-sf::st_bbox( ind_shp )
(io_ras['analysed_sst'] - 273.15) |>
  crop(ind) |>
  plot()
polys( ind_shp |> vect(), "blue")
```

