---
title: Earthdatalogi  Search and Discovery
format:
  html:
    code-fold: true
---

## Summary

In this example we will use the `earthdatalogin` R package to search for data collections from NASA Earthdata. `earthdatalogin` is a R package that simplifies data discovery and access to NASA Earth science data by providing an abstraction layer for NASA’s [Common Metadata Repository (CMR) API](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html) Search API. The library makes searching for data more approachable by using a simpler notation instead of low level HTTP queries. `earthdatalogin` takes the trouble out of Earthdata Login **authentication**, makes **search** easier, and provides a stream-lined way to download or stream search results into R data objects.

For more on `earthdatalogin` visit the [`earthdatalogin` GitHub](https://github.com/boettiger-lab/earthdatalogin/) page and/or the [`earthdatalogin` documentation](https://boettiger-lab.github.io/earthdatalogin/) site. Be aware that `earthdatalogin` is under active development. 

## Prerequisites

An Earthdata Login account is required to access data from NASA Earthdata. Please visit <https://urs.earthdata.nasa.gov> to register and manage your Earthdata Login account. This account is free to create and only takes a moment to set up.  


## Learning Objectives

1. How to authenticate with `earthdatalogin`
2. How to use `earthdatalogin` to search for data using spatial and temporal filters
3. How to explore and work with search results

## Get Started

### Install earthdatalogin

Install the development version of earthdatalogin and update terra.

```{r eval=FALSE}
devtools::install_github("boettiger-lab/earthdatalogin")
install.packages("terra")
```

You will need GDAL installed. See these instructions if you do not have it installed:  https://developers.planet.com/docs/integrations/qgis/install-qgis-gdal/

You may need to install `terra` and `sf` from source to get them to use the latest GDAL installation. 
```
install.packages("terra", type = "source")
install.packages("sf", type = "source")
sf_extSoftVersion()
```


### Import Required Packages  

```{r}
library(earthdatalogin)
library(rstac)
library(gdalcubes)
gdalcubes_options(parallel = TRUE) 
```

### Authentication for NASA Earthdata  

We will start by authenticating using our Earthdata Login credentials. Authentication is not necessarily needed to search for publicly available data collections in Earthdata, but is always needed to download or access data from the NASA Earthdata archives. We can use `edl_netrc()` from the `earthdatalogin` package to create a `.netrc` file that will store our credentials. 

The first time you run authentication use:
```
edl_netrc(
  username = default("user"),
  password = default("password")
)
```
This will save your `.netrc` file. After this you can run:
```{r}
edl_netrc()
```

Because the `gdalcubes` package, which we need for working with data cubes, doesn't respect global environmental variables, we use a helper utility to export those into its configuration as well.

```{r}
with_gdalcubes()
```

### Search for data  

There are multiple keywords we can use to discovery data from collections. The table below contains the `short_name`, `concept_id`, and `doi` for some collections we are interested in for the tutorials today. Each of these can be 
used to search for data or information related to the collection we are interested in.  

| Shortname | Collection Concept ID | DOI |
| --- | --- | --- |
| MUR-JPL-L4-GLOB-v4.1 | C1996881146-POCLOUD | 10.5067/GHGMR-4FJ04 |

How can we find the `shortname`, `concept_id`, and `doi` for collections not in the table above?. Let's take a quick detour.

https://search.earthdata.nasa.gov/search

#### Search by text

Let's search for "GHRSST Level 4 MUR Global Foundation Sea Surface Temperature Analysis". Why this? Because we know the type of SST data we are looking for.

[Link to the search](https://search.earthdata.nasa.gov/search?q=GHRSST%20Level%204%20MUR%20Global%20Foundation%20Sea%20Surface%20Temperature%20Analysis)

![](images/SST_Blended_Earthdata_Search.png)

If we hover over the top box, we will see an i with a circle around it. Click that. On this page, you will see the DOI. Now click "View More Info" to get to https://cmr.earthdata.nasa.gov/search/concepts/C1996881146-POCLOUD.html

On that page you will see the "short name". Note the short name was also on the first search page, but was not noted as the short name.

#### Search by short name

```{r}
short_name <- 'MUR-JPL-L4-GLOB-v4.1'
```

Let's set some time bounds.
```{r}
tbox <- c("2020-01-16", "2020-12-16")
```

```{r}
results <- edl_search(
    short_name = short_name,
    version = "4.1",
    temporal = tbox
)
```

In this example we used the `short_name` parameter to search from our desired data set. However, there are multiple ways to specify the collection(s) we are interested in. Alternative parameters include:  

- `doi` - request collection by digital object identifier (e.g., `doi` = '10.5067/GHAAO-4BC21')  

**NOTE:** Each Earthdata collect has a unique `concept_id` and `doi`. This is not the case with `short_name`. A **shortname** can be associated with multiple versions of a collection. If multiple versions of a collection are publicaly available, using the `short_name` parameter with return all versions available. It is advised to use the `version` parameter in conjunction with the `short_name` parameter with searching.

We can refine our search by passing more parameters that describe the spatiotemporal domain of our use case. Here, we use the `temporal` parameter to request a date range and the `bounding_box` parameter to request granules that intersect with a bounding box.  



```{r}
bbox <- c(xmin=-73.5, ymin=33.5, xmax=-43.5, ymax=43.5) 
```


```{r}
results <- edl_search(
    short_name = short_name,
    version = "4.1",
    temporal = tbox,
    bounding_box = paste(bbox,collapse=",")
)
```


### Working with `earthdatalogin` returns  

Following the search for data, you'll likely take one of two pathways with those results. You may choose to **download** the assets that have been returned to you or you may choose to continue working with the search results within the R environment.  

#### Download `earthdatalogin` results

In some cases you may want to download your assets. `earthdatalogin` makes downloading the data from the search results is very easy using the `edl_download()` function. The MUR SST files are 673Gb file so I would prefer not to download. But you could.

```{r eval=FALSE}
edl_download(
    results[1],
    dest="test.nc"
)
```


```{r}
oi <- edl_search(
    short_name = "AVHRR_OI-NCEI-L4-GLOB-v2.1",
    version = "2.1",
    temporal = c("2020-01-16", "2020-01-17")
)
```


```{r}
library(earthdatalogin)
# Authenticate
edl_netrc()
```

```{r}
library(terra)
url <- "https://archive.podaac.earthdata.nasa.gov/podaac-ops-cumulus-protected/AVHRR_OI-NCEI-L4-GLOB-v2.1/20200115120000-NCEI-L4_GHRSST-SSTblend-AVHRR_OI-GLOB-v02.0-fv02.1.nc"
ras <- terra::rast(url, vsi=TRUE)
```

```{r}
r <- terra::rast(oi[1], vsi=TRUE)
```


#### Explore `earthdatalogin` search response

`results` is a vector of urls to the netCDF files.
```{r}
results[1:3]
```
Notice it will start with `https:` or `s3:`. The former is a slower from of access while the latter allows faster access, like having a cloud bucket attached as a drive to your browser.

```{r}
length(results)
```

```{r}
r <- terra::rast(results[1], vsi=TRUE)
```

#### Open results in a data cube

Based on: https://boettiger-lab.github.io/nasa-topst-env-justice/tutorials/R/2-earthdata.html

Unfortunately these netcdf files lack appropriate metadata (projection, extent) that GDAL expects. We can provide this manually using the GDAL VRT mechanism:
```{r}
vrt <- function(url) {
  prefix <-  "vrt://NETCDF:/vsicurl/"
  suffix <- ":analysed_sst?a_srs=OGC:CRS84&a_ullr=-180,90,180,-90"
  paste0(prefix, url, suffix)
}

# date associated with each file
url_dates <- as.Date(gsub(".*(\\d{8})\\d{6}.*", "\\1", results), format="%Y%m%d")
```

We use `earthaccess`'s `open()` method to make a connection to and open the files from our search result. 

```{python}
fileset = earthaccess.open(results)
```

Then we pass the `fileset` object to xarray.

```{python}
ds = xr.open_mfdataset(fileset, chunks = {})
```

Some really cool things just happened here! Not only were we able to seamlessly stream our `earthaccess` search results into a `xarray` `dataset` using the `open_mfdataset()` (multi-file) method, but `earthaccess` determined that we were working from within AWS us-west-2 and accessed the data via direct S3 access! We didn't have to create a session or a filesystem to authenticate and connect to the data. `earthaccess` did this for us using the `auth` object we created at the beginning of this tutorial. If we were not working in AWS us-west-2, `earthaccess` would "automagically" switch to accessing the data via the HTTPS endpoints and would again handle the authentication for us.

Let's take a quick lock at our `xarray` `dataset`

```{python}
ds
```

---

## Resources  

- NASA’s [Common Metadata Repository (CMR) API](https://cmr.earthdata.nasa.gov/search/site/docs/search/api.html)   
- [`earthaccess` repository](https://github.com/nsidc/earthaccess)
- [`earthaccess` documentation](https://nsidc.github.io/earthaccess/)
- [Earthdata Search](https://search.earthdata.nasa.gov/search)

