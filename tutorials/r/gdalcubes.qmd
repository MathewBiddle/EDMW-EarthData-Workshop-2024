---
title: gdalcubes
---

## STOP NOT WORKED BELOW YET


#### Explore `earthdatalogin` search response

`results` is a vector of urls to the netCDF files.
```{r}
results[1:3]
```
Notice it will start with `https:` or `s3:`. The former is a slower from of access while the latter allows faster access, like having a cloud bucket attached as a drive to your browser.

```{r}
length(results)
```


#### Open results in a data cube

https://r-spatial.org/r/2021/04/23/cloud-based-cubes.html


Based on: [Carl Boettiger lav](https://boettiger-lab.github.io/nasa-topst-env-justice/tutorials/R/2-earthdata.html)

Unfortunately these netCDF files lack appropriate metadata (projection, extent) that GDAL expects. We can provide this manually using the GDAL VRT mechanism:

```{r}
vrt <- function(url) {
  prefix <-  "vrt://NETCDF:/vsicurl/"
  suffix <- ":analysed_sst?a_srs=OGC:CRS84&a_ullr=-180,90,180,-90"
  paste0(prefix, url, suffix)}
```

Date associated with each file
```{r}
url_dates <- as.Date(gsub(".*(\\d{8})\\d{6}.*", "\\1", results), format="%Y%m%d")
```

Because each file in this list of URLs has the same spatial extent, resolution, and projection, we can now manually construct our space-time data cube from these netcdf slices:

```{r}
data_gd <- gdalcubes::stack_cube(vrt(results[1:3]), datetime_values = url_dates[1:3])
```
```{r}
extent = list(left=-75.5, right=-73.5, bottom=33.5, top=35.5,
              t0=tbox[1], t1=tbox[2])

data_gd |> 
  gdalcubes::crop(extent) |> 
  aggregate_time(dt="P3D", method="mean") |> 
  plot()
```

```{r}
data_gd <- gdalcubes::stack_cube(vrt(results), datetime_values = url_dates)
summary(data_gd)
```

```{r}
extent = list(left=-75.5, right=-73.5, bottom=bbox[2], top=35.5,
              t0=tbox[1], t1=tbox[2])

data_gd |> 
    gdalcubes::crop(extent) |> 
    aggregate_time(dt="P1M", method="mean")
```

```{r eval=FALSE}
# too slow
data_gd |> 
    slice_time(it=1) |>
    plot(col = viridisLite::viridis(10))
```
